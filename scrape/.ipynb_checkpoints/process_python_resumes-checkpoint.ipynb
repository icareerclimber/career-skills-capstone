{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'atlanta_resume_data_01.csv',\n",
    "    'atlanta_resume_data_02.csv',\n",
    "    'atlanta_resume_data_03.csv',\n",
    "    'atlanta_resume_data_04.csv',\n",
    "    'atlanta_resume_data_05.csv',\n",
    "#     'austin_resume_data_01.csv',\n",
    "#     'austin_resume_data_02.csv',\n",
    "#     'austin_resume_data_03.csv',\n",
    "#     'boston_resume_data_01.csv',\n",
    "#     'boston_resume_data_02.csv',\n",
    "#     'boston_resume_data_03.csv',\n",
    "#     'boston_resume_data_04.csv',\n",
    "#     'dc_resume_data_01.csv',\n",
    "#     'dc_resume_data_02.csv',\n",
    "#     'dc_resume_data_03.csv',\n",
    "#     'dc_resume_data_04.csv',\n",
    "#     'denver_resume_data_01.csv',\n",
    "#     'denver_resume_data_02.csv',\n",
    "#     'denver_resume_data_03.csv',\n",
    "#     'denver_resume_data_04.csv',\n",
    "#     'miami_resume_data_01.csv',\n",
    "#     'miami_resume_data_02.csv',\n",
    "#     'miami_resume_data_03.csv',\n",
    "#     'miami_resume_data_04.csv',\n",
    "#     'minn_resume_data_01.csv',\n",
    "#     'minn_resume_data_02.csv',\n",
    "#     'minn_resume_data_03.csv',\n",
    "#     'minn_resume_data_04.csv',\n",
    "#     'minn_resume_data_05.csv',\n",
    "#     'minn_resume_data_06.csv',\n",
    "#     'minn_resume_data_07.csv',\n",
    "#     'nyc_resume_data_01.csv',\n",
    "#     'nyc_resume_data_02.csv',\n",
    "#     'nyc_resume_data_03.csv',\n",
    "#     'nyc_resume_data_04.csv',\n",
    "#     'nyc_resume_data_05.csv',\n",
    "#     'nyc_resume_data_06.csv',\n",
    "#     'nyc_resume_data_07.csv',\n",
    "#     'nyc_resume_data_08.csv',\n",
    "#     'nyc_resume_data_09.csv',\n",
    "#     'seattle_resume_data_01.csv',\n",
    "#     'seattle_resume_data_02.csv',\n",
    "#     'seattle_resume_data_03.csv',\n",
    "#     'sf_resume_data_01.csv',\n",
    "#     'sf_resume_data_02.csv',\n",
    "#     'sf_resume_data_03.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"atlanta_work.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0004d469fc497102</td>\n",
       "      <td>work-experience-items</td>\n",
       "      <td>Senior Informix Database Administrator</td>\n",
       "      <td>Breckinridge Insurance</td>\n",
       "      <td>Kennesaw, GA</td>\n",
       "      <td>July 2017 to Present</td>\n",
       "      <td>.Informix DBA for Breckinridge Insurance appli...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0004d469fc497102</td>\n",
       "      <td>work-experience-items</td>\n",
       "      <td>Senior Informix DBA Database Administrator</td>\n",
       "      <td>INTERCALL Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>January 2007 to June 2017</td>\n",
       "      <td>.Informix Database Administor for InterCall's ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0004d469fc497102</td>\n",
       "      <td>work-experience-items</td>\n",
       "      <td>Oracle/Informix DBA Database Administrator</td>\n",
       "      <td>Accenture/Bellsouth Telecommuncations Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>March 2004 to December 2007</td>\n",
       "      <td>.Oracle Database for OPEDS production support....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0004d469fc497102</td>\n",
       "      <td>work-experience-items</td>\n",
       "      <td>PeopleSoft HRMS Oracle DBA Database Administrator</td>\n",
       "      <td>ACENTRON/Michelin Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>March 2003 to February 2004</td>\n",
       "      <td>.Responsible for Migrating objects and Project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0004d469fc497102</td>\n",
       "      <td>work-experience-items</td>\n",
       "      <td>INFORMIX/ORACLE Database Administrator</td>\n",
       "      <td>BellSouth Telecommunications INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November 1998 to January 2003</td>\n",
       "      <td>.Worked on various projects for BellSouth. Wor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                 1                      2  \\\n",
       "0  atlanta  0004d469fc497102  work-experience-items   \n",
       "1  atlanta  0004d469fc497102  work-experience-items   \n",
       "2  atlanta  0004d469fc497102  work-experience-items   \n",
       "3  atlanta  0004d469fc497102  work-experience-items   \n",
       "4  atlanta  0004d469fc497102  work-experience-items   \n",
       "\n",
       "                                                   3  \\\n",
       "0             Senior Informix Database Administrator   \n",
       "1         Senior Informix DBA Database Administrator   \n",
       "2         Oracle/Informix DBA Database Administrator   \n",
       "3  PeopleSoft HRMS Oracle DBA Database Administrator   \n",
       "4             INFORMIX/ORACLE Database Administrator   \n",
       "\n",
       "                                           4             5  \\\n",
       "0                     Breckinridge Insurance  Kennesaw, GA   \n",
       "1                              INTERCALL Inc           NaN   \n",
       "2  Accenture/Bellsouth Telecommuncations Inc           NaN   \n",
       "3                      ACENTRON/Michelin Inc           NaN   \n",
       "4           BellSouth Telecommunications INC           NaN   \n",
       "\n",
       "                               6  \\\n",
       "0           July 2017 to Present   \n",
       "1      January 2007 to June 2017   \n",
       "2    March 2004 to December 2007   \n",
       "3    March 2003 to February 2004   \n",
       "4  November 1998 to January 2003   \n",
       "\n",
       "                                                   7   8  \n",
       "0  .Informix DBA for Breckinridge Insurance appli... NaN  \n",
       "1  .Informix Database Administor for InterCall's ... NaN  \n",
       "2  .Oracle Database for OPEDS production support.... NaN  \n",
       "3  .Responsible for Migrating objects and Project... NaN  \n",
       "4  .Worked on various projects for BellSouth. Wor... NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "# data.columns = ['city','resume_id','container','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atlanta_resume_data_01.csv\n",
      "atlanta_resume_data_02.csv\n",
      "atlanta_resume_data_03.csv\n",
      "atlanta_resume_data_04.csv\n",
      "atlanta_resume_data_05.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in files:\n",
    "    print(filename)\n",
    "    city = filename.split(\"_\")[0]\n",
    "    process_raw_data(city,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_raw_data(city,filename):\n",
    "    for i in data.iterrows():\n",
    "        resume_id = i[1][0]\n",
    "        info = i[1][1]\n",
    "\n",
    "        resume_soup = BeautifulSoup(info, \"html.parser\")\n",
    "        containers = resume_soup.findAll(name=\"div\", attrs={\"class\":\"items-container\"})\n",
    "\n",
    "        for container in containers:\n",
    "            container_type = container['id']\n",
    "\n",
    "            if container_type == 'work-experience-items':\n",
    "                all_work = resume_soup.findAll(name=\"div\", attrs={\"id\":re.compile('workExperience.*')})\n",
    "\n",
    "                for work_pos in all_work:\n",
    "\n",
    "                    work_title = work_pos.find(name=\"p\", attrs={\"class\":\"work_title title\"})\n",
    "                    if work_title: work_title = work_title.next\n",
    "                    else: work_title = ''\n",
    "\n",
    "                    work_company = work_pos.find(name=\"div\", attrs={\"class\":\"work_company\"})\n",
    "                    if work_company:work_company = work_company.next.next\n",
    "                    else: work_company = ''\n",
    "\n",
    "                    addressLocality = work_pos.find(name=\"span\", attrs={\"itemprop\":\"addressLocality\"})\n",
    "                    if addressLocality: addressLocality = addressLocality.next\n",
    "                    else: addressLocality = ''\n",
    "\n",
    "                    work_dates = work_pos.find(name=\"p\", attrs={\"class\":\"work_dates\"})\n",
    "                    if work_dates: work_dates = work_dates.next\n",
    "                    else: work_dates = ''\n",
    "\n",
    "                    work_descript = work_pos.find(name=\"p\", attrs={\"class\":\"work_description\"})\n",
    "                    if work_descript: work_descript = re.sub('<[^<]+?>', '.', str(work_descript))\n",
    "                    else: work_descript = ''\n",
    "\n",
    "                    row = [city, resume_id, container_type, work_title, work_company, addressLocality, work_dates, work_descript]\n",
    "                    with open(city + '_work.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)                \n",
    "\n",
    "            if container_type == 'education-items':\n",
    "                all_edu = resume_soup.findAll(name=\"div\", attrs={\"class\":re.compile(\"education-section*\")})\n",
    "                for edu in all_edu:\n",
    "                    edu_title = edu.find(name=\"p\", attrs={\"class\":\"edu_title\"})\n",
    "                    if edu_title: edu_title = edu_title.next\n",
    "                    else: edu_title = ''\n",
    "\n",
    "                    edu_school = edu.find(name=\"div\", attrs={\"class\":\"edu_school\"})\n",
    "                    if edu_school: edu_school = edu_school.next.next\n",
    "                    else: edu_school = ''\n",
    "\n",
    "                    edu_dates = edu.find(name=\"p\", attrs={\"class\":\"edu_dates\"})\n",
    "                    if edu_dates: edu_dates = edu_dates.next\n",
    "                    else: edu_dates = ''\n",
    "\n",
    "                    edu_addressLocality = edu.find(name=\"span\", attrs={\"itemprop\":\"addressLocality\"})\n",
    "                    if edu_addressLocality: edu_addressLocality = edu_addressLocality.next\n",
    "                    else: edu_addressLocality = ''\n",
    "\n",
    "                    row = [city, resume_id, container_type, edu_title, edu_school, edu_addressLocality, edu_dates]\n",
    "                    with open(city + '_edu.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)                \n",
    "\n",
    "            if container_type == 'skills-items':\n",
    "                all_skills = resume_soup.findAll(name=\"span\", attrs={\"class\":\"skill-text\"})\n",
    "                for skill in all_skills:\n",
    "                    if skill: skill = skill.next\n",
    "                    else: skill = ''\n",
    "\n",
    "                    row = [city, resume_id, container_type, skill]\n",
    "                    with open(city + '_skill.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)                \n",
    "\n",
    "            if container_type == 'additionalinfo-items':\n",
    "                add_info = resume_soup.find(name=\"div\", attrs={\"id\":\"additionalinfo-section\"})\n",
    "                if add_info: add_info = re.sub('<[^<]+?>', '.', str(add_info))\n",
    "                else: add_info = ''\n",
    "\n",
    "                row = [city, resume_id, container_type, add_info]\n",
    "                with open(city + '_addinfo.csv', 'a') as myfile:\n",
    "                    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                    wr.writerow(row)                \n",
    "\n",
    "            if container_type in ['certification-items','group-items','award-items','patent-items','publication-items','link-items']:\n",
    "                data_type = container_type.partition('-')[0]\n",
    "                all_groupings = resume_soup.findAll(name=\"div\", attrs={\"class\":re.compile(data_type + \"-section*\")})\n",
    "                for grouping in all_groupings:\n",
    "\n",
    "                    title = grouping.find(name=\"p\", attrs={\"class\": data_type + \"_title\"})\n",
    "                    if title: title = title.next\n",
    "                    else: title = ''\n",
    "\n",
    "                    date = grouping.find(name=\"p\", attrs={\"class\": data_type + \"_date\"})\n",
    "                    if date: date = date.next\n",
    "                    else: date = ''\n",
    "\n",
    "                    url = grouping.find(name=\"p\", attrs={\"class\": data_type + \"_url\"})\n",
    "                    if url: url = url.next.next\n",
    "                    else: url = ''\n",
    "\n",
    "                    descript = grouping.find(name=\"p\", attrs={\"class\": data_type + \"_description\"})\n",
    "                    if descript: \n",
    "                        descript = re.sub('<[^<]+?>', '.', str(descript))\n",
    "                    else: descript = ''\n",
    "\n",
    "                    row = [city, resume_id, container_type, title, date, descript, url]\n",
    "                    with open(city + '_cert.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)\n",
    "\n",
    "            if container_type == 'military-items':\n",
    "                all_military = resume_soup.findAll(name=\"div\", attrs={\"class\":re.compile(\"military-section*\")})\n",
    "                for military in all_military:\n",
    "\n",
    "                    military_country = military.find(name=\"p\", attrs={\"military_country\"})\n",
    "                    if military_country: \n",
    "                        military_country = re.sub('<[^<]+?>', '.', str(military_country))\n",
    "                    else: military_country = ''\n",
    "\n",
    "                    military_rank = military.find(name=\"p\", attrs={\"military_rank\"})\n",
    "                    if military_rank: \n",
    "                        military_rank = re.sub('<[^<]+?>', '.', str(military_rank))\n",
    "                    else: military_rank = ''\n",
    "\n",
    "                    military_branch = military.find(name=\"p\", attrs={\"military_branch\"})\n",
    "                    if military_branch: \n",
    "                        military_branch = re.sub('<[^<]+?>', '.', str(military_branch))\n",
    "                    else: military_branch = ''\n",
    "\n",
    "                    military_date = military.find(name=\"p\", attrs={\"military_date\"})\n",
    "                    if military_date: military_date = military_date.next\n",
    "                    else: military_date = ''\n",
    "\n",
    "                    military_description = military.find(name=\"p\", attrs={\"military_description\"})\n",
    "                    if military_description: \n",
    "                        military_description = re.sub('<[^<]+?>', '.', str(military_description))\n",
    "                    else: military_description = ''\n",
    "\n",
    "                    military_commendations_title = military.find(name=\"p\", attrs={\"military_commendations_title\"})\n",
    "                    if military_commendations_title: \n",
    "                        military_commendations_title = re.sub('<[^<]+?>', '.', str(military_commendations_title))\n",
    "                    else: military_commendations_title = ''\n",
    "                        \n",
    "                    row = [city, resume_id, container_type, military_country, military_rank, military_branch, \\\n",
    "                           military_date, military_description, military_commendations_title]\n",
    "                    with open(city + '_military.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
