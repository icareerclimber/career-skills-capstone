{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_raw_data(city,filename):\n",
    "    \n",
    "    data = pd.read_csv(\"data/\" + filename, header=None)\n",
    "    print(\"filename\", filename)\n",
    "    print(\"data\", data.head(1))\n",
    "    print()\n",
    "    \n",
    "    for i in data.iterrows():\n",
    "        resume_id = i[1][0]\n",
    "        info = i[1][1]\n",
    "\n",
    "        resume_soup = BeautifulSoup(info, \"html.parser\")\n",
    "        containers = resume_soup.findAll(name=\"div\", attrs={\"class\":\"items-container\"})\n",
    "\n",
    "        for container in containers:\n",
    "            container_type = container['id']\n",
    "\n",
    "            if container_type == 'work-experience-items':\n",
    "                all_work = resume_soup.findAll(name=\"div\", attrs={\"id\":re.compile('workExperience.*')})\n",
    "\n",
    "                for work_pos in all_work:\n",
    "\n",
    "                    work_title = work_pos.find(name=\"p\", attrs={\"class\":\"work_title title\"})\n",
    "                    if work_title: work_title = work_title.next\n",
    "                    else: work_title = ''\n",
    "\n",
    "                    work_company = work_pos.find(name=\"div\", attrs={\"class\":\"work_company\"})\n",
    "                    if work_company:work_company = work_company.next.next\n",
    "                    else: work_company = ''\n",
    "\n",
    "                    addressLocality = work_pos.find(name=\"span\", attrs={\"itemprop\":\"addressLocality\"})\n",
    "                    if addressLocality: addressLocality = addressLocality.next\n",
    "                    else: addressLocality = ''\n",
    "\n",
    "                    work_dates = work_pos.find(name=\"p\", attrs={\"class\":\"work_dates\"})\n",
    "                    if work_dates: work_dates = work_dates.next\n",
    "                    else: work_dates = ''\n",
    "\n",
    "                    work_descript = work_pos.find(name=\"p\", attrs={\"class\":\"work_description\"})\n",
    "                    if work_descript: work_descript = re.sub('<[^<]+?>', '.', str(work_descript))\n",
    "                    else: work_descript = ''\n",
    "\n",
    "                    row = [city, resume_id, container_type, work_title, work_company, addressLocality, work_dates, work_descript]\n",
    "                    with open('00_resumes_work.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)                \n",
    "\n",
    "            if container_type == 'education-items':\n",
    "                all_edu = resume_soup.findAll(name=\"div\", attrs={\"class\":re.compile(\"education-section*\")})\n",
    "                for edu in all_edu:\n",
    "                    edu_title = edu.find(name=\"p\", attrs={\"class\":\"edu_title\"})\n",
    "                    if edu_title: edu_title = edu_title.next\n",
    "                    else: edu_title = ''\n",
    "\n",
    "                    edu_school = edu.find(name=\"div\", attrs={\"class\":\"edu_school\"})\n",
    "                    if edu_school: edu_school = edu_school.next.next\n",
    "                    else: edu_school = ''\n",
    "\n",
    "                    edu_dates = edu.find(name=\"p\", attrs={\"class\":\"edu_dates\"})\n",
    "                    if edu_dates: edu_dates = edu_dates.next\n",
    "                    else: edu_dates = ''\n",
    "\n",
    "                    edu_addressLocality = edu.find(name=\"span\", attrs={\"itemprop\":\"addressLocality\"})\n",
    "                    if edu_addressLocality: edu_addressLocality = edu_addressLocality.next\n",
    "                    else: edu_addressLocality = ''\n",
    "\n",
    "                    row = [city, resume_id, container_type, edu_title, edu_school, edu_addressLocality, edu_dates]\n",
    "                    with open('00_resumes_education.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)                \n",
    "\n",
    "            if container_type == 'skills-items':\n",
    "                all_skills = resume_soup.findAll(name=\"span\", attrs={\"class\":\"skill-text\"})\n",
    "                for skill in all_skills:\n",
    "                    if skill: skill = skill.next\n",
    "                    else: skill = ''\n",
    "\n",
    "                    row = [city, resume_id, container_type, skill]\n",
    "                    with open('00_resumes_skill.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)                \n",
    "\n",
    "            if container_type == 'additionalinfo-items':\n",
    "                add_info = resume_soup.find(name=\"div\", attrs={\"id\":\"additionalinfo-section\"})\n",
    "                if add_info: add_info = re.sub('<[^<]+?>', '.', str(add_info))\n",
    "                else: add_info = ''\n",
    "\n",
    "                row = [city, resume_id, container_type, add_info]\n",
    "                with open('00_resumes_addinfo.csv', 'a') as myfile:\n",
    "                    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                    wr.writerow(row)                \n",
    "\n",
    "            if container_type in ['certification-items','group-items','award-items','patent-items','publication-items','link-items']:\n",
    "                data_type = container_type.partition('-')[0]\n",
    "                all_groupings = resume_soup.findAll(name=\"div\", attrs={\"class\":re.compile(data_type + \"-section*\")})\n",
    "                for grouping in all_groupings:\n",
    "\n",
    "                    title = grouping.find(name=\"p\", attrs={\"class\": data_type + \"_title\"})\n",
    "                    if title: title = title.next\n",
    "                    else: title = ''\n",
    "\n",
    "                    date = grouping.find(name=\"p\", attrs={\"class\": data_type + \"_date\"})\n",
    "                    if date: date = date.next\n",
    "                    else: date = ''\n",
    "\n",
    "                    url = grouping.find(name=\"p\", attrs={\"class\": data_type + \"_url\"})\n",
    "                    if url: url = url.next.next\n",
    "                    else: url = ''\n",
    "\n",
    "                    descript = grouping.find(name=\"p\", attrs={\"class\": data_type + \"_description\"})\n",
    "                    if descript: \n",
    "                        descript = re.sub('<[^<]+?>', '.', str(descript))\n",
    "                    else: descript = ''\n",
    "\n",
    "                    row = [city, resume_id, container_type, title, date, descript, url]\n",
    "                    with open('00_resumes_cert.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)\n",
    "\n",
    "            if container_type == 'military-items':\n",
    "                all_military = resume_soup.findAll(name=\"div\", attrs={\"class\":re.compile(\"military-section*\")})\n",
    "                for military in all_military:\n",
    "\n",
    "                    military_country = military.find(name=\"p\", attrs={\"military_country\"})\n",
    "                    if military_country: \n",
    "                        military_country = re.sub('<[^<]+?>', '.', str(military_country))\n",
    "                    else: military_country = ''\n",
    "\n",
    "                    military_rank = military.find(name=\"p\", attrs={\"military_rank\"})\n",
    "                    if military_rank: \n",
    "                        military_rank = re.sub('<[^<]+?>', '.', str(military_rank))\n",
    "                    else: military_rank = ''\n",
    "\n",
    "                    military_branch = military.find(name=\"p\", attrs={\"military_branch\"})\n",
    "                    if military_branch: \n",
    "                        military_branch = re.sub('<[^<]+?>', '.', str(military_branch))\n",
    "                    else: military_branch = ''\n",
    "\n",
    "                    military_date = military.find(name=\"p\", attrs={\"military_date\"})\n",
    "                    if military_date: military_date = military_date.next\n",
    "                    else: military_date = ''\n",
    "\n",
    "                    military_description = military.find(name=\"p\", attrs={\"military_description\"})\n",
    "                    if military_description: \n",
    "                        military_description = re.sub('<[^<]+?>', '.', str(military_description))\n",
    "                    else: military_description = ''\n",
    "\n",
    "                    military_commendations_title = military.find(name=\"p\", attrs={\"military_commendations_title\"})\n",
    "                    if military_commendations_title: \n",
    "                        military_commendations_title = re.sub('<[^<]+?>', '.', str(military_commendations_title))\n",
    "                    else: military_commendations_title = ''\n",
    "                        \n",
    "                    row = [city, resume_id, container_type, military_country, military_rank, military_branch, \\\n",
    "                           military_date, military_description, military_commendations_title]\n",
    "                    with open('00_resumes_military.csv', 'a') as myfile:\n",
    "                        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'atlanta_resume_records.csv'\n",
    "#     'boston_resume_records.csv'\n",
    "#     'sf_resume_records.csv'\n",
    "#     'austin_resume_records.csv',\n",
    "#     'dallas_resume_records.csv',\n",
    "#     'dc_resume_records.csv',\n",
    "#     'denver_resume_records.csv',\n",
    "#     'detroit_resume_records.csv',\n",
    "#     'minneapolis_resume_records.csv',\n",
    "#     'philly_resume_records.csv',\n",
    "#     'raleigh_resume_records.csv',\n",
    "#     'sanjose_resume_records.csv',\n",
    "#     'seattle_resume_records.csv',\n",
    "#     'atlanta_resume_data_01.csv',\n",
    "#     'atlanta_resume_data_02.csv',\n",
    "#     'atlanta_resume_data_03.csv',\n",
    "#     'atlanta_resume_data_04.csv',\n",
    "#     'atlanta_resume_data_05.csv',\n",
    "#     'austin_resume_data_01.csv',\n",
    "#     'austin_resume_data_02.csv',\n",
    "#     'austin_resume_data_03.csv',\n",
    "#     'boston_resume_data_01.csv',\n",
    "#     'boston_resume_data_02.csv',\n",
    "#     'boston_resume_data_03.csv',\n",
    "#     'boston_resume_data_04.csv',\n",
    "#     'dc_resume_data_01.csv',\n",
    "#     'dc_resume_data_02.csv',\n",
    "#     'dc_resume_data_03.csv',\n",
    "#     'dc_resume_data_04.csv',\n",
    "#     'denver_resume_data_01.csv',\n",
    "#     'denver_resume_data_02.csv',\n",
    "#     'denver_resume_data_03.csv',\n",
    "#     'denver_resume_data_04.csv',\n",
    "#     'miami_resume_data_01.csv',\n",
    "#     'miami_resume_data_02.csv',\n",
    "#     'miami_resume_data_03.csv',\n",
    "#     'miami_resume_data_04.csv',\n",
    "#     'minn_resume_data_01.csv',\n",
    "#     'minn_resume_data_02.csv',\n",
    "#     'minn_resume_data_03.csv',\n",
    "#     'minn_resume_data_04.csv',\n",
    "#     'minn_resume_data_05.csv',\n",
    "#     'minn_resume_data_06.csv',\n",
    "#     'minn_resume_data_07.csv',\n",
    "#     'nyc_resume_data_01.csv',\n",
    "#     'nyc_resume_data_02.csv',\n",
    "#     'nyc_resume_data_03.csv',\n",
    "#     'nyc_resume_data_04.csv',\n",
    "#     'nyc_resume_data_05.csv',\n",
    "#     'nyc_resume_data_06.csv',\n",
    "#     'nyc_resume_data_07.csv',\n",
    "#     'nyc_resume_data_08.csv',\n",
    "#     'nyc_resume_data_09.csv',\n",
    "#     'seattle_resume_data_01.csv',\n",
    "#     'seattle_resume_data_02.csv',\n",
    "#     'seattle_resume_data_03.csv',\n",
    "#     'sf_resume_data_01.csv',\n",
    "#     'sf_resume_data_02.csv',\n",
    "#     'sf_resume_data_03.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename atlanta_resume_records.csv\n",
      "data                   0                                                  1\n",
      "0  0002bfaa5b887f08  <div class=\"data_display\" id=\"basic_info_cell\"...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename in files:\n",
    "    city = filename.split(\"_\")[0]\n",
    "    process_raw_data(city,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'\n",
    "\n",
    "resumes_addinfo = pd.read_csv(directory+\"00_resumes_addinfo.csv\",header=None)\n",
    "resumes_cert = pd.read_csv(directory+\"00_resumes_cert.csv\",header=None)\n",
    "resumes_education = pd.read_csv(directory+\"00_resumes_education.csv\",header=None)\n",
    "resumes_military = pd.read_csv(directory+\"00_resumes_military.csv\",header=None)\n",
    "resumes_skill = pd.read_csv(directory+\"00_resumes_skill.csv\",header=None)\n",
    "resumes_work = pd.read_csv(directory+\"00_resumes_work.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_city       426239\n",
      "resume_id         426239\n",
      "container_type    426239\n",
      "skill             426239\n",
      "dtype: int64\n",
      "resume_id         391637\n",
      "container_type    391637\n",
      "skill             391637\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "resumes_addinfo.columns = ['search_city', 'resume_id', 'container_type', 'skill']\n",
    "print(resumes_addinfo.count())\n",
    "del resumes_addinfo['search_city']\n",
    "resumes_addinfo_dd = resumes_addinfo.drop_duplicates()\n",
    "print(resumes_addinfo_dd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_city       498538\n",
      "resume_id         498538\n",
      "container_type    498538\n",
      "title             351046\n",
      "date              242654\n",
      "descript          142672\n",
      "url               166887\n",
      "dtype: int64\n",
      "resume_id         448287\n",
      "container_type    448287\n",
      "title             317234\n",
      "date              219685\n",
      "descript          129113\n",
      "url               147975\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "resumes_cert.columns = ['search_city', 'resume_id', 'container_type', 'title', 'date', \n",
    "                'descript', 'url']\n",
    "print(resumes_cert.count())\n",
    "del resumes_cert['search_city']\n",
    "resumes_cert_dd = resumes_cert.drop_duplicates()\n",
    "print(resumes_cert_dd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_city       1206196\n",
      "resume_id         1206196\n",
      "container_type    1206196\n",
      "edu_title         1098727\n",
      "edu_school        1175219\n",
      "edu_location       769334\n",
      "edu_dates          838240\n",
      "dtype: int64\n",
      "resume_id         1099394\n",
      "container_type    1099394\n",
      "edu_title          999545\n",
      "edu_school        1071508\n",
      "edu_location       702466\n",
      "edu_dates          767455\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "resumes_education.columns = ['search_city', 'resume_id', 'container_type', 'edu_title', \n",
    "                             'edu_school', 'edu_location', 'edu_dates']\n",
    "print(resumes_education.count())\n",
    "del resumes_education['search_city']\n",
    "resumes_education_dd = resumes_education.drop_duplicates()\n",
    "print(resumes_education_dd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_city                     15612\n",
      "resume_id                       15612\n",
      "container_type                  15612\n",
      "military_country                15612\n",
      "military_rank                   15612\n",
      "military_branch                 15612\n",
      "military_date                   13418\n",
      "military_description             8918\n",
      "military_commendations_title     5507\n",
      "dtype: int64\n",
      "resume_id                       14258\n",
      "container_type                  14258\n",
      "military_country                14258\n",
      "military_rank                   14258\n",
      "military_branch                 14258\n",
      "military_date                   12252\n",
      "military_description             8155\n",
      "military_commendations_title     5018\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "resumes_military.columns = ['search_city', 'resume_id', 'container_type', 'military_country',\n",
    "    'military_rank', 'military_branch', 'military_date', 'military_description', 'military_commendations_title']\n",
    "print(resumes_military.count())\n",
    "del resumes_military['search_city']\n",
    "resumes_military_dd = resumes_military.drop_duplicates()\n",
    "print(resumes_military_dd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_city       2382369\n",
      "resume_id         2382369\n",
      "container_type    2382369\n",
      "skill             2382361\n",
      "dtype: int64\n",
      "resume_id         2138983\n",
      "container_type    2138983\n",
      "skill             2138976\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "resumes_skill.columns = ['search_city', 'resume_id', 'container_type', 'skill']\n",
    "print(resumes_skill.count())\n",
    "del resumes_skill['search_city']\n",
    "resumes_skill_dd = resumes_skill.drop_duplicates()\n",
    "print(resumes_skill_dd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_city       3827215\n",
      "resume_id         3827215\n",
      "container_type    3827215\n",
      "work_title        3767137\n",
      "work_company      3744715\n",
      "work_location      434533\n",
      "work_dates        3801669\n",
      "work_descript     3581068\n",
      "dtype: int64\n",
      "resume_id         3503769\n",
      "container_type    3503769\n",
      "work_title        3448142\n",
      "work_company      3428044\n",
      "work_location      401983\n",
      "work_dates        3479698\n",
      "work_descript     3276632\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "resumes_work.columns = ['search_city', 'resume_id', 'container_type', 'work_title', \n",
    "                        'work_company','work_location', 'work_dates', 'work_descript']\n",
    "print(resumes_work.count())\n",
    "del resumes_work['search_city']\n",
    "resumes_work_dd = resumes_work.drop_duplicates()\n",
    "print(resumes_work_dd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes_addinfo_dd.to_csv(directory+\"00_resumes_addinfo_dd.csv\",index=False)\n",
    "resumes_cert_dd.to_csv(directory+\"00_resumes_cert_dd.csv\",index=False)\n",
    "resumes_education_dd.to_csv(directory+\"00_resumes_education_dd.csv\",index=False)\n",
    "resumes_military_dd.to_csv(directory+\"00_resumes_military_dd.csv\",index=False)\n",
    "resumes_skill_dd.to_csv(directory+\"00_resumes_skill_dd.csv\",index=False)\n",
    "resumes_work_dd.to_csv(directory+\"00_resumes_work_dd.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
