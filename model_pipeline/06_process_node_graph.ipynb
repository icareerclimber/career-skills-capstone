{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of relevant resume ids from 03_create_ngram_model\n",
    "relevant_resume_ids = pd.read_csv(directory+'03_relevant_resume_ids.csv')\n",
    "relevant_resume_ids.columns = ['resume_id']\n",
    "\n",
    "# Load the list of relevant job titles from 03_create_ngram_model\n",
    "relevant_job_titles = pd.read_csv(directory+'03_relevant_job_titles.csv')\n",
    "relevant_job_titles.columns = ['cleaned_job_title']\n",
    "\n",
    "# Load jobs\n",
    "current_job_titles = pd.read_csv(directory+'02_resumes_work.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any null job titles\n",
    "current_job_titles = current_job_titles[~current_job_titles.cleaned_job_title.isnull()]\n",
    "\n",
    "# Filter to only relevent job titles\n",
    "current_job_titles = current_job_titles\\\n",
    "    [current_job_titles.cleaned_job_title.isin(relevant_job_titles.cleaned_job_title)]\n",
    "\n",
    "# Create a shift to put current and next job title in the same row\n",
    "current_job_titles = current_job_titles.sort_values(by=['resume_id','from_year','to_year'])\\\n",
    "    .rename(columns={'cleaned_job_title': 'curr_cleaned_job_title',\n",
    "                     'from_year': 'curr_from_year'})\n",
    "current_job_titles['next_cleaned_job_title'] = current_job_titles.groupby('resume_id')\\\n",
    "['curr_cleaned_job_title'].shift(-1).fillna(\"None\")\n",
    "current_job_titles['next_from_year'] = current_job_titles.groupby('resume_id')\\\n",
    "['curr_from_year'].shift(-1).fillna(\"None\")\n",
    "\n",
    "# Remove all records where the next job titles is the same as the current job title\n",
    "current_job_titles = current_job_titles\\\n",
    "    [current_job_titles.curr_cleaned_job_title != current_job_titles.next_cleaned_job_title]\n",
    "\n",
    "# Remove all records where there the next job title doesn't exist\n",
    "current_job_titles = current_job_titles\\\n",
    "    [current_job_titles.next_cleaned_job_title != 'None']\n",
    "\n",
    "# Select only these columns\n",
    "current_job_titles = current_job_titles\\\n",
    "    [['resume_id','curr_cleaned_job_title','next_cleaned_job_title','curr_from_year','next_from_year']]\n",
    "\n",
    "current_job_titles.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_job_titles_copy = current_job_titles.copy()\n",
    "current_job_titles = current_job_titles_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows where the current job started before 10 years ago\n",
    "# Remove all rows where the next job started before 5 years ago\n",
    "current_job_titles = current_job_titles[(current_job_titles.curr_from_year > 2008)\n",
    "                                        & (current_job_titles.next_from_year > 2013)\n",
    "                                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resume_id                 58322\n",
       "curr_cleaned_job_title    58322\n",
       "next_cleaned_job_title    58322\n",
       "curr_from_year            58322\n",
       "next_from_year            58322\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "                \"max_number_records\":2500, # This is the max number of records for each job title\n",
    "}\n",
    "\n",
    "# This code samples the number of records to remove excessive numbers\n",
    "new_job_descriptions = pd.DataFrame()\n",
    "for name, group in current_job_titles.groupby('curr_cleaned_job_title'):\n",
    "    new_job_descriptions = pd.concat([new_job_descriptions,group\\\n",
    "        .sort_values(by='curr_from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "\n",
    "new_job_descriptions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_jobs = current_job_titles\\\n",
    "    .groupby(['curr_cleaned_job_title','next_cleaned_job_title'])\\\n",
    "    .resume_id.count().reset_index()\n",
    "grouped_jobs.columns = ['curr_cleaned_job_title','next_cleaned_job_title','value']\n",
    "\n",
    "grouped_jobs['ranking'] = grouped_jobs.groupby(['curr_cleaned_job_title']).value\\\n",
    "    .rank(ascending=False, method='first').astype(int)\n",
    "    \n",
    "grouped_jobs = grouped_jobs[grouped_jobs.ranking <= 15].sort_values(by=['curr_cleaned_job_title','ranking'])\n",
    "\n",
    "del grouped_jobs['ranking']\n",
    "\n",
    "grouped_jobs = grouped_jobs\\\n",
    "    .groupby(['curr_cleaned_job_title','next_cleaned_job_title'])\\\n",
    "    .value.sum()\n",
    "\n",
    "grouped_jobs = pd.DataFrame(grouped_jobs / grouped_jobs.groupby(level=0).sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_jobs.columns = ['one','two','value']\n",
    "grouped_jobs1 = grouped_jobs.copy()\n",
    "grouped_jobs1['idx'] = grouped_jobs1.two\n",
    "grouped_jobs1.set_index('idx', inplace=True )\n",
    "grouped_jobs1.columns = ['one','two','value_two']\n",
    "grouped_jobs2 = grouped_jobs.copy()\n",
    "grouped_jobs2['idx'] = grouped_jobs2.one\n",
    "grouped_jobs2.set_index('idx', inplace=True )\n",
    "grouped_jobs2.columns = ['two','three','value_three']\n",
    "curr_grouped_jobs = grouped_jobs1.merge(grouped_jobs2)\n",
    "grouped_jobs3 = grouped_jobs.copy()\n",
    "grouped_jobs3['idx'] = grouped_jobs3.one\n",
    "grouped_jobs3.set_index('idx', inplace=True )\n",
    "grouped_jobs3.columns = ['three','four','value_four']\n",
    "curr_grouped_jobs['idx'] = curr_grouped_jobs.three\n",
    "curr_grouped_jobs.set_index('idx',inplace=True)\n",
    "curr_grouped_jobs.drop_duplicates(inplace=True)\n",
    "curr_grouped_jobs = curr_grouped_jobs.merge(grouped_jobs3)\n",
    "grouped = curr_grouped_jobs.groupby(['one','two','three','four']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_parent = ''\n",
    "curr_child1 = ''\n",
    "curr_child2 = ''\n",
    "curr_child3 = ''\n",
    "parent_index = -1\n",
    "child1_index = -1\n",
    "child2_index = -1\n",
    "child3_index = -1\n",
    "\n",
    "for index, row in grouped.iterrows():\n",
    "    \n",
    "    parent = index[0]\n",
    "    child1 = index[1]\n",
    "    child2 = index[2]\n",
    "    child3 = index[3]\n",
    "\n",
    "    if curr_parent != parent:\n",
    "        if curr_parent != '':\n",
    "            with open(directory+'06_hierarchy_data/'+curr_parent.replace(' ','_')+'_hierarchy.json', 'w') as outfile:\n",
    "                json.dump(d, outfile, indent=4)\n",
    "        child1_index = -1\n",
    "        child2_index = -1\n",
    "        curr_parent = parent\n",
    "        d = {\"name\": parent, \"children\": []}\n",
    "        \n",
    "    if curr_child1 != child1:\n",
    "        child1_index += 1\n",
    "        child2_index = -1\n",
    "        curr_child1 = child1\n",
    "        d['children'].append({\"name\": child1, \n",
    "                              \"value\": round(row[0],4),\n",
    "                              \"children\": []})\n",
    "\n",
    "    if curr_child2 != child2:\n",
    "        child2_index += 1\n",
    "        curr_child2 = child2\n",
    "        d['children'][child1_index]['children'].append({\"name\": child2, \n",
    "                                                        \"value\": round(row[1],4),\n",
    "                                                         \"children\": []})\n",
    "\n",
    "    if curr_child3 != child3:\n",
    "        curr_child3 = child3\n",
    "        d['children'][child1_index]['children'][child2_index]['children'].append(\n",
    "                                                                            {\"name\": child3, \n",
    "                                                                            \"value\": round(row[2],4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
