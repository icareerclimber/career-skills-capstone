{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'\n",
    "directory = '/mnt/disks/mnt_dir/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 606127\n",
      "Number of unique resume ids: 351206\n"
     ]
    }
   ],
   "source": [
    "# Load education for resumes\n",
    "resume_edu = pd.read_csv(directory+'02_resumes_education.csv')\n",
    "\n",
    "# Load the list of relevant job titles\n",
    "relevant_job_titles = pd.read_csv(directory+'03_relevant_job_titles.csv')\n",
    "relevant_job_titles.columns = ['cleaned_job_title']\n",
    "\n",
    "# Load the list of relevant resume ids from 03_create_ngram_model\n",
    "relevant_resume_ids = pd.read_csv(directory+'03_relevant_resume_ids.csv')\n",
    "relevant_resume_ids.columns = ['resume_id']\n",
    "\n",
    "# Remove all education not in resume id list\n",
    "resume_edu = resume_edu[resume_edu.resume_id\\\n",
    "                       .isin(relevant_resume_ids.resume_id)]\n",
    "\n",
    "print(\"Number of records:\", resume_edu.resume_id.count())\n",
    "print(\"Number of unique resume ids:\", resume_edu.resume_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean education titles and tokenize\n",
    "edu_titles = resume_edu.edu_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_titles = [re.sub('[^A-Za-z0-9\\s]+', '', row.lower()) for row in edu_titles]\n",
    "edu_tokens = [word_tokenize(row) for row in edu_titles]\n",
    "\n",
    "# Create a list of acronyms by selecting all words that are 4 or less letters\n",
    "acronym_list = []\n",
    "for row in edu_tokens:\n",
    "    [acronym_list.append(x) for x in row if len(x) < 5]\n",
    "acronym_list = list(set(acronym_list))\n",
    "\n",
    "# Read in the manually created degree dictionary `degree_type_word_dict`\n",
    "degree_type_word_dict = pd.read_csv('functions/configuration_files/degree_type_word_dict.csv', encoding='latin-1')\n",
    "degree_type_word_dict = degree_type_word_dict[['keyword','type']]\\\n",
    "                        .set_index('keyword')['type']\\\n",
    "                        .to_dict()\n",
    "\n",
    "# Read in the manually created degree dictionary `degree_type_phrase_dict`\n",
    "degree_type_phrase_dict = pd.read_csv('functions/configuration_files/degree_type_phrase_dict.csv', encoding='latin-1')\n",
    "degree_type_phrase_dict = degree_type_phrase_dict[['keyword','type']]\\\n",
    "                        .set_index('keyword')['type']\\\n",
    "                        .to_dict()\n",
    "\n",
    "# Iterate through all the degree titles. Process each word:\n",
    "# 1. If the word = 'in', then add it as a `degree_row`, remove that word from the \n",
    "#   `subject_row`, and stop processing word\n",
    "# 2. If the word is in the acronym list or the manual dictionary, then add it as a\n",
    "#    `degree_row`, remove that word from the `subject_row`, and stop processing word\n",
    "# 3. If the word is not 1 or 2, stop processing the word\n",
    "degree_name_list = []\n",
    "subject_name_list = []\n",
    "for row in edu_tokens:\n",
    "    \n",
    "    degree_row = []\n",
    "    subject_row = row\n",
    "    for token in row:\n",
    "        if token == 'in':\n",
    "            degree_row.append(token)\n",
    "            subject_row = subject_row[1:]\n",
    "            break\n",
    "        elif token in list(degree_type_word_dict.keys()) + acronym_list:\n",
    "            degree_row.append(token)\n",
    "            subject_row = subject_row[1:]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    degree_name_list.append(' '.join(degree_row))\n",
    "    subject_name_list.append(' '.join(subject_row))\n",
    "    \n",
    "last_dict = {\n",
    "        'immersive':'bootcamp',\n",
    "        'certificate':'bootcamp',\n",
    "        'bootcamp':'bootcamp',\n",
    "        'boot camp':'bootcamp',\n",
    "        'license':'license',\n",
    "        'licensure':'license',\n",
    "        'certification':'certificate',\n",
    "        'certificate':'certificate',        \n",
    "        }\n",
    "\n",
    "degree_category_list = []\n",
    "for index, row in enumerate(degree_name_list):\n",
    "    degree_category = []\n",
    "    \n",
    "    found_key=0\n",
    "    # Use the `degree_type_word_dict` dictionary to assign a degree type to each `degree_row`\n",
    "    for key in filter(lambda x: str(degree_type_word_dict[x])!='nan', degree_type_word_dict):\n",
    "        if key in row.split():\n",
    "            degree_category.append(degree_type_word_dict[key])\n",
    "            found_key=1\n",
    "\n",
    "    if found_key==0:\n",
    "        # Use the `degree_type_phrase_dict` dictionary to assign a degree type to each `degree_row`\n",
    "        for phrase in degree_type_phrase_dict:\n",
    "            if re.match(phrase,row):\n",
    "                degree_category.append(degree_type_phrase_dict[phrase])\n",
    "                found_key=1\n",
    "\n",
    "    if found_key==0:\n",
    "        for key in last_dict:\n",
    "            if key in subject_name_list[index]:\n",
    "                degree_category.append(last_dict[key])\n",
    "                \n",
    "    degree_category_list.append(list(set([x.strip() for x in degree_category if str(x)!='nan' and str(x)!= ' '])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_test = ['minor',\n",
    "'all but dissertation',\n",
    "'juris doctor',\n",
    "'doctorate',\n",
    "'associates',\n",
    "'some education',\n",
    "'masters',\n",
    "'bachelors',\n",
    "'license',\n",
    "'hs diploma',\n",
    "'vocational',\n",
    "'certificate']\n",
    "\n",
    "final_degree_category_list = []\n",
    "for row in degree_category_list:\n",
    "    if len(row) > 1:\n",
    "        for job in dict_test:\n",
    "            if job in row:\n",
    "                final_degree_category_list.append(job)\n",
    "#                 print(job)\n",
    "                break\n",
    "    elif len(row) == 1:\n",
    "        final_degree_category_list.append(row[0])\n",
    "    else:\n",
    "        final_degree_category_list.append('unknown')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resume_edu['degree_name'] = degree_name_list\n",
    "resume_edu['subject_name'] = subject_name_list\n",
    "resume_edu['final_degree_category'] = final_degree_category_list\n",
    "resume_edu['possible_degree_category'] = degree_category_list\n",
    "resume_edu['possible_degree_category'] = resume_edu['possible_degree_category'].astype(str)\n",
    "\n",
    "# resume_edu.groupby(['degree_name','subject_name','final_degree_category','state'])['resume_id'].count().to_csv('temp.csv')\n",
    "current_edu = resume_edu[['resume_id','final_degree_category', 'subject_name', 'to_year']]\n",
    "current_edu.set_index('resume_id',inplace=True)\n",
    "current_edu.columns = ['final_degree_category','subject_name','edu_grad_year']\n",
    "current_edu = current_edu.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_job_titles = pd.read_csv(directory+'02_resumes_work.csv')\n",
    "current_job_titles = current_job_titles\\\n",
    "    [current_job_titles.resume_id.isin(relevant_resume_ids.resume_id)]\\\n",
    "    [['resume_id','cleaned_job_title','from_year']]\\\n",
    "    .sort_values(by='from_year')\n",
    "current_job_titles.set_index('resume_id',inplace=True)\n",
    "current_job_titles.columns = ['cleaned_job_title','work_start_year']\n",
    "current_job_titles = current_job_titles.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_job_titles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-06d501a0fe89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m combined_data = pd.merge(current_job_titles, current_edu, how='left',\n\u001b[0m\u001b[1;32m      2\u001b[0m          left_index=True, right_index=True, sort=True)\n\u001b[1;32m      3\u001b[0m \u001b[0mcombined_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_start_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_start_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcombined_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medu_grad_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medu_grad_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcombined_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_start_year\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcombined_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medu_grad_year\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'current_job_titles' is not defined"
     ]
    }
   ],
   "source": [
    "combined_data = pd.merge(current_job_titles, current_edu, how='left',\n",
    "         left_index=True, right_index=True, sort=True)\n",
    "combined_data.work_start_year = combined_data.work_start_year.fillna(0).astype(int)\n",
    "combined_data.edu_grad_year = combined_data.edu_grad_year.fillna(0).astype(int)\n",
    "combined_data = combined_data[combined_data.work_start_year >= combined_data.edu_grad_year]\n",
    "combined_data = combined_data.drop_duplicates()\n",
    "\n",
    "filler_df = current_job_titles[~current_job_titles.index.isin(combined_data.index)]\n",
    "filler_df['final_degree_category'] = 'not listed'\n",
    "filler_df['subject_name'] = 'not listed'\n",
    "filler_df['edu_grad_year'] = 1900\n",
    "\n",
    "combined_data = pd.concat([combined_data,filler_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data[['cleaned_job_title','final_degree_category','subject_name']]\\\n",
    "    .to_json(path_or_buf=directory+'04_edu_data_bar_chart.json', orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = combined_data[['cleaned_job_title','final_degree_category','subject_name']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = combined_data[combined_data.cleaned_job_title\\\n",
    "                       .isin(relevant_job_titles.cleaned_job_title)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = combined_data.groupby(['cleaned_job_title','final_degree_category','subject_name'])\\\n",
    "    .resume_id.count().reset_index()\n",
    "temp['ranking'] = temp.groupby(['cleaned_job_title','final_degree_category'])\\\n",
    "    .resume_id.rank(ascending=False).astype(int)\n",
    "temp.loc[temp.ranking>500,'subject_name'] = 'other'\n",
    "temp2 = temp.copy()\n",
    "temp = temp.groupby(['cleaned_job_title','final_degree_category','subject_name'])\\\n",
    "    .resume_id.sum().unstack('subject_name')\n",
    "temp = temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(combined_data.cleaned_job_title.unique()).rename(index=str, columns={0:'cleaned_job_title'})\\\n",
    "    .sort_values(by='cleaned_job_title')\\\n",
    "    .to_csv(directory+'04_unique_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temp = temp[temp.cleaned_job_title == 'software engineer']\n",
    "\n",
    "with open(directory+'04_edu_data_bar_chart.json', 'w') as outfile: \n",
    "    json.dump([row.dropna().to_dict() for index,row in temp.iterrows()],outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp2.groupby(['cleaned_job_title','subject_name']).resume_id.agg(['sum','max']).reset_index()\\\n",
    "    .sort_values(by=['cleaned_job_title','sum','max'],ascending=False)\\\n",
    "    .to_csv(directory+'04_ranked_subjects.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
