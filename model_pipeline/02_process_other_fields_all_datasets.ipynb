{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code does transformations on each dataset to clean fields. Transformations added to:\n",
    "# 1. salary -> remove comma and convert to int\n",
    "# 2. location -> city and state\n",
    "# 3. dates -> convert to datetime and create year\n",
    "# 4. greencard, h1b visa status -> remove records with status of WITHDRAWN or INVALIDATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary of state abbreviations to state names\n",
    "state_abbr_dict = pd.read_csv(\"functions/configuration_files/state_abbr_dict.csv\")\n",
    "state_abbr_dict = state_abbr_dict.set_index('abbreviation')['result_state'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process H1B Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'salaries_h1b'\n",
    "data = pd.read_csv(directory+\"01_\"+filename+\".csv\")\n",
    "\n",
    "# There are 4 statuses available: 'CERTIFIED', 'WITHDRAWN', 'DENIED', 'INVALIDATED'\n",
    "# Let's remove all records with WITHDRAWN or INVALIDATED\n",
    "# We don't know the details of why they were removed\n",
    "data = data[data.status.isin(['CERTIFIED', 'DENIED'])]\n",
    "\n",
    "# Convert salary data into int\n",
    "data['salary'] = data.salary.apply(lambda x: x.replace(',','')).astype(int)\n",
    "\n",
    "# Poverty line is $12,486; let's remove all the salaries less than $15k\n",
    "data = data[data.salary >= 15000]\n",
    "\n",
    "# Split location to city and state\n",
    "data['city'] = data.location.apply(lambda x: x.lower().split(',')[0])\n",
    "data['state'] = data.location.apply(lambda x: x.lower().split(',')[1])\n",
    "\n",
    "# Clean city and state data; remove numbers and special characters\n",
    "data['city'] = data.city.apply(lambda x: re.sub('[^ A-Za-z]+', '', x).strip())\n",
    "data['state'] = data.state.apply(lambda x: re.sub('[^ A-Za-z]+', '', x).strip())\n",
    "\n",
    "# Replace state abbreviation with cleaned state name\n",
    "data['state'] = data.state.apply(lambda x: state_abbr_dict[x] if x in state_abbr_dict else 'Unknown')\n",
    "\n",
    "# Convert dates into datetime format and pull out years\n",
    "data['submit_date'] = data.submit_date.apply(lambda x: datetime.datetime.strptime(x, '%M/%d/%Y'))\n",
    "data['start_date'] = data.start_date.apply(lambda x: datetime.datetime.strptime(x, '%M/%d/%Y'))\n",
    "data['submit_year'] = data.submit_date.apply(lambda x: str(x.year))\n",
    "data['start_year'] = data.start_date.apply(lambda x: str(x.year))\n",
    "\n",
    "data.to_csv(directory+\"02_\"+filename+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Greencard Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'salaries_greencard'\n",
    "data = pd.read_csv(directory+\"01_\"+filename+\".csv\")\n",
    "\n",
    "# There are 4 statuses available: 'Certified', 'Denied', 'Withdrawn', 'Certified-expired', 'Certified-Expired'\n",
    "# Let's remove all records with Withdrawn\n",
    "# We don't know the details of why they were removed\n",
    "data = data[data.status.isin(['Certified', 'Denied', 'Withdrawn', 'Certified-expired', 'Certified-Expired'])]\n",
    "\n",
    "# Clean salary information; split amount from type\n",
    "data['salary_amount'] = data.salary.apply(lambda x: x.split('/')[0].strip())\n",
    "data['salary_type'] = data.salary.apply(lambda x: x.split('/')[1].lower().strip())\n",
    "\n",
    "# Convert salary amount into float\n",
    "data['salary_amount'] = data.salary_amount.apply(lambda x: x.replace('#','').replace(',','').strip())\n",
    "data = data[data.salary_amount != '']\n",
    "data['salary_amount'] = data.salary_amount.astype(float)\n",
    "\n",
    "# Here are all the possible salary types: \n",
    "# 'hr', 'yr', 'wk', 'bi', 'mth', 'year', 'hour', '', 'month', 'week','bi-weekly'\n",
    "# We will calculate salary based on each type\n",
    "list_salaries = []\n",
    "for index, row in data[['salary_amount','salary_type']].iterrows():\n",
    "    if row.salary_type in ('hr','hour','wk','week','bi','bi-weekly','yr','year','') \\\n",
    "        and row.salary_amount >= 15000:\n",
    "            calc_salary = row.salary_amount\n",
    "    else: calc_salary = None\n",
    "    list_salaries.append(calc_salary)\n",
    "data.salary_amount = list_salaries\n",
    "\n",
    "# Split location into city and state\n",
    "data.location = data.location.apply(lambda x: x.replace(',,',','))\n",
    "data['city'] = data.location.apply(lambda x: x.lower().split(',')[0] if ',' in x else '')\n",
    "data['state'] = data.location.apply(lambda x: x.lower().split(',')[1] if ',' in x else x)\n",
    "\n",
    "# Clean city and state data; remove numbers and special characters\n",
    "data['city'] = data.city.apply(lambda x: re.sub('[^ A-Za-z]+', '', x).strip())\n",
    "data['state'] = data.state.apply(lambda x: re.sub('[^ A-Za-z]+', '', x).strip())\n",
    "\n",
    "# Replace state abbreviation with cleaned state name\n",
    "data['state'] = data.state.apply(lambda x: state_abbr_dict[x] if x in state_abbr_dict else 'Unknown')\n",
    "\n",
    "# Convert dates into datetime format and pull out years\n",
    "data.decision_date = data.decision_date.apply(lambda x:'20'+x.split('/')[2] +'-'+ \\\n",
    "                                    ('0'+x.split('/')[0])[-2:] +'-'+ \\\n",
    "                                    ('0'+x.split('/')[1])[-2:] if '/' in x else x)\n",
    "data['decision_date'] = data.decision_date.apply(lambda x: datetime.datetime.strptime(x, '%Y-%M-%d'))\n",
    "data['decision_year'] = data.decision_date.apply(lambda x: str(x.year))\n",
    "\n",
    "data.to_csv(directory+\"02_\"+filename+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Indeed Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'resumes_work'\n",
    "data = pd.read_csv(directory+\"01_\"+filename+\".csv\")\n",
    "\n",
    "# Split location into city and state\n",
    "data.location = data.location.fillna(\"\")\n",
    "data.location = data.location.apply(lambda x: x.replace(',,',','))\n",
    "data['city'] = data.location.apply(lambda x: x.split(',')[0].strip() if ',' in x else '')\n",
    "data['state'] = data.location.apply(lambda x: x.split(',')[1].strip() if ',' in x else x)\n",
    "\n",
    "# Split date information\n",
    "# If no end date, then use December in the start year as the end date\n",
    "# If \"Present\" for end date, then use June 2018 as the end date\n",
    "data['from_date'] = data.dates.apply(lambda x: (x.split(\" to \")[0]).strip())\n",
    "data['from_date'] = data.from_date.apply(lambda x: \n",
    "                        datetime.datetime.strptime('January ' + x, '%B %Y')\n",
    "                        if len(x.split(\" \"))==1\n",
    "                        else datetime.datetime.strptime(x, '%B %Y'))\n",
    "data['to_date'] = data.dates.apply(lambda x: (x.split(\" to \")[1]).strip()\n",
    "                        if len(x.split(\" to \"))>1\n",
    "                        else x.strip())\n",
    "data.loc[data.to_date == 'Present','to_date'] = 'July 2018'\n",
    "data['to_date'] = data.to_date.apply(lambda x: \n",
    "                        datetime.datetime.strptime('December ' + x, '%B %Y')\n",
    "                        if len(x.split(\" \"))==1\n",
    "                        else datetime.datetime.strptime(x, '%B %Y'))\n",
    "data['from_year'] = data.from_date.apply(lambda x: str(x.year))\n",
    "data['to_year'] = data.to_date.apply(lambda x: str(x.year))\n",
    "data['days_worked'] = (data.to_date - data.from_date).dt.days\n",
    "data['years_worked'] = round(data.days_worked/365)\n",
    "\n",
    "data.to_csv(directory+\"02_\"+filename+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'resumes_education'\n",
    "data = pd.read_csv(directory+\"00_\"+filename+\".csv\",header=None)\n",
    "data.columns = ['search_city','resume_id','container_type','edu_title',\n",
    "                      'edu_school','edu_addressLocality','edu_dates']\n",
    "\n",
    "# Remove any null education titles\n",
    "data = data[~data.edu_title.isnull()]\n",
    "\n",
    "data['city'] = data.edu_addressLocality.apply(\n",
    "                            lambda x: x.lower().split(',')[0]\n",
    "                            if len(str(x).split(','))>1\n",
    "                            else x)\n",
    "data['state'] = data.edu_addressLocality.apply(\n",
    "                            lambda x: x.lower().split(',')[1] \n",
    "                            if len(str(x).split(','))>1 and str(x)!='nan'\n",
    "                            else x)\n",
    "data['state'] = data.state.apply(lambda x: state_abbr_dict[x] if x in state_abbr_dict else x)\n",
    "\n",
    "# Update dates\n",
    "data.loc[data.edu_dates.isnull(),'edu_dates'] = 'January 1900'\n",
    "data['from_date'] = data.edu_dates.apply(lambda x: (x.split(\" to \")[0]).strip())\n",
    "data['from_date'] = data.from_date.apply(lambda x: \n",
    "                        datetime.datetime.strptime('January ' + x, '%B %Y')\n",
    "                        if len(x.split(\" \"))==1\n",
    "                        else datetime.datetime.strptime(x, '%B %Y'))\n",
    "data['to_date'] = data.edu_dates.apply(lambda x: (x.split(\" to \")[1]).strip()\n",
    "                        if len(x.split(\" to \"))>1\n",
    "                        else x.strip())\n",
    "data['currently_here'] = 'No'\n",
    "data.loc[data.to_date == 'Present','currently_here'] = 'Yes'\n",
    "data.loc[data.to_date == 'Present','to_date'] = 'July 2018'\n",
    "data['to_date'] = data.to_date.apply(lambda x: \n",
    "                        datetime.datetime.strptime('December ' + x, '%B %Y')\n",
    "                        if len(x.split(\" \"))==1\n",
    "                        else datetime.datetime.strptime(x, '%B %Y'))\n",
    "data['from_year'] = data.from_date.apply(lambda x: str(x.year))\n",
    "data['to_year'] = data.to_date.apply(lambda x: str(x.year))\n",
    "data['days_edu'] = (data.to_date - data.from_date).dt.days\n",
    "data['years_edu'] = round(data.days_edu/365)\n",
    "\n",
    "data.to_csv(directory+\"02_\"+filename+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Indeed Job Postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'job_posts_indeed'\n",
    "data = pd.read_csv(directory+\"01_\"+filename+\".csv\")\n",
    "\n",
    "# Split the city, state, and zip \n",
    "data.location = data.location.fillna(\"\")\n",
    "data.location = data.location.apply(lambda x: x.replace(',,',','))\n",
    "data['city'] = data.location.apply(lambda x: x.split(',')[0].strip() if ',' in x else '')\n",
    "data['state'] = data.location.apply(lambda x: x.split(',')[1].strip() if ',' in x else x)\n",
    "data['zip'] = data.state.apply(lambda x: x.split(' ')[1].strip() if any(char.isdigit() for char in x) else '')\n",
    "data['state'] = data.state.apply(lambda x: x.split(' ')[0].strip() if any(char.isdigit() for char in x) else x)\n",
    "\n",
    "# I have not done anything to convert the dates. Sometimes there is not an accurate date for Indeed job postings.\n",
    "# We will ignore dates anyway for Indeed Job postings.\n",
    "\n",
    "data.to_csv(directory+\"02_\"+filename+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process CCAR Job Postings¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'job_posts_ccars'\n",
    "data = pd.read_csv(directory+\"01_\"+filename+\".csv\")\n",
    "\n",
    "# Convert date field to datetime format\n",
    "data['datePosted'] = data.datePosted.apply(lambda x: datetime.datetime.strptime(x, '%Y-%M-%d'))\n",
    "data['datePosted_year'] = data.datePosted.apply(lambda x: str(x.year))\n",
    "\n",
    "# Change names for city and state\n",
    "data['state'] = data.region\n",
    "data['city'] = data.locality\n",
    "del data['region']\n",
    "del data['locality']\n",
    "\n",
    "data.to_csv(directory+\"02_\"+filename+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
