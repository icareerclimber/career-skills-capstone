{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Naive Bayes classifier using TD-IDF vectorizer and pickle results. This model can be \n",
    "# trained on job resumes or job postings. Steps include:\n",
    "# 1. Set the model parameters\n",
    "# 2. Getting a combined list of salaries and only using job titles with 500+ salary records\n",
    "# 3. Getting a list of resumes using this list of job titles and remove any job titles with \n",
    "#    less than 500 resumes\n",
    "# 4. Run TD-IDF vectorizer and Naive Bayes model training\n",
    "# 5. Test the model using \"List Most Relevant Skills\"\n",
    "# 6. Test the model using \"Document Similarity Score\"\n",
    "\n",
    "\n",
    "# We are only looking at the most recent 5 years of salary\n",
    "# We are only looking at the mode recent 10 years of work start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "\n",
    "# Custom function in functions folder\n",
    "from functions.word_preprocessing import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'\n",
    "# directory = '/mnt/disks/mnt_dir/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters for doc similarity\n",
    "parameters = {\n",
    "                \"doc_type\":\"resume\", # Use \"resume\" or \"postings\"\n",
    "                \"min_salary_year\":2014, # Filter out all salaries older than specified number\n",
    "                \"min_job_year\":2008, # Filter out all resume jobs older than specified number\n",
    "                \"min_salary_records\":100, # Filter out all jobs with less than specified salary records\n",
    "                \"min_job_summaries\":1000, # Filter out all jobs with less than specified job summaries\n",
    "                \"min_ngram\":1, # For TD-IDF vectorizer\n",
    "                \"max_ngram\":3, # For TD-IDF vectorizer\n",
    "                \"min_df\":5, # For TD-IDF vectorizer, ignore features in less than this number of documents\n",
    "                \"train_test_split\":0.05, # For train-test split\n",
    "                \"random_state\":1, # For train-test split\n",
    "                \"alpha\":0.02, # For Naive Bayes model 0.02 is current best\n",
    "                \"num_skills\":50, # Number of skill to show per job \n",
    "                \"max_number_records\":2500, # Number of records in each class, SMOTE is used to fill small classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best parameters for skills\n",
    "\n",
    "# parameters = {\n",
    "#                 \"doc_type\":\"resume\", # Use \"resume\" or \"postings\"\n",
    "#                 \"min_salary_year\":2014, # Filter out all salaries older than specified number\n",
    "#                 \"min_job_year\":2008, # Filter out all resume jobs older than specified number\n",
    "#                 \"min_salary_records\":100, # Filter out all jobs with less than specified salary records\n",
    "#                 \"min_job_summaries\":1000, # Filter out all jobs with less than specified job summaries\n",
    "#                 \"min_ngram\":3, # For TD-IDF vectorizer\n",
    "#                 \"max_ngram\":3, # For TD-IDF vectorizer\n",
    "#                 \"min_df\":5, # For TD-IDF vectorizer, ignore features in less than this number of documents\n",
    "#                 \"train_test_split\":0.05, # For train-test split\n",
    "#                 \"random_state\":1, # For train-test split\n",
    "#                 \"alpha\":0.02, # For Naive Bayes model 0.02 is current best\n",
    "#                 \"num_skills\":100, # Number of skill to show per job \n",
    "#                 \"max_number_records\":5000, # Number of records in each class, SMOTE is used to fill small classes\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Salary Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both salary datasets\n",
    "salary1 = pd.read_csv(directory+'02_salaries_h1b.csv')\n",
    "salary2 = pd.read_csv(directory+'02_salaries_greencard.csv')\n",
    "\n",
    "# Combine salary datasets\n",
    "temp_salary1 = salary1[['role','city','state','start_year','cleaned_job_title','experiences','salary']]\n",
    "temp_salary2 = salary2[['job_title','city','state','decision_year','cleaned_job_title','experiences','salary_amount']]\n",
    "temp_salary1.columns = ['original_role','city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "temp_salary2.columns = ['original_role','city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "combined_salaries = temp_salary1.append(temp_salary2)\n",
    "\n",
    "# Remove salaries with null value and convert to int\n",
    "combined_salaries = combined_salaries[~combined_salaries.salary.isnull()]\n",
    "combined_salaries.salary = combined_salaries.salary.astype(int)\n",
    "\n",
    "# Fill any NaN fields with no_value and convert each column into a list\n",
    "combined_salaries = combined_salaries.fillna('no_value')\n",
    "combined_salaries.experiences = combined_salaries.experiences.apply(lambda x: \n",
    "                                                list([item.strip() for item in x.split(',')]))\n",
    "combined_salaries.original_role = combined_salaries.original_role.apply(lambda x: [x])\n",
    "combined_salaries.city = combined_salaries.city.apply(lambda x: [x])\n",
    "combined_salaries.state = combined_salaries.state.apply(lambda x: [x])\n",
    "combined_salaries.start_year = combined_salaries.start_year.apply(lambda x: [x])\n",
    "combined_salaries.cleaned_job_title = combined_salaries.cleaned_job_title.apply(lambda x: [x])\n",
    "combined_salaries.salary = combined_salaries.salary.apply(lambda x: [x])\n",
    "\n",
    "# Perform a pivot on the columns to split out rows with multiple experience level qualifiers\n",
    "combined_salaries = pd.DataFrame([j for i in combined_salaries.values for j in product(*i)],\n",
    "                                      columns = combined_salaries.columns)\n",
    "\n",
    "# Only look at jobs in the past 5 years\n",
    "combined_salaries = combined_salaries[combined_salaries.start_year >= parameters['min_salary_year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 100+ salary records: 732\n"
     ]
    }
   ],
   "source": [
    "# Choose all jobs with `min_salary_records` or more records\n",
    "temp = combined_salaries.groupby('cleaned_job_title').count().salary.reset_index()\n",
    "jobs_to_model = temp[temp.salary >= parameters['min_salary_records']]\n",
    "combined_salaries = combined_salaries[combined_salaries.cleaned_job_title\\\n",
    "                                                       .fillna('').isin(jobs_to_model.cleaned_job_title)]\n",
    "print(\"Number of jobs with \"+str(parameters['min_salary_records'])+\"+ salary records:\", jobs_to_model.cleaned_job_title.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Job Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load resume data\n",
    "if parameters['doc_type'] == 'resume':\n",
    "    data = pd.read_csv(directory+'02_resumes_work.csv')\n",
    "    data.rename(columns = {'descript':'summary_text'}, inplace=True)\n",
    "if parameters['doc_type'] == 'postings':\n",
    "    data = pd.read_csv(directory+'02_job_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 1000+ resume entries: 114\n",
      "Number of resume entries available: 497928\n"
     ]
    }
   ],
   "source": [
    "# Remove all null cleaned_job_title records\n",
    "jobs_descriptions = data[~data.cleaned_job_title.isnull()]\n",
    "\n",
    "# Remove all jobs older than 10 years\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.from_year >= parameters['min_job_year']]\n",
    "\n",
    "# Drop insignificant job names\n",
    "jobs_to_remove = ['technical','team','test','project']\n",
    "jobs_descriptions = jobs_descriptions[~jobs_descriptions.cleaned_job_title.isin(jobs_to_remove)] \n",
    "\n",
    "# Filter to only jobs specified by the jobs_to_model list\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title\\\n",
    "                                      .isin(jobs_to_model.cleaned_job_title)]\n",
    "    \n",
    "# Remove all jobs without `min_job_summaries` or more resume entries\n",
    "cnt_resumes_available = jobs_descriptions.groupby('cleaned_job_title')\\\n",
    "                                .count().reset_index()\n",
    "cnt_resumes_available = list(cnt_resumes_available[\n",
    "            cnt_resumes_available.summary_text>parameters['min_job_summaries']].cleaned_job_title)\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title\\\n",
    "                       .isin(cnt_resumes_available)]\n",
    "\n",
    "# Remove duplicate data\n",
    "jobs_descriptions = jobs_descriptions.groupby(['cleaned_job_title','summary_text','from_year'])\\\n",
    "        .resume_id.first().reset_index()\n",
    "\n",
    "print(\"Number of jobs with \"+str(parameters['min_job_summaries'])+\"+ resume entries:\", len(cnt_resumes_available))\n",
    "print(\"Number of resume entries available:\", jobs_descriptions.cleaned_job_title.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleaned_job_title    342934\n",
       "summary_text         342934\n",
       "from_year            342934\n",
       "resume_id            342934\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code samples the number of records to remove excessive numbers\n",
    "new_job_descriptions = pd.DataFrame()\n",
    "for name, group in jobs_descriptions.groupby('cleaned_job_title'):\n",
    "    if group[group.from_year == 2016].cleaned_job_title.count() >= parameters['max_number_records']:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group[group.from_year < 2017]\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "    elif group[(group.from_year == 2016) | (group.from_year == 2017)].cleaned_job_title.count() >= parameters['max_number_records']:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group[group.from_year < 2018]\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "    else:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "\n",
    "new_job_descriptions.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data for Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save off list of resume ids\n",
    "if parameters['doc_type'] == 'resume':\n",
    "    # Save the list of resume ids for resumes being used\n",
    "    pd.DataFrame(new_job_descriptions.resume_id.unique())\\\n",
    "                .to_csv(directory+'03_relevant_resume_ids.csv',index=False)\n",
    "\n",
    "# Save off list of relevant job titles\n",
    "relevant_job_titles = pd.DataFrame(new_job_descriptions.cleaned_job_title.unique())\n",
    "relevant_job_titles.columns = ['cleaned_job_title']\n",
    "relevant_job_titles.to_csv(directory+'03_relevant_job_titles.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves the cleaned salary information back to the main data folder\n",
    "combined_salaries.to_csv(directory+'03_cleaned_salaries_for_app.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = new_job_descriptions.summary_text\n",
    "y_labels = new_job_descriptions.cleaned_job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, \n",
    "                                                    y_labels,\n",
    "                                                    test_size=parameters['train_test_split'],\n",
    "                                                    random_state=parameters['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 325787\n",
      "y_train:  325787\n",
      "X_test:  17147\n",
      "y_test:  17147\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\",len(X_train))\n",
    "print(\"y_train: \",len(y_train))\n",
    "print(\"X_test: \",len(X_test))\n",
    "print(\"y_test: \",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_job_descriptions.cleaned_job_title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in new_job_descriptions.cleaned_job_title.unique():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# x_data = new_job_descriptions.summary_text\n",
    "# y_labels = new_job_descriptions.cleaned_job_title\n",
    "\n",
    "# x_data = preprocess_list(new_job_descriptions.summary_text)\n",
    "# print(\"Done with preprocess\")\n",
    "\n",
    "# # create a count vectorizer object \n",
    "# count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "# count_vectorized_X_train = count_vect.fit_transform(X_train)\n",
    "\n",
    "# sm = SMOTE(kind='regular')\n",
    "# count_vect_X_res, count_vect_y_res = sm.fit_sample(count_vectorized_X_train, y_train)\n",
    "\n",
    "# # transform the training and validation data using count vectorizer object\n",
    "# # xtrain_count =  count_vect.transform(train_x)\n",
    "# count_vectorized_X_test =  count_vect.transform(X_test)\n",
    "\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# x_data = new_job_descriptions.summary_text\n",
    "# y_labels = new_job_descriptions.cleaned_job_title\n",
    "\n",
    "# x_data = preprocess_list(new_job_descriptions.summary_text)\n",
    "# print(\"Done with preprocess\")\n",
    "\n",
    "# # Split the data into test and train datasets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x_data, \n",
    "#                                                     y_labels,\n",
    "#                                                     test_size=parameters['train_test_split'],\n",
    "#                                                     random_state=parameters['random_state'])\n",
    "\n",
    "# # Train TF-IDF vectorizer model\n",
    "# vect = TfidfVectorizer(min_df=parameters['min_df'], \n",
    "#                        ngram_range=(parameters['min_ngram'], parameters['max_ngram'])\n",
    "#                       ).fit(X_train)\n",
    "# X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "# print(\"Done with TD-IDF\")\n",
    "\n",
    "# print('Vocabulary len:', len(vect.get_feature_names()))\n",
    "\n",
    "# sm = SMOTE(kind='regular')\n",
    "# X_res, y_res = sm.fit_sample(X_train_vectorized, y_train)\n",
    "\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickling_on = open(directory+\"models/dev_X_test.pkl\",\"wb\")\n",
    "# # pickle.dump(X_test, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/dev_y_test.pkl\",\"wb\")\n",
    "# # pickle.dump(y_test, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/dev_x_SMOTE_data.pkl\",\"wb\")\n",
    "# # pickle.dump(X_res, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/dev_y_SMOTE_data.pkl\",\"wb\")\n",
    "# # pickle.dump(y_res, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/vect.pkl\",\"wb\")\n",
    "# # pickle.dump(vect, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_X_test.pkl\",\"rb\")\n",
    "# X_test = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_y_test.pkl\",\"rb\")\n",
    "# y_test = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_x_SMOTE_data.pkl\",\"rb\")\n",
    "# X_res = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_y_SMOTE_data.pkl\",\"rb\")\n",
    "# y_res = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/vect.pkl\",\"rb\")\n",
    "# vect = pickle.load(pickling_on)\n",
    "# pickling_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_model = MultinomialNB(alpha=0.02)\n",
    "# nb_model.fit(X_res, y_res)\n",
    "\n",
    "# y_pred = nb_model.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# # Accuracy: 35.83% .012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# svm_model = SGDClassifier(loss='hinge', penalty='l2', alpha=.0008, n_iter=3, random_state=42)\n",
    "\n",
    "# svm_model.fit(X_res, y_res)\n",
    "\n",
    "# y_pred = svm_model.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# print(\"End:\", datetime.datetime.now())\n",
    "# # Accuracy: 47.21% alpha=.0008, n_iter=3\n",
    "# # Count Vectorizer Accuracy: 40.81% .0008 n_iter=3\n",
    "# # Accuracy: 41.42% .001 5\n",
    "# # Accuracy: 41.41% .009 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# eclf1 = VotingClassifier(estimators=[\n",
    "#             ('nb', nb_model), ('svm', svm_model)], voting='hard')\n",
    "# eclf2 = VotingClassifier(estimators=[\n",
    "#             ('nb', nb_model), ('svm', svm_model)], voting='soft')\n",
    "# # eclf3 = VotingClassifier(estimators=[\n",
    "# #             ('nb', nb_model), ('svm', svm_model)], voting='soft', weights=[1,1,2], flatten_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "# eclf1.fit(X_res, y_res)\n",
    "# y_pred = eclf1.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "# eclf2.fit(X_res, y_res)\n",
    "# y_pred = eclf2.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# # from sklearn.decomposition import PCA\n",
    "# # from sklearn.pipeline import Pipeline\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# # pca = PCA(n_components=152).fit(X_res)\n",
    "# # data2D = pca.transform(X_res)\n",
    "# # plt.scatter(data2D[:,0], data2D[:,1], c=data.target)\n",
    "# # plt.show()              #not required if using ipython notebook\n",
    "\n",
    "\n",
    "# # Load libraries\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# from scipy.sparse import csr_matrix\n",
    "# from sklearn import datasets\n",
    "# import numpy as np\n",
    "\n",
    "# tsvd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# X_sparse_tsvd = tsvd.fit_transform(X_res)\n",
    "\n",
    "# # # Show results\n",
    "# print('Original number of features:', X_res.shape[1])\n",
    "# print('Reduced number of features:', X_sparse_tsvd.shape[1])\n",
    "# # Original number of features: 64\n",
    "# # Reduced number of features: 10\n",
    "# # View Percent Of Variance Explained By New Features\n",
    "# # # Sum of first three components' explained variance ratios\n",
    "# # tsvd.explained_variance_ratio_[0:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_matrix = X_res.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_remove_index = []\n",
    "# # filevector = open('docvectors.txt', 'w')\n",
    "# vector_list = []\n",
    "# meta_list = []\n",
    "# meta_list = list(y_res)\n",
    "# # filemeta = open('docmeta.txt', 'w')\n",
    "# # edu_filemeta.write(\"%s\\n\" % 'title')\n",
    "\n",
    "# for index in range(X_res.shape[0]):\n",
    "#     cleaned_vectors = '\\t'.join(str(vector) for vector in X_sparse_tsvd[index])\n",
    "#     if not cleaned_vectors or cleaned_vectors == '':\n",
    "#         print(index)\n",
    "#         list_of_remove_index.append(index)\n",
    "#         continue\n",
    "#     vector_list.append(cleaned_vectors)\n",
    "# #     filevector.write(\"%s\\n\" % cleaned_vectors)\n",
    "# #     cleaned_meta = (str(index) + ' ' + ' '.join(traindocs[index].words))\n",
    "# #     if index >= 94999:\n",
    "# #         print(index)\n",
    "# #     if not cleaned_meta:\n",
    "# #         print(\"issue with meta\")\n",
    "# #         print(index)\n",
    "# #     filemeta.write(\"%s\\n\" %cleaned_meta )\n",
    "# #     meta_list.append(cleaned_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(X_sparse_tsvd).to_csv('teest.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(vector_list))\n",
    "# print(X_sparse_tsvd.shape)\n",
    "# print(len(meta_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len(vector_list)\n",
    "# # len(meta_list)\n",
    "# filevector = open('docvectors.txt', 'w')\n",
    "# filemeta = open('docmeta.txt', 'w')\n",
    "# for row in vector_list:\n",
    "#     filevector.write(\"%s\\n\" % row)\n",
    "# for row in meta_list:\n",
    "#     filemeta.write(\"%s\\n\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# conf_mat = confusion_matrix(y_test, y_pred)\n",
    "# fig, ax = plt.subplots(figsize=(50,50))\n",
    "# sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Greys',\n",
    "#             xticklabels=nb_model.classes_, yticklabels=nb_model.classes_)\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = FunctionTransformer(preprocess_list)\n",
    "smt = SMOTE()\n",
    "tfidf = TfidfVectorizer(min_df=parameters['min_df'], ngram_range=(parameters['min_ngram'], parameters['max_ngram']))\n",
    "nb = MultinomialNB(alpha=parameters['alpha'])\n",
    "preprocess = FunctionTransformer(preprocess_list, validate=False)\n",
    "\n",
    "pipeline = Pipeline([('preprocess', preprocess), ('tfidf', tfidf), ('smt', smt), ('nb', nb)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 325787\n",
      "y_train: 325787\n",
      "Start: 2018-08-05 08:49:20.819808\n",
      "End: 2018-08-05 09:07:29.022073\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', len(X_train))\n",
    "print('y_train:', len(y_train))\n",
    "\n",
    "print(\"Start:\", datetime.datetime.now())\n",
    "pipeline.fit(X_train,y_train)\n",
    "print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.39%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# Accuracy: 48.86% for doc similarity\n",
    "# Accuracy: 39.39% for skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.356097542179\n",
      "precision_score:  0.368799372728\n",
      "recall_score:  0.36099768835\n"
     ]
    }
   ],
   "source": [
    "print('f1_score: ', f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print('precision_score: ', precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print('recall_score: ', recall_score(y_test, y_pred, average=\"macro\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>build and release engineer</td>\n",
       "      <td>81.01%</td>\n",
       "      <td>88.28%</td>\n",
       "      <td>84.49%</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>devops engineer</td>\n",
       "      <td>83.59%</td>\n",
       "      <td>82.95%</td>\n",
       "      <td>83.27%</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>salesforce engineer</td>\n",
       "      <td>80.31%</td>\n",
       "      <td>85.71%</td>\n",
       "      <td>82.93%</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>database administrator</td>\n",
       "      <td>80.66%</td>\n",
       "      <td>79.91%</td>\n",
       "      <td>80.28%</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>network engineer</td>\n",
       "      <td>81.30%</td>\n",
       "      <td>77.82%</td>\n",
       "      <td>79.52%</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         class precision  recall  fscore  support\n",
       "17  build and release engineer    81.01%  88.28%  84.49%      145\n",
       "37             devops engineer    83.59%  82.95%  83.27%      258\n",
       "94         salesforce engineer    80.31%  85.71%  82.93%      119\n",
       "34      database administrator    80.66%  79.91%  80.28%      214\n",
       "68            network engineer    81.30%  77.82%  79.52%      257"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(y_test, y_pred)\n",
    "'{:.1%}'.format(1/3.0)\n",
    "\n",
    "metrics = pd.DataFrame(list(zip(pipeline.classes_, precision, recall, fscore, support)))\n",
    "metrics.columns = ['class','precision', 'recall', 'fscore', 'support']\n",
    "metrics_samples = metrics.sort_values(by='fscore',ascending=False).head(5)\n",
    "metrics_samples.precision = metrics_samples.precision.map(lambda x: '{:.2%}'.format(x))\n",
    "metrics_samples.recall = metrics_samples.recall.map(lambda x: '{:.2%}'.format(x))\n",
    "metrics_samples.fscore = metrics_samples.fscore.map(lambda x: '{:.2%}'.format(x))\n",
    "metrics_samples.sort_values(by='fscore',ascending=True).to_csv('temp.csv')\n",
    "metrics_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# counted = collections.Counter(y_test)\n",
    "\n",
    "# from operator import itemgetter\n",
    "# import heapq\n",
    "# import collections\n",
    "# def least_common_values(array, to_find=None):\n",
    "#     counter = collections.Counter(array)\n",
    "#     if to_find is None:\n",
    "#         return sorted(counter.items(), key=itemgetter(1), reverse=False)\n",
    "#     return heapq.nsmallest(to_find, counter.items(), key=itemgetter(1))\n",
    "\n",
    "# # counted.most_common()\n",
    "# least_common_values(counted, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>accountant</td>\n",
       "      <td>staff accountant</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>staff accountant</td>\n",
       "      <td>accountant</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>systems engineer</td>\n",
       "      <td>systems administrator</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>network administrator</td>\n",
       "      <td>systems administrator</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>j2ee engineer</td>\n",
       "      <td>java software engineer</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>java software engineer</td>\n",
       "      <td>j2ee engineer</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>process engineer</td>\n",
       "      <td>manufacturing engineer</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>quality assurance engineer</td>\n",
       "      <td>quality assurance analyst</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>systems administrator</td>\n",
       "      <td>network administrator</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>quality assurance analyst</td>\n",
       "      <td>quality assurance tester</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          actual                 prediction  count\n",
       "108                   accountant           staff accountant    101\n",
       "3065            staff accountant                 accountant     65\n",
       "3207            systems engineer      systems administrator     55\n",
       "1985       network administrator      systems administrator     46\n",
       "1717               j2ee engineer     java software engineer     41\n",
       "1727      java software engineer              j2ee engineer     40\n",
       "2089            process engineer     manufacturing engineer     37\n",
       "2598  quality assurance engineer  quality assurance analyst     34\n",
       "3097       systems administrator      network administrator     33\n",
       "2565   quality assurance analyst   quality assurance tester     32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the test population, get the most confused labels\n",
    "\n",
    "# pd.options.display.max_rows = 10000\n",
    "predictions = pd.DataFrame(list(zip(y_test, y_pred)))\n",
    "predictions.columns=['actual','prediction']\n",
    "predictions['count']=1\n",
    "pred_group = predictions.groupby(['actual','prediction']).count().reset_index()\n",
    "pred_group[(pred_group.actual != pred_group.prediction) \n",
    "           & (pred_group.prediction!='account executive')\n",
    "          ].sort_values(by='count',ascending=False).head(10)\n",
    "# .to_csv('most_confusion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Most Relevant Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ios engineer\n",
      "-------\n",
      "0 io iphone sdk\n",
      "1 objective cocoa framework\n",
      "2 url http itunes\n",
      "3 adobe cs5 suite\n",
      "4 available app store\n",
      "5 ui navigation controller\n",
      "6 code fix bug\n",
      "7 storyboards autolayout constraint\n",
      "8 json parsing include\n",
      "9 cross functional team\n",
      "10 mapkit core location\n",
      "11 work backend team\n",
      "12 breakpoints lldb statement\n",
      "13 suite photoshop dreamweaver\n",
      "14 web service json\n",
      "15 parse json response\n",
      "16 call xml json\n",
      "17 gdb xcode debugging\n",
      "18 view controller made\n",
      "19 implement core data\n",
      "20 tester developer work\n",
      "21 use xib design\n",
      "22 sdk mac objective\n",
      "23 customize table view\n",
      "24 tool xcode objectivec\n",
      "25 apple com app\n",
      "26 app link http\n",
      "27 checkout update codebase\n",
      "28 work closely within\n",
      "29 responsibility work extensively\n",
      "30 design development work\n",
      "31 view mixture using\n",
      "32 xcode interface builder\n",
      "33 display correct data\n",
      "34 work git checkout\n",
      "35 smooth transitioning better\n",
      "36 apple push notification\n",
      "37 work uikit framework\n",
      "38 create model mvc\n",
      "39 updating model information\n",
      "40 xcode cocoa touch\n",
      "41 environment io mac\n",
      "42 data flow principle\n",
      "43 develop navigation view\n",
      "44 data format device\n",
      "45 report progress challenge\n",
      "46 grand central dispatch\n",
      "47 prefetching data different\n",
      "48 code review code\n",
      "49 follow work data\n",
      "50 team io developer\n",
      "51 better user experience\n",
      "52 integrate backend web\n"
     ]
    }
   ],
   "source": [
    "# This code finds the top parameters['num_skills'] of features to show the user. It filters out any \n",
    "# ngram where the same n-1 version of the ngram is shown. This cuts down on repetition.\n",
    "\n",
    "label_id = 51\n",
    "\n",
    "print(pipeline.classes_[label_id])\n",
    "print('-------')\n",
    "\n",
    "features_list = []\n",
    "topn_class1 = sorted(zip(pipeline.named_steps['nb'].coef_[label_id], \n",
    "                         pipeline.named_steps['tfidf'].get_feature_names()))[-parameters['num_skills']:]\n",
    "for coef, feat in topn_class1:\n",
    "    features_list.append(feat)\n",
    "\n",
    "accepted_skill_list = [pipeline.classes_[label_id]]\n",
    "for potential_skill in sorted(features_list, key=lambda x: -len(x.split())):\n",
    "    highest_match = len(potential_skill.split())\n",
    "    for accepted_skill in accepted_skill_list:\n",
    "        leftovers = list(set(potential_skill.split()) - set(accepted_skill.split()))\n",
    "        if len(leftovers) < highest_match:\n",
    "            highest_match = len(leftovers)\n",
    "    if highest_match > 1:\n",
    "        accepted_skill_list.append(potential_skill)\n",
    "accepted_skill_list = accepted_skill_list[1:]\n",
    "shuffle(accepted_skill_list)\n",
    "\n",
    "for index, skill in enumerate(accepted_skill_list):\n",
    "    print(index, skill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL LABEL\n",
      "326718    project manager\n",
      "Name: cleaned_job_title, dtype: object\n",
      "\n",
      "---------------------\n",
      "\n",
      "INPUT\n",
      "326718    .Produced 7 videos to be used a part of an online interactive trainin .module. \"Shortening Management.\" Heavily involved in all aspects of production. Created light diagrams, shot logs, and initial rough cuts. .Attended overnight shoots and managed team..\n",
      "Name: summary_text, dtype: object\n",
      "\n",
      "---------------------\n",
      "\n",
      "OUTPUT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.33121678375734054, 'designer'),\n",
       " (0.14559227791404752, 'art director'),\n",
       " (0.10827273831558622, 'creative director'),\n",
       " (0.10219457961707287, 'graphic designer'),\n",
       " (0.049579636789399292, 'mechanical engineer'),\n",
       " (0.044342383494734759, 'production manager'),\n",
       " (0.032139331633062838, 'marketing manager'),\n",
       " (0.017060862261132688, 'project manager'),\n",
       " (0.014791250897224082, 'director'),\n",
       " (0.013185577762211452, 'mechanical design engineer'),\n",
       " (0.01040982642872439, 'process engineer'),\n",
       " (0.009375135533138226, 'software test engineer'),\n",
       " (0.0092984499230077504, 'manufacturing engineer'),\n",
       " (0.0080556784073791358, 'design engineer'),\n",
       " (0.0070383626963855068, 'technical writer'),\n",
       " (0.005623314604888875, 'product engineer'),\n",
       " (0.0054593857647914235, 'architect'),\n",
       " (0.0042924682071691349, 'quality assurance manager'),\n",
       " (0.0034467212089058078, 'applications engineer'),\n",
       " (0.0032189923779301064, 'engineer')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code returns the prediction probabilities for an example input\n",
    "\n",
    "print(\"ACTUAL LABEL\")\n",
    "example_index = 43\n",
    "print(y_test[example_index:example_index+1])\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "print()\n",
    "print(\"INPUT\")\n",
    "example = X_test[example_index:example_index+1]\n",
    "print(example)\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "print()\n",
    "print(\"OUTPUT\")\n",
    "\n",
    "job_rankings = list(zip(pipeline.predict_proba(example)[0],pipeline.classes_))\n",
    "sorted(job_rankings,reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180805090815480402\n"
     ]
    }
   ],
   "source": [
    "# This code saves the model to the models folder\n",
    "# directory = '/mnt/disks/mnt_dir/'\n",
    "\n",
    "save_time = re.sub('[^A-Za-z0-9]+', '', str(datetime.datetime.now()))\n",
    "print(save_time)\n",
    "\n",
    "write_param = open(directory+\"models/\" + save_time + '_parameters.txt','w')\n",
    "for key in parameters:\n",
    "    write_param.write(key + \"=\" + str(parameters[key]) + '\\n')\n",
    "write_param.close()\n",
    "\n",
    "# Save preprocessed x data\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_data.pkl\",\"wb\")\n",
    "pickle.dump(x_data, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save preprocessed y labels\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_y_labels.pkl\",\"wb\")\n",
    "pickle.dump(y_labels, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# # Save NB model\n",
    "# pickling_on = open(directory+\"models/\"+save_time+\"_pipeline_model.pkl\",\"wb\")\n",
    "# pickle.dump(pipeline, pickling_on)\n",
    "# pickling_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MacOSFile(object):\n",
    "\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        return getattr(self.f, item)\n",
    "\n",
    "    def read(self, n):\n",
    "        # print(\"reading total_bytes=%s\" % n, flush=True)\n",
    "        if n >= (1 << 31):\n",
    "            buffer = bytearray(n)\n",
    "            idx = 0\n",
    "            while idx < n:\n",
    "                batch_size = min(n - idx, 1 << 31 - 1)\n",
    "                # print(\"reading bytes [%s,%s)...\" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "                buffer[idx:idx + batch_size] = self.f.read(batch_size)\n",
    "                # print(\"done.\", flush=True)\n",
    "                idx += batch_size\n",
    "            return buffer\n",
    "        return self.f.read(n)\n",
    "\n",
    "    def write(self, buffer):\n",
    "        n = len(buffer)\n",
    "        print(\"writing total_bytes=%s...\" % n, flush=True)\n",
    "        idx = 0\n",
    "        while idx < n:\n",
    "            batch_size = min(n - idx, 1 << 31 - 1)\n",
    "            print(\"writing bytes [%s, %s)... \" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "            self.f.write(buffer[idx:idx + batch_size])\n",
    "            print(\"done.\", flush=True)\n",
    "            idx += batch_size\n",
    "\n",
    "\n",
    "def pickle_dump(obj, file_path):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        return pickle.dump(obj, MacOSFile(f), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=1721537373...\n",
      "writing bytes [0, 1073741824)... done.\n",
      "writing bytes [1073741824, 1721537373)... done.\n"
     ]
    }
   ],
   "source": [
    "pickle_dump(pipeline,directory+\"models/\"+save_time+\"_pipeline_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code loads an old model\n",
    "# directory = '/mnt/disks/mnt_dir/'\n",
    "\n",
    "save_time = '20180805074152591471' # Currently best model for doc similarity\n",
    "# save_time = '20180805090815480402' # Currently best model for skills\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_data.pkl\",\"rb\")\n",
    "x_data = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_y_labels.pkl\",\"rb\")\n",
    "y_labels = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_pipeline_model.pkl\",\"rb\")\n",
    "pipeline = pickle.load(pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
