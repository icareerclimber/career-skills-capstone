{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Custom function in functions folder\n",
    "from functions.process_edu_titles import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'\n",
    "# directory = '/mnt/disks/mnt_dir/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 259134\n",
      "Number of unique resume ids: 153067\n"
     ]
    }
   ],
   "source": [
    "# Load education for resumes\n",
    "resume_edu = pd.read_csv(directory+'02_resumes_education.csv')\n",
    "\n",
    "# Load the list of relevant job titles\n",
    "relevant_job_titles = pd.read_csv(directory+'03_relevant_job_titles.csv')\n",
    "relevant_job_titles.columns = ['cleaned_job_title']\n",
    "\n",
    "# Remove all education not in resume id list\n",
    "resume_edu = resume_edu[resume_edu.resume_id\\\n",
    "                       .isin(relevant_resume_ids.resume_id)]\n",
    "\n",
    "print(\"Number of records:\", resume_edu.resume_id.count())\n",
    "print(\"Number of unique resume ids:\", resume_edu.resume_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the resume work information\n",
    "current_job_titles = pd.read_csv(directory+'02_resumes_work.csv')\n",
    "\n",
    "# Remove all null cleaned_job_title records\n",
    "current_job_titles = current_job_titles[~current_job_titles.cleaned_job_title.isnull()]\n",
    "\n",
    "# Load the list of relevant job titles\n",
    "relevant_job_titles = pd.read_csv(directory+'03_relevant_job_titles.csv')\n",
    "relevant_job_titles.columns = ['cleaned_job_title']\n",
    "\n",
    "# Filter to only job titles used in `03_process_salary_and_create_ngram_model`\n",
    "current_job_titles = current_job_titles[current_job_titles.cleaned_job_title\\\n",
    "                                        .isin(relevant_job_titles.cleaned_job_title)]\n",
    "\n",
    "# Filter to only resumes used in `03_process_salary_and_create_ngram_model`\n",
    "current_job_titles = current_job_titles[current_job_titles.resume_id.isin(relevant_resume_ids.resume_id)]    \n",
    "\n",
    "# Select only these columns\n",
    "current_job_titles = current_job_titles[['resume_id','cleaned_job_title','from_year']]\n",
    "\n",
    "# Drop any duplicates\n",
    "current_job_titles = current_job_titles.drop_duplicates()\n",
    "\n",
    "# Make resume id the index\n",
    "current_job_titles.set_index('resume_id', inplace=True)\n",
    "\n",
    "# Rename the columns\n",
    "current_job_titles.columns = ['cleaned_job_title','work_start_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Education Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name_list, degree_name_list, degree_category_list = process_edu_titles(resume_edu.edu_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the processed data to the original dataframe\n",
    "resume_edu['degree_name'] = degree_name_list\n",
    "resume_edu['subject_name'] = subject_name_list\n",
    "resume_edu['degree_category'] = degree_category_list\n",
    "\n",
    "\n",
    "# Create a new dataframe with processed data\n",
    "current_edu = resume_edu[['resume_id','degree_category', 'subject_name', 'to_year']].set_index('resume_id')\n",
    "current_edu.columns = ['final_degree_category','subject_name','edu_grad_year']\n",
    "current_edu = current_edu.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Education and Work History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the list of processed education titles with the list of resumes.\n",
    "# This section matches the work start date and the education end date.\n",
    "# If education end date is after the work start date, the education record\n",
    "# is removed from the list. This ensures that education is applied to the \n",
    "# correct timeframes.\n",
    "combined_data = pd.merge(current_job_titles, current_edu, how='left',\n",
    "         left_index=True, right_index=True, sort=True)\n",
    "combined_data.work_start_year = combined_data.work_start_year.fillna(0).astype(int)\n",
    "combined_data.edu_grad_year = combined_data.edu_grad_year.fillna(0).astype(int)\n",
    "combined_data = combined_data[combined_data.work_start_year >= combined_data.edu_grad_year]\n",
    "combined_data = combined_data.drop_duplicates()\n",
    "\n",
    "# filler_df = current_job_titles[~current_job_titles.index.isin(combined_data.index)]\n",
    "# filler_df['final_degree_category'] = 'not listed'\n",
    "# filler_df['subject_name'] = 'not listed'\n",
    "# filler_df['edu_grad_year'] = 1900\n",
    "\n",
    "# combined_data = pd.concat([combined_data,filler_df])\n",
    "combined_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_data[combined_data.cleaned_job_title == 'accountant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For any job titles that have more than 1000 subjects, we will mask the last subjects as `other`\n",
    "final_combined_data = combined_data.groupby(['cleaned_job_title','final_degree_category','subject_name'])\\\n",
    "    .resume_id.count().reset_index()\n",
    "final_combined_data['ranking'] = final_combined_data.groupby(['cleaned_job_title','final_degree_category'])\\\n",
    "    .resume_id.rank(ascending=False).astype(int)\n",
    "final_combined_data.loc[final_combined_data.ranking>1000,'subject_name'] = 'other'\n",
    "\n",
    "# Save list of subject rankings. This is used for sorting for each job title.\n",
    "final_combined_data.groupby(['cleaned_job_title','subject_name']).resume_id.agg(['sum','max']).reset_index()\\\n",
    "    .sort_values(by=['cleaned_job_title','sum','max'],ascending=False)\\\n",
    "    .to_csv(directory+'04_ranked_subjects.csv',index=False)\n",
    "    \n",
    "final_combined_data = final_combined_data.groupby(['cleaned_job_title','final_degree_category','subject_name'])\\\n",
    "    .resume_id.sum().unstack('subject_name')\n",
    "final_combined_data = final_combined_data.reset_index()\n",
    "\n",
    "# Save data records\n",
    "with open(directory+'04_edu_data_bar_chart.json', 'w') as outfile: \n",
    "    json.dump([row.dropna().to_dict() for index,row in final_combined_data.iterrows()],outfile)\n",
    "    \n",
    "# Save distinct list of jobs\n",
    "unique_jobs = pd.DataFrame(final_combined_data.cleaned_job_title.unique())\\\n",
    "    .rename(index=str, columns={0:'cleaned_job_title'})\\\n",
    "    .sort_values(by='cleaned_job_title')\n",
    "unique_jobs.to_csv(directory+'04_unique_jobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
