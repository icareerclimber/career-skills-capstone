{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Naive Bayes classifier using TD-IDF vectorizer and pickle results. This model can be \n",
    "# trained on job resumes or Indeed job postings. Steps include:\n",
    "# 1. Set the model parameters\n",
    "# 2. Getting a combined list of salaries and only using job titles with 500+ salary records\n",
    "# 3. Getting a list of resumes using this list of job titles and remove any job titles with \n",
    "#    less than 500 resumes\n",
    "# 4. Run TD-IDF vectorizer and Naive Bayes model training\n",
    "# 5. Test the model using \"List Most Relevant Skills\"\n",
    "# 6. Test the model using \"Document Similarity Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functions.word_preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import datetime\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "                \"doc_type\":\"indeed_resume\", # Use \"indeed_resume\" or \"indeed_postings\"\n",
    "                \"min_salary_records\":500, # Filter out all jobs with less than specified salary records\n",
    "                \"min_job_summaries\":500, # Filter out all jobs with less than specified job summaries\n",
    "                \"min_ngram\":2, # For TD-IDF vectorizer\n",
    "                \"max_ngram\":4, # For TD-IDF vectorizer\n",
    "                \"min_df\":0, # For TD-IDF vectorizer, ignore features in less than this number of documents\n",
    "                \"train_test_split\":0.05, # For train-test split\n",
    "                \"random_state\":1, # For train-test split\n",
    "                \"alpha\":0.1, # For Naive Bayes model\n",
    "                \"num_skills\":50, # Number of skill to show per job \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Salary Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the both salary datasets\n",
    "salary1 = pd.read_csv(directory+'02_h1b_salaries_CLEAN.csv')\n",
    "salary2 = pd.read_csv(directory+'02_greencard_salaries_CLEAN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine salary datasets\n",
    "temp_salary1 = salary1[['city','state','start_year','cleaned_job_title','experiences','salary']]\n",
    "temp_salary2 = salary2[['city','state','decision_year','cleaned_job_title','experiences','salary_amount']]\n",
    "temp_salary1.columns = ['city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "temp_salary2.columns = ['city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "combined_salaries = temp_salary1.append(temp_salary2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 500+ salary records: 275\n"
     ]
    }
   ],
   "source": [
    "# Choose all jobs with 500 or more records\n",
    "temp = combined_salaries.groupby(['cleaned_job_title']).count().salary.reset_index()\n",
    "jobs_to_model = temp[temp.salary >= 500]\n",
    "print(\"Number of jobs with 500+ salary records:\", jobs_to_model.cleaned_job_title.count())\n",
    "\n",
    "# combined_salaries.groupby(['cleaned_job_title'])\\\n",
    "# .salary.agg(['count','mean','min','max','median','std']).to_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Job Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load resume data\n",
    "if parameters['doc_type'] == 'indeed_resume':\n",
    "    data = pd.read_csv(directory+'02_processed_resumes_work_CLEAN.csv')\n",
    "if parameters['doc_type'] == 'indeed_postings':\n",
    "    data = pd.read_csv(directory+'02_indeed_job_postings_CLEAN.csv')\n",
    "\n",
    "# Remove all null cleaned_job_title records\n",
    "jobs_descriptions = data[~data.cleaned_job_title.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only jobs specified by the jobs_to_model list\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title.isin(jobs_to_model.cleaned_job_title)]\n",
    "\n",
    "# Get job title and job summary\n",
    "if parameters['doc_type'] == 'indeed_resume':\n",
    "    jobs_descriptions = jobs_descriptions[['cleaned_job_title','descript']]\n",
    "if parameters['doc_type'] == 'indeed_postings':\n",
    "    jobs_descriptions = jobs_descriptions[['cleaned_job_title','summary_text']]\n",
    "\n",
    "jobs_descriptions.columns = ['cleaned_job_title','summary']\n",
    "jobs_descriptions = jobs_descriptions.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of resume entries available: 252678/1215292\n"
     ]
    }
   ],
   "source": [
    "# Print the number of records left after removing irrelevant jobs\n",
    "print(\"Number of resume entries available:\", \n",
    "      str(jobs_descriptions.cleaned_job_title.count()) +\"/\"+\n",
    "      str(data.cleaned_job_title.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 500+ resume entries: 90\n",
      "Number of resume entries available now: 235496\n"
     ]
    }
   ],
   "source": [
    "# Remove all jobs without 500 or more resume entries\n",
    "cnt_resumes_available = jobs_descriptions.groupby('cleaned_job_title')\\\n",
    "                                .count().reset_index()\n",
    "cnt_resumes_available = list(cnt_resumes_available[cnt_resumes_available.summary>500]\\\n",
    "                                .cleaned_job_title)\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title\\\n",
    "                       .isin(cnt_resumes_available)]\n",
    "\n",
    "print(\"Number of jobs with 500+ resume entries:\", len(cnt_resumes_available))\n",
    "print(\"Number of resume entries available now:\", jobs_descriptions.cleaned_job_title.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Job Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we add a spell checker somehow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functions.word_preprocessing\n",
    "x_data = preprocess_list(jobs_descriptions.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels using cleaned_job_title\n",
    "y_labels = jobs_descriptions.cleaned_job_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, \n",
    "                                                    y_labels,\n",
    "                                                    test_size=parameters['train_test_split'],\n",
    "                                                    random_state=parameters['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2018-07-03 18:15:57.234151\n",
      "End: 2018-07-03 18:44:17.999290\n",
      "Vocabulary len: 35083980\n"
     ]
    }
   ],
   "source": [
    "print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# Train TF-IDF vectorizer model\n",
    "vect = TfidfVectorizer(min_df=parameters['min_df'], \n",
    "                       ngram_range=(parameters['min_ngram'], parameters['max_ngram'])\n",
    "                      ).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "print(\"End:\", datetime.datetime.now())\n",
    "\n",
    "print('Vocabulary len:', len(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multinomial Naive Bayes model\n",
    "model = MultinomialNB(alpha=parameters['alpha'])\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred = model.predict(vect.transform(X_test))\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = pd.DataFrame(list(zip(y_test, y_pred)))\n",
    "# predictions.columns=['actual','prediction']\n",
    "# predictions['count']=1\n",
    "# predictions.groupby(['actual','prediction']).count().reset_index().to_csv('most_confusion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Most Relevant Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code finds the top parameters['num_skills'] of features to show the user. It filters out any \n",
    "# ngram where the same n-1 version of the ngram is shown. This cuts down on repetition.\n",
    "\n",
    "label_id = 61\n",
    "\n",
    "print(model.classes_[label_id])\n",
    "print('-------')\n",
    "\n",
    "features_list = []\n",
    "topn_class1 = sorted(zip(model.coef_[label_id], vect.get_feature_names()))[-parameters['num_skills']:]\n",
    "for coef, feat in topn_class1:\n",
    "    features_list.append(feat)\n",
    "\n",
    "accepted_skill_list = ['none']\n",
    "for potential_skill in sorted(features_list, key=lambda x: -len(x.split())):\n",
    "    highest_match = len(potential_skill.split())\n",
    "    for accepted_skill in accepted_skill_list:\n",
    "        leftovers = list(set(potential_skill.split()) - set(accepted_skill.split()))\n",
    "        if len(leftovers) < highest_match:\n",
    "            highest_match = len(leftovers)\n",
    "    if highest_match > 1:\n",
    "        accepted_skill_list.append(potential_skill)\n",
    "accepted_skill_list = accepted_skill_list[1:]\n",
    "shuffle(accepted_skill_list)\n",
    "\n",
    "for skill in accepted_skill_list:\n",
    "    print(skill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code returns the prediction probabilities for an example input\n",
    "\n",
    "example_index = 11\n",
    "print(y_test[example_index:example_index+1])\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "print(X_test[example_index])\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "vector_example = vect.transform(preprocess_list([X_test[example_index]]))\n",
    "job_rankings = list(zip(model.predict_proba(vector_example)[0],model.classes_))\n",
    "sorted(job_rankings,reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves the model to the models folder\n",
    "\n",
    "save_time = re.sub('[^A-Za-z0-9]+', '', str(datetime.datetime.now()))\n",
    "print(save_time)\n",
    "\n",
    "write_param = open(\"models/\" + save_time + '_parameters.txt','w')\n",
    "for key in parameters:\n",
    "    write_param.write(key + \"=\" + str(parameters[key]) + '\\n')\n",
    "write_param.close()\n",
    "\n",
    "# Save preprocessed x data\n",
    "pickling_on = open(\"models/\"+save_time+\"_x_data.pkl\",\"wb\")\n",
    "pickle.dump(x_data, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save preprocessed y labels\n",
    "pickling_on = open(\"models/\"+save_time+\"_y_labels.pkl\",\"wb\")\n",
    "pickle.dump(y_labels, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save TD-IDF vectorizer\n",
    "pickling_on = open(\"models/\"+save_time+\"_tdidf_vect.pkl\",\"wb\")\n",
    "pickle.dump(vect, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save vectorized x_train\n",
    "pickling_on = open(\"models/\"+save_time+\"_x_trained_tdidf_vect.pkl\",\"wb\")\n",
    "pickle.dump(X_train_vectorized, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save NB model\n",
    "pickling_on = open(\"models/\"+save_time+\"_nb_model.pkl\",\"wb\")\n",
    "pickle.dump(model, pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code loads an old model\n",
    "\n",
    "save_time = '20180703161959266229'\n",
    "\n",
    "pickling_on = open(\"models/\"+save_time+\"_x_data.pkl\",\"rb\")\n",
    "x_data = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save preprocessed y labels\n",
    "pickling_on = open(\"models/\"+save_time+\"_y_labels.pkl\",\"rb\")\n",
    "y_labels = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save TD-IDF vectorizer\n",
    "pickling_on = open(\"models/\"+save_time+\"_tdidf_vect.pkl\",\"rb\")\n",
    "vect = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save vectorized x_train\n",
    "pickling_on = open(\"models/\"+save_time+\"_x_trained_tdidf_vect.pkl\",\"rb\")\n",
    "X_train_vectorized = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save NB model\n",
    "pickling_on = open(\"models/\"+save_time+\"_nb_model.pkl\",\"rb\")\n",
    "model = pickle.load(pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely I will need to train with a 1-5 ngram model and then return skills\n",
    "based on a 3-4 ngram model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
