{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of relevant resume ids from 03_create_ngram_model\n",
    "relevant_resume_ids = pd.read_csv(directory+'03_relevant_resume_ids.csv')\n",
    "relevant_resume_ids.columns = ['resume_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_job_titles = pd.read_csv(directory+'02_resumes_work.csv')\n",
    "current_job_titles = current_job_titles\\\n",
    "    [current_job_titles.resume_id.isin(relevant_resume_ids.resume_id)]\\\n",
    "    [['resume_id','cleaned_job_title','from_year','to_year']]\\\n",
    "    .sort_values(by='from_year')\n",
    "    \n",
    "current_job_titles = current_job_titles.sort_values(by=['resume_id','from_year','to_year'])\\\n",
    "    .rename(columns={'cleaned_job_title': 'curr_cleaned_job_title'})\n",
    "current_job_titles['next_cleaned_job_title'] = current_job_titles.groupby('resume_id')\\\n",
    "['curr_cleaned_job_title'].shift(-1).fillna(\"None\")\n",
    "\n",
    "nodes = pd.DataFrame(current_job_titles.curr_cleaned_job_title.unique()).reset_index()\n",
    "nodes.columns = ['index_num','name']\n",
    "\n",
    "current_job_titles = current_job_titles\\\n",
    "    [current_job_titles.curr_cleaned_job_title != current_job_titles.next_cleaned_job_title]\n",
    "current_job_titles = current_job_titles\\\n",
    "    [current_job_titles.next_cleaned_job_title != 'None']\n",
    "    \n",
    "current_job_titles = current_job_titles\\\n",
    "    [['resume_id','curr_cleaned_job_title','next_cleaned_job_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_jobs = current_job_titles\\\n",
    "    .groupby(['curr_cleaned_job_title','next_cleaned_job_title'])\\\n",
    "    .resume_id.count().reset_index()\n",
    "\n",
    "grouped_jobs = pd.merge(left=grouped_jobs,right=nodes, left_on='curr_cleaned_job_title', right_on='name')\n",
    "del grouped_jobs['name']\n",
    "grouped_jobs.columns = ['curr_cleaned_job_title','next_cleaned_job_title','value','source']\n",
    "grouped_jobs = pd.merge(left=grouped_jobs,right=nodes, left_on='next_cleaned_job_title', right_on='name')\n",
    "del grouped_jobs['name']\n",
    "grouped_jobs.columns = ['curr_cleaned_job_title','next_cleaned_job_title','value','source','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del nodes['index_num']\n",
    "links = grouped_jobs[['source','target','value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_json = nodes.to_json(orient='records')\n",
    "links_json = links.to_json(orient='records')\n",
    "\n",
    "final = { '\"nodes\"' : nodes_json, '\"links\"' : links_json }\n",
    "with open(directory+'06_job_sankey_data.json', 'w') as outfile:\n",
    "    outfile.write(str(final).replace(\"\\\\\",\"\").replace(\"'\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
