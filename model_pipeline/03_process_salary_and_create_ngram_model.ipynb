{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Naive Bayes classifier using TD-IDF vectorizer and pickle results. This model can be \n",
    "# trained on job resumes or Indeed job postings. Steps include:\n",
    "# 1. Set the model parameters\n",
    "# 2. Getting a combined list of salaries and only using job titles with 500+ salary records\n",
    "# 3. Getting a list of resumes using this list of job titles and remove any job titles with \n",
    "#    less than 500 resumes\n",
    "# 4. Run TD-IDF vectorizer and Naive Bayes model training\n",
    "# 5. Test the model using \"List Most Relevant Skills\"\n",
    "# 6. Test the model using \"Document Similarity Score\"\n",
    "\n",
    "\n",
    "# We are only looking at the most recent 5 years of salary\n",
    "# We are only looking at the mode recent 10 years of work start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "\n",
    "# Custom function in functions folder\n",
    "from functions.word_preprocessing import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'\n",
    "# directory = '/mnt/disks/mnt_dir/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters for doc similarity\n",
    "parameters = {\n",
    "                \"doc_type\":\"indeed_resume\", # Use \"indeed_resume\" or \"indeed_postings\"\n",
    "                \"min_salary_year\":2014, # Filter out all salaries older than specified number\n",
    "                \"min_job_year\":2008, # Filter out all resume jobs older than specified number\n",
    "                \"min_salary_records\":100, # Filter out all jobs with less than specified salary records\n",
    "                \"min_job_summaries\":1000, # Filter out all jobs with less than specified job summaries\n",
    "                \"min_ngram\":1, # For TD-IDF vectorizer\n",
    "                \"max_ngram\":3, # For TD-IDF vectorizer\n",
    "                \"min_df\":5, # For TD-IDF vectorizer, ignore features in less than this number of documents\n",
    "                \"train_test_split\":0.05, # For train-test split\n",
    "                \"random_state\":1, # For train-test split\n",
    "                \"alpha\":0.02, # For Naive Bayes model 0.02 is current best\n",
    "                \"num_skills\":50, # Number of skill to show per job \n",
    "                \"max_number_records\":2500, # Number of records in each class, SMOTE is used to fill small classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best parameters for skills\n",
    "\n",
    "# parameters = {\n",
    "#                 \"doc_type\":\"indeed_resume\", # Use \"indeed_resume\" or \"indeed_postings\"\n",
    "#                 \"min_salary_year\":2014, # Filter out all salaries older than specified number\n",
    "#                 \"min_job_year\":2008, # Filter out all resume jobs older than specified number\n",
    "#                 \"min_salary_records\":100, # Filter out all jobs with less than specified salary records\n",
    "#                 \"min_job_summaries\":1000, # Filter out all jobs with less than specified job summaries\n",
    "#                 \"min_ngram\":3, # For TD-IDF vectorizer\n",
    "#                 \"max_ngram\":3, # For TD-IDF vectorizer\n",
    "#                 \"min_df\":5, # For TD-IDF vectorizer, ignore features in less than this number of documents\n",
    "#                 \"train_test_split\":0.05, # For train-test split\n",
    "#                 \"random_state\":1, # For train-test split\n",
    "#                 \"alpha\":0.02, # For Naive Bayes model 0.02 is current best\n",
    "#                 \"num_skills\":100, # Number of skill to show per job \n",
    "#                 \"max_number_records\":5000, # Number of records in each class, SMOTE is used to fill small classes\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Salary Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both salary datasets\n",
    "salary1 = pd.read_csv(directory+'02_salaries_h1b.csv')\n",
    "salary2 = pd.read_csv(directory+'02_salaries_greencard.csv')\n",
    "\n",
    "# Combine salary datasets\n",
    "temp_salary1 = salary1[['role','city','state','start_year','cleaned_job_title','experiences','salary']]\n",
    "temp_salary2 = salary2[['job_title','city','state','decision_year','cleaned_job_title','experiences','salary_amount']]\n",
    "temp_salary1.columns = ['original_role','city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "temp_salary2.columns = ['original_role','city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "combined_salaries = temp_salary1.append(temp_salary2)\n",
    "\n",
    "# Remove salaries with null value and convert to int\n",
    "combined_salaries = combined_salaries[~combined_salaries.salary.isnull()]\n",
    "combined_salaries.salary = combined_salaries.salary.astype(int)\n",
    "\n",
    "# Fill any NaN fields with no_value and convert each column into a list\n",
    "combined_salaries = combined_salaries.fillna('no_value')\n",
    "combined_salaries.experiences = combined_salaries.experiences.apply(lambda x: \n",
    "                                                list([item.strip() for item in x.split(',')]))\n",
    "combined_salaries.original_role = combined_salaries.original_role.apply(lambda x: [x])\n",
    "combined_salaries.city = combined_salaries.city.apply(lambda x: [x])\n",
    "combined_salaries.state = combined_salaries.state.apply(lambda x: [x])\n",
    "combined_salaries.start_year = combined_salaries.start_year.apply(lambda x: [x])\n",
    "combined_salaries.cleaned_job_title = combined_salaries.cleaned_job_title.apply(lambda x: [x])\n",
    "combined_salaries.salary = combined_salaries.salary.apply(lambda x: [x])\n",
    "\n",
    "# Perform a pivot on the columns to split out rows with multiple experience level qualifiers\n",
    "combined_salaries = pd.DataFrame([j for i in combined_salaries.values for j in product(*i)],\n",
    "                                      columns = combined_salaries.columns)\n",
    "\n",
    "# Only look at jobs in the past 5 years\n",
    "combined_salaries = combined_salaries[combined_salaries.start_year >= parameters['min_salary_year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 100+ salary records: 732\n"
     ]
    }
   ],
   "source": [
    "# Choose all jobs with `min_salary_records` or more records\n",
    "temp = combined_salaries.groupby('cleaned_job_title').count().salary.reset_index()\n",
    "jobs_to_model = temp[temp.salary >= parameters['min_salary_records']]\n",
    "combined_salaries = combined_salaries[combined_salaries.cleaned_job_title\\\n",
    "                                                       .fillna('').isin(jobs_to_model.cleaned_job_title)]\n",
    "print(\"Number of jobs with \"+str(parameters['min_salary_records'])+\"+ salary records:\", jobs_to_model.cleaned_job_title.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Job Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load resume data\n",
    "if parameters['doc_type'] == 'indeed_resume':\n",
    "    data = pd.read_csv(directory+'02_resumes_work.csv')\n",
    "    data.rename(columns = {'descript':'summary_text'}, inplace=True)\n",
    "if parameters['doc_type'] == 'indeed_postings':\n",
    "    data = pd.read_csv(directory+'02_job_posts_indeed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 1000+ resume entries: 114\n",
      "Number of resume entries available: 497928\n"
     ]
    }
   ],
   "source": [
    "# Remove all null cleaned_job_title records\n",
    "jobs_descriptions = data[~data.cleaned_job_title.isnull()]\n",
    "\n",
    "# Remove all jobs older than 10 years\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.from_year >= parameters['min_job_year']]\n",
    "\n",
    "# Drop insignificant job names\n",
    "jobs_to_remove = ['technical','team','test','project']\n",
    "jobs_descriptions = jobs_descriptions[~jobs_descriptions.cleaned_job_title.isin(jobs_to_remove)] \n",
    "\n",
    "# Filter to only jobs specified by the jobs_to_model list\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title\\\n",
    "                                      .isin(jobs_to_model.cleaned_job_title)]\n",
    "    \n",
    "# Remove all jobs without `min_job_summaries` or more resume entries\n",
    "cnt_resumes_available = jobs_descriptions.groupby('cleaned_job_title')\\\n",
    "                                .count().reset_index()\n",
    "cnt_resumes_available = list(cnt_resumes_available[\n",
    "            cnt_resumes_available.summary_text>parameters['min_job_summaries']].cleaned_job_title)\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title\\\n",
    "                       .isin(cnt_resumes_available)]\n",
    "\n",
    "# Remove duplicate data\n",
    "jobs_descriptions = jobs_descriptions.groupby(['cleaned_job_title','summary_text','from_year'])\\\n",
    "        .resume_id.first().reset_index()\n",
    "\n",
    "print(\"Number of jobs with \"+str(parameters['min_job_summaries'])+\"+ resume entries:\", len(cnt_resumes_available))\n",
    "print(\"Number of resume entries available:\", jobs_descriptions.cleaned_job_title.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleaned_job_title    234714\n",
       "summary_text         234714\n",
       "from_year            234714\n",
       "resume_id            234714\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code samples the number of records to remove excessive numbers\n",
    "new_job_descriptions = pd.DataFrame()\n",
    "for name, group in jobs_descriptions.groupby('cleaned_job_title'):\n",
    "    if group[group.from_year == 2016].cleaned_job_title.count() >= parameters['max_number_records']:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group[group.from_year < 2017]\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "    elif group[(group.from_year == 2016) | (group.from_year == 2017)].cleaned_job_title.count() >= parameters['max_number_records']:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group[group.from_year < 2018]\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "    else:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "\n",
    "new_job_descriptions.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data for Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save off list of resume ids\n",
    "if parameters['doc_type'] == 'indeed_resume':\n",
    "    # Save the list of resume ids for resumes being used\n",
    "    pd.DataFrame(new_job_descriptions.resume_id.unique())\\\n",
    "                .to_csv(directory+'03_relevant_resume_ids.csv',index=False)\n",
    "\n",
    "# Save off list of relevant job titles\n",
    "relevant_job_titles = pd.DataFrame(new_job_descriptions.cleaned_job_title.unique())\n",
    "relevant_job_titles.columns = ['cleaned_job_title']\n",
    "relevant_job_titles.to_csv(directory+'03_relevant_job_titles.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves the cleaned salary information back to the main data folder\n",
    "combined_salaries.to_csv(directory+'03_cleaned_salaries_for_app.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = new_job_descriptions.summary_text\n",
    "y_labels = new_job_descriptions.cleaned_job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, \n",
    "                                                    y_labels,\n",
    "                                                    test_size=parameters['train_test_split'],\n",
    "                                                    random_state=parameters['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 222978\n",
      "y_train:  222978\n",
      "X_test:  11736\n",
      "y_test:  11736\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\",len(X_train))\n",
    "print(\"y_train: \",len(y_train))\n",
    "print(\"X_test: \",len(X_test))\n",
    "print(\"y_test: \",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_job_descriptions.cleaned_job_title.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# x_data = new_job_descriptions.summary_text\n",
    "# y_labels = new_job_descriptions.cleaned_job_title\n",
    "\n",
    "# x_data = preprocess_list(new_job_descriptions.summary_text)\n",
    "# print(\"Done with preprocess\")\n",
    "\n",
    "# # create a count vectorizer object \n",
    "# count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "# count_vectorized_X_train = count_vect.fit_transform(X_train)\n",
    "\n",
    "# sm = SMOTE(kind='regular')\n",
    "# count_vect_X_res, count_vect_y_res = sm.fit_sample(count_vectorized_X_train, y_train)\n",
    "\n",
    "# # transform the training and validation data using count vectorizer object\n",
    "# # xtrain_count =  count_vect.transform(train_x)\n",
    "# count_vectorized_X_test =  count_vect.transform(X_test)\n",
    "\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# x_data = new_job_descriptions.summary_text\n",
    "# y_labels = new_job_descriptions.cleaned_job_title\n",
    "\n",
    "# x_data = preprocess_list(new_job_descriptions.summary_text)\n",
    "# print(\"Done with preprocess\")\n",
    "\n",
    "# # Split the data into test and train datasets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x_data, \n",
    "#                                                     y_labels,\n",
    "#                                                     test_size=parameters['train_test_split'],\n",
    "#                                                     random_state=parameters['random_state'])\n",
    "\n",
    "# # Train TF-IDF vectorizer model\n",
    "# vect = TfidfVectorizer(min_df=parameters['min_df'], \n",
    "#                        ngram_range=(parameters['min_ngram'], parameters['max_ngram'])\n",
    "#                       ).fit(X_train)\n",
    "# X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "# print(\"Done with TD-IDF\")\n",
    "\n",
    "# print('Vocabulary len:', len(vect.get_feature_names()))\n",
    "\n",
    "# sm = SMOTE(kind='regular')\n",
    "# X_res, y_res = sm.fit_sample(X_train_vectorized, y_train)\n",
    "\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickling_on = open(directory+\"models/dev_X_test.pkl\",\"wb\")\n",
    "# # pickle.dump(X_test, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/dev_y_test.pkl\",\"wb\")\n",
    "# # pickle.dump(y_test, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/dev_x_SMOTE_data.pkl\",\"wb\")\n",
    "# # pickle.dump(X_res, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/dev_y_SMOTE_data.pkl\",\"wb\")\n",
    "# # pickle.dump(y_res, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/vect.pkl\",\"wb\")\n",
    "# # pickle.dump(vect, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_X_test.pkl\",\"rb\")\n",
    "# X_test = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_y_test.pkl\",\"rb\")\n",
    "# y_test = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_x_SMOTE_data.pkl\",\"rb\")\n",
    "# X_res = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_y_SMOTE_data.pkl\",\"rb\")\n",
    "# y_res = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/vect.pkl\",\"rb\")\n",
    "# vect = pickle.load(pickling_on)\n",
    "# pickling_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_model = MultinomialNB(alpha=0.02)\n",
    "# nb_model.fit(X_res, y_res)\n",
    "\n",
    "# y_pred = nb_model.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# # Accuracy: 35.83% .012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# svm_model = SGDClassifier(loss='hinge', penalty='l2', alpha=.0008, n_iter=3, random_state=42)\n",
    "\n",
    "# svm_model.fit(X_res, y_res)\n",
    "\n",
    "# y_pred = svm_model.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# print(\"End:\", datetime.datetime.now())\n",
    "# # Accuracy: 47.21% alpha=.0008, n_iter=3\n",
    "# # Count Vectorizer Accuracy: 40.81% .0008 n_iter=3\n",
    "# # Accuracy: 41.42% .001 5\n",
    "# # Accuracy: 41.41% .009 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# eclf1 = VotingClassifier(estimators=[\n",
    "#             ('nb', nb_model), ('svm', svm_model)], voting='hard')\n",
    "# eclf2 = VotingClassifier(estimators=[\n",
    "#             ('nb', nb_model), ('svm', svm_model)], voting='soft')\n",
    "# # eclf3 = VotingClassifier(estimators=[\n",
    "# #             ('nb', nb_model), ('svm', svm_model)], voting='soft', weights=[1,1,2], flatten_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "# eclf1.fit(X_res, y_res)\n",
    "# y_pred = eclf1.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "# eclf2.fit(X_res, y_res)\n",
    "# y_pred = eclf2.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# # from sklearn.decomposition import PCA\n",
    "# # from sklearn.pipeline import Pipeline\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# # pca = PCA(n_components=152).fit(X_res)\n",
    "# # data2D = pca.transform(X_res)\n",
    "# # plt.scatter(data2D[:,0], data2D[:,1], c=data.target)\n",
    "# # plt.show()              #not required if using ipython notebook\n",
    "\n",
    "\n",
    "# # Load libraries\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# from scipy.sparse import csr_matrix\n",
    "# from sklearn import datasets\n",
    "# import numpy as np\n",
    "\n",
    "# tsvd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# X_sparse_tsvd = tsvd.fit_transform(X_res)\n",
    "\n",
    "# # # Show results\n",
    "# print('Original number of features:', X_res.shape[1])\n",
    "# print('Reduced number of features:', X_sparse_tsvd.shape[1])\n",
    "# # Original number of features: 64\n",
    "# # Reduced number of features: 10\n",
    "# # View Percent Of Variance Explained By New Features\n",
    "# # # Sum of first three components' explained variance ratios\n",
    "# # tsvd.explained_variance_ratio_[0:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_matrix = X_res.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_remove_index = []\n",
    "# # filevector = open('docvectors.txt', 'w')\n",
    "# vector_list = []\n",
    "# meta_list = []\n",
    "# meta_list = list(y_res)\n",
    "# # filemeta = open('docmeta.txt', 'w')\n",
    "# # edu_filemeta.write(\"%s\\n\" % 'title')\n",
    "\n",
    "# for index in range(X_res.shape[0]):\n",
    "#     cleaned_vectors = '\\t'.join(str(vector) for vector in X_sparse_tsvd[index])\n",
    "#     if not cleaned_vectors or cleaned_vectors == '':\n",
    "#         print(index)\n",
    "#         list_of_remove_index.append(index)\n",
    "#         continue\n",
    "#     vector_list.append(cleaned_vectors)\n",
    "# #     filevector.write(\"%s\\n\" % cleaned_vectors)\n",
    "# #     cleaned_meta = (str(index) + ' ' + ' '.join(traindocs[index].words))\n",
    "# #     if index >= 94999:\n",
    "# #         print(index)\n",
    "# #     if not cleaned_meta:\n",
    "# #         print(\"issue with meta\")\n",
    "# #         print(index)\n",
    "# #     filemeta.write(\"%s\\n\" %cleaned_meta )\n",
    "# #     meta_list.append(cleaned_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(X_sparse_tsvd).to_csv('teest.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(vector_list))\n",
    "# print(X_sparse_tsvd.shape)\n",
    "# print(len(meta_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len(vector_list)\n",
    "# # len(meta_list)\n",
    "# filevector = open('docvectors.txt', 'w')\n",
    "# filemeta = open('docmeta.txt', 'w')\n",
    "# for row in vector_list:\n",
    "#     filevector.write(\"%s\\n\" % row)\n",
    "# for row in meta_list:\n",
    "#     filemeta.write(\"%s\\n\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# conf_mat = confusion_matrix(y_test, y_pred)\n",
    "# fig, ax = plt.subplots(figsize=(50,50))\n",
    "# sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Greys',\n",
    "#             xticklabels=nb_model.classes_, yticklabels=nb_model.classes_)\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = FunctionTransformer(preprocess_list)\n",
    "smt = SMOTE()\n",
    "tfidf = TfidfVectorizer(min_df=parameters['min_df'], ngram_range=(parameters['min_ngram'], parameters['max_ngram']))\n",
    "nb = MultinomialNB(alpha=parameters['alpha'])\n",
    "preprocess = FunctionTransformer(preprocess_list, validate=False)\n",
    "\n",
    "pipeline = Pipeline([('preprocess', preprocess), ('tfidf', tfidf), ('smt', smt), ('nb', nb)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 222978\n",
      "y_train: 222978\n",
      "Start: 2018-08-03 15:59:05.564573\n",
      "End: 2018-08-03 16:14:46.156899\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', len(X_train))\n",
    "print('y_train:', len(y_train))\n",
    "\n",
    "print(\"Start:\", datetime.datetime.now())\n",
    "pipeline.fit(X_train,y_train)\n",
    "print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# Accuracy: 44.81% for doc similarity\n",
    "# Accuracy: 35.53% for skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.463566473445\n",
      "precision_score:  0.478324534188\n",
      "recall_score:  0.477572484021\n"
     ]
    }
   ],
   "source": [
    "print('f1_score: ', f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print('precision_score: ', precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print('recall_score: ', recall_score(y_test, y_pred, average=\"macro\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>android engineer</td>\n",
       "      <td>89.06%</td>\n",
       "      <td>93.44%</td>\n",
       "      <td>91.20%</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ios engineer</td>\n",
       "      <td>87.76%</td>\n",
       "      <td>82.69%</td>\n",
       "      <td>85.15%</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>technical recruiter</td>\n",
       "      <td>77.05%</td>\n",
       "      <td>94.95%</td>\n",
       "      <td>85.07%</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>build and release engineer</td>\n",
       "      <td>82.09%</td>\n",
       "      <td>83.97%</td>\n",
       "      <td>83.02%</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>linux administrator</td>\n",
       "      <td>81.51%</td>\n",
       "      <td>83.80%</td>\n",
       "      <td>82.64%</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          class precision  recall  fscore  support\n",
       "7              android engineer    89.06%  93.44%  91.20%       61\n",
       "51                 ios engineer    87.76%  82.69%  85.15%       52\n",
       "108         technical recruiter    77.05%  94.95%  85.07%       99\n",
       "17   build and release engineer    82.09%  83.97%  83.02%      131\n",
       "58          linux administrator    81.51%  83.80%  82.64%      142"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(y_test, y_pred)\n",
    "'{:.1%}'.format(1/3.0)\n",
    "\n",
    "metrics = pd.DataFrame(list(zip(pipeline.classes_, precision, recall, fscore, support)))\n",
    "metrics.columns = ['class','precision', 'recall', 'fscore', 'support']\n",
    "metrics_samples = metrics.sort_values(by='fscore',ascending=False).head(5)\n",
    "metrics_samples.precision = metrics_samples.precision.map(lambda x: '{:.2%}'.format(x))\n",
    "metrics_samples.recall = metrics_samples.recall.map(lambda x: '{:.2%}'.format(x))\n",
    "metrics_samples.fscore = metrics_samples.fscore.map(lambda x: '{:.2%}'.format(x))\n",
    "metrics_samples.sort_values(by='fscore',ascending=True).to_csv('temp.csv')\n",
    "metrics_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# counted = collections.Counter(y_test)\n",
    "\n",
    "# from operator import itemgetter\n",
    "# import heapq\n",
    "# import collections\n",
    "# def least_common_values(array, to_find=None):\n",
    "#     counter = collections.Counter(array)\n",
    "#     if to_find is None:\n",
    "#         return sorted(counter.items(), key=itemgetter(1), reverse=False)\n",
    "#     return heapq.nsmallest(to_find, counter.items(), key=itemgetter(1))\n",
    "\n",
    "# # counted.most_common()\n",
    "# least_common_values(counted, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>accountant</td>\n",
       "      <td>staff accountant</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>marketing director</td>\n",
       "      <td>marketing manager</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>java software engineer</td>\n",
       "      <td>j2ee engineer</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>network administrator</td>\n",
       "      <td>network engineer</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>manager</td>\n",
       "      <td>general manager</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>associate</td>\n",
       "      <td>cashier</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>design engineer</td>\n",
       "      <td>mechanical design engineer</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>human resources specialist</td>\n",
       "      <td>human resources manager</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>project manager</td>\n",
       "      <td>it project manager</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>assistant</td>\n",
       "      <td>administrative assistant</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          actual                  prediction  count\n",
       "73                    accountant            staff accountant     38\n",
       "1214          marketing director           marketing manager     34\n",
       "1140      java software engineer               j2ee engineer     32\n",
       "1286       network administrator            network engineer     30\n",
       "1177                     manager             general manager     30\n",
       "329                    associate                     cashier     30\n",
       "742              design engineer  mechanical design engineer     27\n",
       "1012  human resources specialist     human resources manager     27\n",
       "1594             project manager          it project manager     26\n",
       "250                    assistant    administrative assistant     26"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the test population, get the most confused labels\n",
    "\n",
    "# pd.options.display.max_rows = 10000\n",
    "predictions = pd.DataFrame(list(zip(y_test, y_pred)))\n",
    "predictions.columns=['actual','prediction']\n",
    "predictions['count']=1\n",
    "pred_group = predictions.groupby(['actual','prediction']).count().reset_index()\n",
    "pred_group[(pred_group.actual != pred_group.prediction) \n",
    "           & (pred_group.prediction!='account executive')\n",
    "          ].sort_values(by='count',ascending=False).head(10)\n",
    "# .to_csv('most_confusion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Most Relevant Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data scientist\n",
      "-------\n",
      "0 using python\n",
      "1 predictive model\n",
      "2 random forest\n",
      "3 neural network\n",
      "4 machine learning algorithm\n"
     ]
    }
   ],
   "source": [
    "# This code finds the top parameters['num_skills'] of features to show the user. It filters out any \n",
    "# ngram where the same n-1 version of the ngram is shown. This cuts down on repetition.\n",
    "\n",
    "label_id = 33\n",
    "\n",
    "print(pipeline.classes_[label_id])\n",
    "print('-------')\n",
    "\n",
    "features_list = []\n",
    "topn_class1 = sorted(zip(pipeline.named_steps['nb'].coef_[label_id], \n",
    "                         pipeline.named_steps['tfidf'].get_feature_names()))[-parameters['num_skills']:]\n",
    "for coef, feat in topn_class1:\n",
    "    features_list.append(feat)\n",
    "\n",
    "accepted_skill_list = [pipeline.classes_[label_id]]\n",
    "for potential_skill in sorted(features_list, key=lambda x: -len(x.split())):\n",
    "    highest_match = len(potential_skill.split())\n",
    "    for accepted_skill in accepted_skill_list:\n",
    "        leftovers = list(set(potential_skill.split()) - set(accepted_skill.split()))\n",
    "        if len(leftovers) < highest_match:\n",
    "            highest_match = len(leftovers)\n",
    "    if highest_match > 1:\n",
    "        accepted_skill_list.append(potential_skill)\n",
    "accepted_skill_list = accepted_skill_list[1:]\n",
    "shuffle(accepted_skill_list)\n",
    "\n",
    "for index, skill in enumerate(accepted_skill_list):\n",
    "    print(index, skill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL LABEL\n",
      "301362    programmer analyst\n",
      "Name: cleaned_job_title, dtype: object\n",
      "\n",
      "---------------------\n",
      "\n",
      "INPUT\n",
      "301362    .Senior Oracle Developer .Project for DTE working on changes on the CSB application. .Project: CSB - Costumer service and Billing application .Responsibilities: .• Creating DML Scripts to insert new records into parameters and system variables tables. .• Creating packages, procedures, functions using Oracle SQL and PL/SQL .• Written and modifying Unix shell scripts to execute batch processes. .• Written and modifying SQL Scripts. .• Responsible for coding and unit testing. .• Using ClearCase...\n",
      "Name: summary_text, dtype: object\n",
      "\n",
      "---------------------\n",
      "\n",
      "OUTPUT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9978340659949313, 'data engineer'),\n",
       " (0.0014342866064529999, 'programmer analyst'),\n",
       " (0.00037762455779945302, 'database administrator'),\n",
       " (0.00017219622021523117, 'java software engineer'),\n",
       " (7.7756568109475864e-05, 'j2ee engineer'),\n",
       " (3.5517140151324498e-05, 'net engineer'),\n",
       " (1.9459374587818572e-05, 'applications engineer'),\n",
       " (1.6664879307130436e-05, 'business intelligence engineer'),\n",
       " (1.2004045572908779e-05, 'data architect'),\n",
       " (1.0195811781449465e-05, 'systems analyst'),\n",
       " (2.0803668212201924e-06, 'quality assurance tester'),\n",
       " (1.6934176259829252e-06, 'data analyst'),\n",
       " (1.2100536382277625e-06, 'technical consultant'),\n",
       " (9.4936238222760885e-07, 'engineer'),\n",
       " (8.9461394591253385e-07, 'software engineer'),\n",
       " (7.6251638392561244e-07, 'quality assurance analyst'),\n",
       " (7.1413660467824605e-07, 'software architect'),\n",
       " (4.6464338815070513e-07, 'quality assurance'),\n",
       " (4.353133243876083e-07, 'software quality engineer'),\n",
       " (2.6698230815407866e-07, 'test engineer')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code returns the prediction probabilities for an example input\n",
    "\n",
    "print(\"ACTUAL LABEL\")\n",
    "example_index = 41\n",
    "print(y_test[example_index:example_index+1])\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "print()\n",
    "print(\"INPUT\")\n",
    "example = X_test[example_index:example_index+1]\n",
    "print(example)\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "print()\n",
    "print(\"OUTPUT\")\n",
    "\n",
    "job_rankings = list(zip(pipeline.predict_proba(example)[0],pipeline.classes_))\n",
    "sorted(job_rankings,reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves the model to the models folder\n",
    "# directory = '/mnt/disks/mnt_dir/'\n",
    "\n",
    "save_time = re.sub('[^A-Za-z0-9]+', '', str(datetime.datetime.now()))\n",
    "print(save_time)\n",
    "\n",
    "write_param = open(directory+\"models/\" + save_time + '_parameters.txt','w')\n",
    "for key in parameters:\n",
    "    write_param.write(key + \"=\" + str(parameters[key]) + '\\n')\n",
    "write_param.close()\n",
    "\n",
    "# Save preprocessed x data\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_data.pkl\",\"wb\")\n",
    "pickle.dump(x_data, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save preprocessed y labels\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_y_labels.pkl\",\"wb\")\n",
    "pickle.dump(y_labels, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save NB model\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_pipeline_model.pkl\",\"wb\")\n",
    "pickle.dump(pipeline, pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator FunctionTransformer from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator NearestNeighbors from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# This code loads an old model\n",
    "# directory = '/mnt/disks/mnt_dir/'\n",
    "\n",
    "save_time = '20180724220628349336' # Currently best model for doc similarity\n",
    "# save_time = '20180725002822539809' # Currently best model for skills\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_data.pkl\",\"rb\")\n",
    "x_data = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_y_labels.pkl\",\"rb\")\n",
    "y_labels = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_pipeline_model.pkl\",\"rb\")\n",
    "pipeline = pickle.load(pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
