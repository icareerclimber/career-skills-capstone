{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Naive Bayes classifier using TD-IDF vectorizer and pickle results. This model can be \n",
    "# trained on job resumes or Indeed job postings. Steps include:\n",
    "# 1. Set the model parameters\n",
    "# 2. Getting a combined list of salaries and only using job titles with 500+ salary records\n",
    "# 3. Getting a list of resumes using this list of job titles and remove any job titles with \n",
    "#    less than 500 resumes\n",
    "# 4. Run TD-IDF vectorizer and Naive Bayes model training\n",
    "# 5. Test the model using \"List Most Relevant Skills\"\n",
    "# 6. Test the model using \"Document Similarity Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "\n",
    "# Custom function in functions folder\n",
    "from functions.word_preprocessing import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'\n",
    "directory = '/mnt/disks/mnt_dir/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Best parameters for doc similarity\n",
    "# parameters = {\n",
    "#                 \"doc_type\":\"indeed_resume\", # Use \"indeed_resume\" or \"indeed_postings\"\n",
    "#                 \"min_salary_records\":100, # Filter out all jobs with less than specified salary records\n",
    "#                 \"min_job_summaries\":1000, # Filter out all jobs with less than specified job summaries\n",
    "#                 \"min_ngram\":1, # For TD-IDF vectorizer\n",
    "#                 \"max_ngram\":3, # For TD-IDF vectorizer\n",
    "#                 \"min_df\":5, # For TD-IDF vectorizer, ignore features in less than this number of documents\n",
    "#                 \"train_test_split\":0.05, # For train-test split\n",
    "#                 \"random_state\":1, # For train-test split\n",
    "#                 \"alpha\":0.02, # For Naive Bayes model 0.02 is current best\n",
    "#                 \"num_skills\":50, # Number of skill to show per job \n",
    "#                 \"max_number_records\":2500, # Number of records in each class, SMOTE is used to fill small classes\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best parameters for skills\n",
    "\n",
    "parameters = {\n",
    "                \"doc_type\":\"indeed_resume\", # Use \"indeed_resume\" or \"indeed_postings\"\n",
    "                \"min_salary_records\":100, # Filter out all jobs with less than specified salary records\n",
    "                \"min_job_summaries\":1000, # Filter out all jobs with less than specified job summaries\n",
    "                \"min_ngram\":3, # For TD-IDF vectorizer\n",
    "                \"max_ngram\":3, # For TD-IDF vectorizer\n",
    "                \"min_df\":5, # For TD-IDF vectorizer, ignore features in less than this number of documents\n",
    "                \"train_test_split\":0.05, # For train-test split\n",
    "                \"random_state\":1, # For train-test split\n",
    "                \"alpha\":0.2, # For Naive Bayes model 0.02 is current best\n",
    "                \"num_skills\":100, # Number of skill to show per job \n",
    "                \"max_number_records\":5000, # Number of records in each class, SMOTE is used to fill small classes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Salary Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the both salary datasets\n",
    "salary1 = pd.read_csv(directory+'02_salaries_h1b.csv')\n",
    "salary2 = pd.read_csv(directory+'02_salaries_greencard.csv')\n",
    "\n",
    "# Combine salary datasets\n",
    "temp_salary1 = salary1[['role','city','state','start_year','cleaned_job_title','experiences','salary']]\n",
    "temp_salary2 = salary2[['job_title','city','state','decision_year','cleaned_job_title','experiences','salary_amount']]\n",
    "temp_salary1.columns = ['original_role','city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "temp_salary2.columns = ['original_role','city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "combined_salaries = temp_salary1.append(temp_salary2)\n",
    "\n",
    "# Remove salaries with null value and convert to int\n",
    "combined_salaries = combined_salaries[~combined_salaries.salary.isnull()]\n",
    "combined_salaries.salary = combined_salaries.salary.astype(int)\n",
    "\n",
    "# Fill any NaN fields with no_value and convert each column into a list\n",
    "combined_salaries = combined_salaries.fillna('no_value')\n",
    "combined_salaries.experiences = combined_salaries.experiences.apply(lambda x: \n",
    "                                                list([item.strip() for item in x.split(',')]))\n",
    "combined_salaries.original_role = combined_salaries.original_role.apply(lambda x: [x])\n",
    "combined_salaries.city = combined_salaries.city.apply(lambda x: [x])\n",
    "combined_salaries.state = combined_salaries.state.apply(lambda x: [x])\n",
    "combined_salaries.start_year = combined_salaries.start_year.apply(lambda x: [x])\n",
    "combined_salaries.cleaned_job_title = combined_salaries.cleaned_job_title.apply(lambda x: [x])\n",
    "combined_salaries.salary = combined_salaries.salary.apply(lambda x: [x])\n",
    "\n",
    "# Perform a pivot on the columns to split out rows with multiple experience level qualifiers\n",
    "combined_salaries = pd.DataFrame([j for i in combined_salaries.values for j in product(*i)],\n",
    "                                      columns = combined_salaries.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 100+ salary records: 867\n"
     ]
    }
   ],
   "source": [
    "# Choose all jobs with `min_salary_records` or more records\n",
    "temp = combined_salaries.groupby('cleaned_job_title').count().salary.reset_index()\n",
    "jobs_to_model = temp[temp.salary >= parameters['min_salary_records']]\n",
    "pd.DataFrame(jobs_to_model.cleaned_job_title.unique()).to_csv(directory+'03_relevant_job_titles.csv',index=False)\n",
    "combined_salaries = combined_salaries[combined_salaries.cleaned_job_title\\\n",
    "                                                       .fillna('').isin(jobs_to_model.cleaned_job_title)]\n",
    "print(\"Number of jobs with \"+str(parameters['min_salary_records'])+\"+ salary records:\", jobs_to_model.cleaned_job_title.count())\n",
    "\n",
    "# combined_salaries.groupby(['cleaned_job_title'])\\\n",
    "# .salary.agg(['count','mean','min','max','median','std']).to_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Job Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load resume data\n",
    "if parameters['doc_type'] == 'indeed_resume':\n",
    "    data = pd.read_csv(directory+'02_resumes_work.csv')\n",
    "if parameters['doc_type'] == 'indeed_postings':\n",
    "    data = pd.read_csv(directory+'02_job_posts_indeed.csv')\n",
    "\n",
    "# Remove all null cleaned_job_title records\n",
    "jobs_descriptions = data[~data.cleaned_job_title.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter to only jobs specified by the jobs_to_model list\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title\\\n",
    "                                      .isin(jobs_to_model.cleaned_job_title)]\n",
    "\n",
    "# Rename job summary field\n",
    "if parameters['doc_type'] == 'indeed_resume':\n",
    "    jobs_descriptions.rename(columns = {'descript':'summary_text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of resume entries available: 997695/3200066\n"
     ]
    }
   ],
   "source": [
    "# Print the number of records left after removing irrelevant jobs\n",
    "print(\"Number of resume entries available:\", \n",
    "      str(jobs_descriptions.cleaned_job_title.count()) +\"/\"+\n",
    "      str(data.cleaned_job_title.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 1000+ resume entries: 152\n",
      "Number of resume entries available now: 849706\n"
     ]
    }
   ],
   "source": [
    "# Remove all jobs without `min_job_summaries` or more resume entries\n",
    "cnt_resumes_available = jobs_descriptions.groupby('cleaned_job_title')\\\n",
    "                                .count().reset_index()\n",
    "cnt_resumes_available = list(cnt_resumes_available[\n",
    "            cnt_resumes_available.summary_text>parameters['min_job_summaries']].cleaned_job_title)\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title\\\n",
    "                       .isin(cnt_resumes_available)]\n",
    "\n",
    "# Save off list of resume ids\n",
    "if parameters['doc_type'] == 'indeed_resume':\n",
    "    # Save the list of resume ids for resumes being used\n",
    "    pd.DataFrame(jobs_descriptions.resume_id.unique())\\\n",
    "                .to_csv(directory+'03_relevant_resume_ids.csv',index=False)\n",
    "        \n",
    "# Remove duplicate data\n",
    "jobs_descriptions = jobs_descriptions[['cleaned_job_title','summary_text','from_year']].drop_duplicates()\n",
    "\n",
    "print(\"Number of jobs with \"+str(parameters['min_job_summaries'])+\"+ resume entries:\", len(cnt_resumes_available))\n",
    "print(\"Number of resume entries available now:\", jobs_descriptions.cleaned_job_title.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Salary Data for App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code saves the cleaned salary information back to the main data folder\n",
    "combined_salaries.to_csv(directory+'03_cleaned_salaries_for_app.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleaned_job_title    318102\n",
       "summary_text         318102\n",
       "from_year            318102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code samples the number of records to remove excessive numbers\n",
    "new_job_descriptions = pd.DataFrame()\n",
    "for name, group in jobs_descriptions.groupby('cleaned_job_title'):\n",
    "    if group[group.from_year == 2016].cleaned_job_title.count() >= parameters['max_number_records']:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group[group.from_year < 2017]\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "    elif group[(group.from_year == 2016) | (group.from_year == 2017)].cleaned_job_title.count() >= parameters['max_number_records']:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group[group.from_year < 2018]\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "    else:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "\n",
    "new_job_descriptions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jobs_descriptions.groupby(['cleaned_job_title']).summary_text.count().sort_values(ascending=False).head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2018-07-20 15:54:02.600306\n",
      "End: 2018-07-20 16:03:29.120794\n"
     ]
    }
   ],
   "source": [
    "print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# from functions.word_preprocessing\n",
    "x_data = preprocess_list(new_job_descriptions.summary_text)\n",
    "\n",
    "# Create labels using cleaned_job_title\n",
    "y_labels = new_job_descriptions.cleaned_job_title\n",
    "\n",
    "print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, \n",
    "                                                    y_labels,\n",
    "                                                    test_size=parameters['train_test_split'],\n",
    "                                                    random_state=parameters['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2018-07-20 20:13:52.625734\n",
      "End: 2018-07-20 20:19:24.621358\n",
      "Vocabulary len: 569472\n"
     ]
    }
   ],
   "source": [
    "print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# Train TF-IDF vectorizer model\n",
    "vect = TfidfVectorizer(min_df=parameters['min_df'], \n",
    "                       ngram_range=(parameters['min_ngram'], parameters['max_ngram'])\n",
    "                      ).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "print(\"End:\", datetime.datetime.now())\n",
    "\n",
    "print('Vocabulary len:', len(vect.get_feature_names()))\n",
    "\n",
    "# Vocabulary len: 893268 When there are 3-4 ngrams\n",
    "# Vocabulary len: 569472 When there are 3 ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2018-07-20 20:19:26.246658\n",
      "End: 2018-07-20 20:20:22.709054\n"
     ]
    }
   ],
   "source": [
    "print(\"Start:\", datetime.datetime.now())\n",
    "sm = SMOTE(kind='regular')\n",
    "X_res, y_res = sm.fit_sample(X_train_vectorized, y_train)\n",
    "print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>range</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>account executive</td>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>account manager</td>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accountant</td>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accounting</td>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accounting clerk</td>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               range  counter\n",
       "0  account executive     2402\n",
       "1    account manager     2402\n",
       "2         accountant     2402\n",
       "3         accounting     2402\n",
       "4   accounting clerk     2402"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_display = pd.DataFrame(y_res)\n",
    "temp_display.columns = ['range']\n",
    "temp_display['counter'] = 1\n",
    "temp_display.groupby('range').count().reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2018-07-20 23:11:02.112940\n",
      "Accuracy: 33.43%\n",
      "End: 2018-07-20 23:11:22.428579\n"
     ]
    }
   ],
   "source": [
    "print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# Train Multinomial Naive Bayes model\n",
    "model = MultinomialNB(alpha=parameters['alpha'])\n",
    "model.fit(X_res, y_res)\n",
    "\n",
    "y_pred = model.predict(vect.transform(X_test))\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "print(\"End:\", datetime.datetime.now())\n",
    "\n",
    "# Accuracy: 44.81% for doc similarity\n",
    "# Accuracy: 33.43% for skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.314963983989\n",
      "precision_score:  0.342383574896\n",
      "recall_score:  0.326414634437\n"
     ]
    }
   ],
   "source": [
    "print('f1_score: ', f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print('precision_score: ', precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print('recall_score: ', recall_score(y_test, y_pred, average=\"macro\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>researcher</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>director</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>account executive</td>\n",
       "      <td>0.032593</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>0.059946</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>manager</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>member of technical staff</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         class  precision    recall    fscore  support\n",
       "114                 researcher   0.000000  0.000000  0.000000       60\n",
       "45                    director   0.114286  0.037736  0.056738      106\n",
       "0            account executive   0.032593  0.372881  0.059946      118\n",
       "73                     manager   0.142857  0.043478  0.066667      138\n",
       "81   member of technical staff   0.111111  0.052632  0.071429       57"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.DataFrame(list(zip(model.classes_, precision, recall, fscore, support)))\n",
    "metrics.columns = ['class','precision', 'recall', 'fscore', 'support']\n",
    "metrics.sort_values(by='fscore',ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import collections\n",
    "# counted = collections.Counter(y_test)\n",
    "\n",
    "# from operator import itemgetter\n",
    "# import heapq\n",
    "# import collections\n",
    "# def least_common_values(array, to_find=None):\n",
    "#     counter = collections.Counter(array)\n",
    "#     if to_find is None:\n",
    "#         return sorted(counter.items(), key=itemgetter(1), reverse=False)\n",
    "#     return heapq.nsmallest(to_find, counter.items(), key=itemgetter(1))\n",
    "\n",
    "# # counted.most_common()\n",
    "# least_common_values(counted, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>controller</td>\n",
       "      <td>accounting manager</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>java software engineer</td>\n",
       "      <td>j2ee engineer</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>human resources specialist</td>\n",
       "      <td>human resources manager</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>marketing director</td>\n",
       "      <td>marketing manager</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>accountant</td>\n",
       "      <td>staff accountant</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>salesforce administrator</td>\n",
       "      <td>salesforce engineer</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>j2ee engineer</td>\n",
       "      <td>java software engineer</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>accounting manager</td>\n",
       "      <td>controller</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>systems administrator</td>\n",
       "      <td>network administrator</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>marketing specialist</td>\n",
       "      <td>marketing manager</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>accountant</td>\n",
       "      <td>accounting manager</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>build and release engineer</td>\n",
       "      <td>devops engineer</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>software quality engineer</td>\n",
       "      <td>quality assurance tester</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>human resources manager</td>\n",
       "      <td>human resources specialist</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>design engineer</td>\n",
       "      <td>mechanical design engineer</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>quality assurance analyst</td>\n",
       "      <td>quality assurance tester</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>staff accountant</td>\n",
       "      <td>accountant</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>project manager</td>\n",
       "      <td>it project manager</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>staff accountant</td>\n",
       "      <td>accounting manager</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>business development</td>\n",
       "      <td>business development manager</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          actual                    prediction  count\n",
       "1095                  controller            accounting manager     37\n",
       "2240      java software engineer                 j2ee engineer     35\n",
       "1996  human resources specialist       human resources manager     32\n",
       "2375          marketing director             marketing manager     32\n",
       "93                    accountant              staff accountant     26\n",
       "3739    salesforce administrator           salesforce engineer     26\n",
       "2230               j2ee engineer        java software engineer     25\n",
       "145           accounting manager                    controller     24\n",
       "4219       systems administrator         network administrator     22\n",
       "2426        marketing specialist             marketing manager     22\n",
       "82                    accountant            accounting manager     21\n",
       "667   build and release engineer               devops engineer     20\n",
       "3961   software quality engineer      quality assurance tester     20\n",
       "1974     human resources manager    human resources specialist     20\n",
       "1304             design engineer    mechanical design engineer     20\n",
       "3308   quality assurance analyst      quality assurance tester     19\n",
       "4101            staff accountant                    accountant     19\n",
       "3231             project manager            it project manager     19\n",
       "4104            staff accountant            accounting manager     19\n",
       "751         business development  business development manager     18"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the test population, get the most confused labels\n",
    "\n",
    "# pd.options.display.max_rows = 10000\n",
    "predictions = pd.DataFrame(list(zip(y_test, y_pred)))\n",
    "predictions.columns=['actual','prediction']\n",
    "predictions['count']=1\n",
    "pred_group = predictions.groupby(['actual','prediction']).count().reset_index()\n",
    "pred_group[(pred_group.actual != pred_group.prediction) \n",
    "           & (pred_group.prediction!='account executive')\n",
    "          ].sort_values(by='count',ascending=False).head(20)\n",
    "# .to_csv('most_confusion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Most Relevant Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mechanical engineer\n",
      "-------\n",
      "computer aid design\n",
      "product data management\n",
      "provide technical support\n",
      "mechanical electrical component\n",
      "geometric dimensioning tolerancing\n",
      "designing building testing\n",
      "3d model 2d\n",
      "using ansys fluent\n",
      "design review presentation\n",
      "perform finite element\n",
      "mechanical engineering support\n",
      "computational fluid dynamic\n",
      "plastic sheet metal\n",
      "piping instrumentation diagram\n",
      "using autodesk inventor\n",
      "print circuit board\n",
      "element analysis fea\n",
      "autocad solidworks design\n",
      "cooling load calculation\n",
      "engineering change request\n",
      "subject matter expert\n",
      "meeting strict deadline\n",
      "injection mold part\n",
      "product life cycle\n",
      "design next generation\n",
      "design 3d print\n",
      "perform root analysis\n",
      "design test fixture\n",
      "plastic injection molding\n",
      "drawing using autocad\n",
      "create bill material\n",
      "design stress analysis\n",
      "using catia v5\n",
      "mode effect analysis\n",
      "cross functional team\n",
      "new existing product\n",
      "draft engineering drawing\n",
      "model using solidworks\n",
      "create part drawing\n",
      "first article inspection\n",
      "cad model drawing\n",
      "product design development\n",
      "part assembly using\n",
      "nuclear power plant\n",
      "fire protection system\n",
      "responsible mechanical design\n",
      "per asme y14\n",
      "air handling unit\n",
      "hvac plumbing fire\n",
      "design hvac system\n",
      "technical data package\n"
     ]
    }
   ],
   "source": [
    "# This code finds the top parameters['num_skills'] of features to show the user. It filters out any \n",
    "# ngram where the same n-1 version of the ngram is shown. This cuts down on repetition.\n",
    "\n",
    "label_id = 80\n",
    "\n",
    "print(model.classes_[label_id])\n",
    "print('-------')\n",
    "\n",
    "features_list = []\n",
    "topn_class1 = sorted(zip(model.coef_[label_id], vect.get_feature_names()))[-parameters['num_skills']:]\n",
    "for coef, feat in topn_class1:\n",
    "    features_list.append(feat)\n",
    "\n",
    "accepted_skill_list = [model.classes_[label_id]]\n",
    "for potential_skill in sorted(features_list, key=lambda x: -len(x.split())):\n",
    "    highest_match = len(potential_skill.split())\n",
    "    for accepted_skill in accepted_skill_list:\n",
    "        leftovers = list(set(potential_skill.split()) - set(accepted_skill.split()))\n",
    "        if len(leftovers) < highest_match:\n",
    "            highest_match = len(leftovers)\n",
    "    if highest_match > 1:\n",
    "        accepted_skill_list.append(potential_skill)\n",
    "accepted_skill_list = accepted_skill_list[1:]\n",
    "shuffle(accepted_skill_list)\n",
    "\n",
    "for skill in accepted_skill_list:\n",
    "    print(skill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756656    quality assurance tester\n",
      "Name: cleaned_job_title, dtype: object\n",
      "\n",
      "---------------------\n",
      " definition functional testing strategy module design test plan checklist test case validation structure visual monitoring standard template accomplishment smoke testing exploratory testing functional testing regression testing integration testing registration bug found development production assign task development team fix error monitoring resolution evaluate approval rejection work done development team research develop necessary documentation improve process test plan test case use case report preparing suggestion document improve quality application produce analyze customer report progress project regularly \n",
      "\n",
      "---------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.97465683265290171, 'quality assurance analyst'),\n",
       " (0.0078351714292003022, 'quality assurance tester'),\n",
       " (0.0059408891885279948, 'software tester'),\n",
       " (0.0043898792065852482, 'test engineer'),\n",
       " (0.0043151850727030623, 'software quality engineer'),\n",
       " (0.0013814186011663091, 'software test engineer'),\n",
       " (0.00066400263754561105, 'quality assurance engineer'),\n",
       " (0.00040898850899171005, 'quality assurance'),\n",
       " (0.00030397507120115977, 'test'),\n",
       " (4.5799081373216704e-05, 'automation engineer'),\n",
       " (1.9464541054858887e-05, 'quality assurance specialist'),\n",
       " (1.590720864434804e-05, 'quality assurance manager'),\n",
       " (9.0489167140637224e-06, 'business analyst'),\n",
       " (5.8303131247096438e-06, 'project'),\n",
       " (2.0566547023995492e-06, 'programmer analyst'),\n",
       " (1.9071343583170404e-06, 'dit analyst'),\n",
       " (1.4204332071099108e-06, 'systems analyst'),\n",
       " (3.3992404932238059e-07, 'analyst'),\n",
       " (3.3005341030906443e-07, 'technical'),\n",
       " (2.4755806702249873e-07, 'engineer')]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code returns the prediction probabilities for an example input\n",
    "\n",
    "example_index = 11\n",
    "print(y_test[example_index:example_index+1])\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "print(X_test[example_index])\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "vector_example = vect.transform(preprocess_list([X_test[example_index]]))\n",
    "job_rankings = list(zip(model.predict_proba(vector_example)[0],model.classes_))\n",
    "sorted(job_rankings,reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180720231219859630\n"
     ]
    }
   ],
   "source": [
    "# This code saves the model to the models folder\n",
    "directory = '/mnt/disks/mnt_dir/'\n",
    "\n",
    "save_time = re.sub('[^A-Za-z0-9]+', '', str(datetime.datetime.now()))\n",
    "print(save_time)\n",
    "\n",
    "write_param = open(directory+\"models/\" + save_time + '_parameters.txt','w')\n",
    "for key in parameters:\n",
    "    write_param.write(key + \"=\" + str(parameters[key]) + '\\n')\n",
    "write_param.close()\n",
    "\n",
    "# Save preprocessed x data\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_data.pkl\",\"wb\")\n",
    "pickle.dump(x_data, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save preprocessed y labels\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_y_labels.pkl\",\"wb\")\n",
    "pickle.dump(y_labels, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save preprocessed x SMOTE data\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_SMOTE_data.pkl\",\"wb\")\n",
    "pickle.dump(X_res, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save preprocessed y SMOTE labels\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_y_SMOTE_labels.pkl\",\"wb\")\n",
    "pickle.dump(y_res, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save TD-IDF vectorizer\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_tdidf_vect.pkl\",\"wb\")\n",
    "pickle.dump(vect, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save vectorized x_train\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_trained_tdidf_vect.pkl\",\"wb\")\n",
    "pickle.dump(X_train_vectorized, pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save NB model\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_nb_model.pkl\",\"wb\")\n",
    "pickle.dump(model, pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code loads an old model\n",
    "directory = '/mnt/disks/mnt_dir/'\n",
    "\n",
    "save_time = '20180720171945426156' # Currently best model for doc similarity\n",
    "# save_time = '20180720231219859630' # Currently best model for skills\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_data.pkl\",\"rb\")\n",
    "x_data = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save preprocessed y labels\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_y_labels.pkl\",\"rb\")\n",
    "y_labels = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save TD-IDF vectorizer\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_tdidf_vect.pkl\",\"rb\")\n",
    "vect = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# Save vectorized x_train\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_trained_tdidf_vect.pkl\",\"rb\")\n",
    "X_train_vectorized = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "# # Save NB model\n",
    "# pickling_on = open(directory+\"models/\"+save_time+\"_nb_model.pkl\",\"rb\")\n",
    "# model = pickle.load(pickling_on)\n",
    "# pickling_on.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
