{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Naive Bayes classifier using TD-IDF vectorizer and pickle results. This model can be \n",
    "# trained on job resumes or Indeed job postings. Steps include:\n",
    "# 1. Set the model parameters\n",
    "# 2. Getting a combined list of salaries and only using job titles with 500+ salary records\n",
    "# 3. Getting a list of resumes using this list of job titles and remove any job titles with \n",
    "#    less than 500 resumes\n",
    "# 4. Run TD-IDF vectorizer and Naive Bayes model training\n",
    "# 5. Test the model using \"List Most Relevant Skills\"\n",
    "# 6. Test the model using \"Document Similarity Score\"\n",
    "\n",
    "\n",
    "# We are only looking at the most recent 5 years of salary\n",
    "# We are only looking at the mode recent 10 years of work start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "\n",
    "# Custom function in functions folder\n",
    "from functions.word_preprocessing import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/kwheatley/Desktop/Capstone/gcloud_data/'\n",
    "# directory = '/mnt/disks/mnt_dir/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters for doc similarity\n",
    "parameters = {\n",
    "                \"doc_type\":\"indeed_resume\", # Use \"indeed_resume\" or \"indeed_postings\"\n",
    "                \"min_salary_year\":2014, # Filter out all salaries older than specified number\n",
    "                \"min_job_year\":2008, # Filter out all resume jobs older than specified number\n",
    "                \"min_salary_records\":100, # Filter out all jobs with less than specified salary records\n",
    "                \"min_job_summaries\":1000, # Filter out all jobs with less than specified job summaries\n",
    "                \"min_ngram\":1, # For TD-IDF vectorizer\n",
    "                \"max_ngram\":3, # For TD-IDF vectorizer\n",
    "                \"min_df\":5, # For TD-IDF vectorizer, ignore features in less than this number of documents\n",
    "                \"train_test_split\":0.05, # For train-test split\n",
    "                \"random_state\":1, # For train-test split\n",
    "                \"alpha\":0.02, # For Naive Bayes model 0.02 is current best\n",
    "                \"num_skills\":50, # Number of skill to show per job \n",
    "                \"max_number_records\":2500, # Number of records in each class, SMOTE is used to fill small classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best parameters for skills\n",
    "\n",
    "# parameters = {\n",
    "#                 \"doc_type\":\"indeed_resume\", # Use \"indeed_resume\" or \"indeed_postings\"\n",
    "#                 \"min_salary_year\":2014, # Filter out all salaries older than specified number\n",
    "#                 \"min_job_year\":2008, # Filter out all resume jobs older than specified number\n",
    "#                 \"min_salary_records\":100, # Filter out all jobs with less than specified salary records\n",
    "#                 \"min_job_summaries\":1000, # Filter out all jobs with less than specified job summaries\n",
    "#                 \"min_ngram\":3, # For TD-IDF vectorizer\n",
    "#                 \"max_ngram\":3, # For TD-IDF vectorizer\n",
    "#                 \"min_df\":5, # For TD-IDF vectorizer, ignore features in less than this number of documents\n",
    "#                 \"train_test_split\":0.05, # For train-test split\n",
    "#                 \"random_state\":1, # For train-test split\n",
    "#                 \"alpha\":0.02, # For Naive Bayes model 0.02 is current best\n",
    "#                 \"num_skills\":100, # Number of skill to show per job \n",
    "#                 \"max_number_records\":5000, # Number of records in each class, SMOTE is used to fill small classes\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Salary Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both salary datasets\n",
    "salary1 = pd.read_csv(directory+'02_salaries_h1b.csv')\n",
    "salary2 = pd.read_csv(directory+'02_salaries_greencard.csv')\n",
    "\n",
    "# Combine salary datasets\n",
    "temp_salary1 = salary1[['role','city','state','start_year','cleaned_job_title','experiences','salary']]\n",
    "temp_salary2 = salary2[['job_title','city','state','decision_year','cleaned_job_title','experiences','salary_amount']]\n",
    "temp_salary1.columns = ['original_role','city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "temp_salary2.columns = ['original_role','city','state','start_year','cleaned_job_title','experiences','salary']\n",
    "combined_salaries = temp_salary1.append(temp_salary2)\n",
    "\n",
    "# Remove salaries with null value and convert to int\n",
    "combined_salaries = combined_salaries[~combined_salaries.salary.isnull()]\n",
    "combined_salaries.salary = combined_salaries.salary.astype(int)\n",
    "\n",
    "# Fill any NaN fields with no_value and convert each column into a list\n",
    "combined_salaries = combined_salaries.fillna('no_value')\n",
    "combined_salaries.experiences = combined_salaries.experiences.apply(lambda x: \n",
    "                                                list([item.strip() for item in x.split(',')]))\n",
    "combined_salaries.original_role = combined_salaries.original_role.apply(lambda x: [x])\n",
    "combined_salaries.city = combined_salaries.city.apply(lambda x: [x])\n",
    "combined_salaries.state = combined_salaries.state.apply(lambda x: [x])\n",
    "combined_salaries.start_year = combined_salaries.start_year.apply(lambda x: [x])\n",
    "combined_salaries.cleaned_job_title = combined_salaries.cleaned_job_title.apply(lambda x: [x])\n",
    "combined_salaries.salary = combined_salaries.salary.apply(lambda x: [x])\n",
    "\n",
    "# Perform a pivot on the columns to split out rows with multiple experience level qualifiers\n",
    "combined_salaries = pd.DataFrame([j for i in combined_salaries.values for j in product(*i)],\n",
    "                                      columns = combined_salaries.columns)\n",
    "\n",
    "# Only look at jobs in the past 5 years\n",
    "combined_salaries = combined_salaries[combined_salaries.start_year >= parameters['min_salary_year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 100+ salary records: 732\n"
     ]
    }
   ],
   "source": [
    "# Choose all jobs with `min_salary_records` or more records\n",
    "temp = combined_salaries.groupby('cleaned_job_title').count().salary.reset_index()\n",
    "jobs_to_model = temp[temp.salary >= parameters['min_salary_records']]\n",
    "combined_salaries = combined_salaries[combined_salaries.cleaned_job_title\\\n",
    "                                                       .fillna('').isin(jobs_to_model.cleaned_job_title)]\n",
    "print(\"Number of jobs with \"+str(parameters['min_salary_records'])+\"+ salary records:\", jobs_to_model.cleaned_job_title.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Job Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load resume data\n",
    "if parameters['doc_type'] == 'indeed_resume':\n",
    "    data = pd.read_csv(directory+'02_resumes_work.csv')\n",
    "    data.rename(columns = {'descript':'summary_text'}, inplace=True)\n",
    "if parameters['doc_type'] == 'indeed_postings':\n",
    "    data = pd.read_csv(directory+'02_job_posts_indeed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs with 1000+ resume entries: 114\n",
      "Number of resume entries available: 497928\n"
     ]
    }
   ],
   "source": [
    "# Remove all null cleaned_job_title records\n",
    "jobs_descriptions = data[~data.cleaned_job_title.isnull()]\n",
    "\n",
    "# Remove all jobs older than 10 years\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.from_year >= parameters['min_job_year']]\n",
    "\n",
    "# Drop insignificant job names\n",
    "jobs_to_remove = ['technical','team','test','project']\n",
    "jobs_descriptions = jobs_descriptions[~jobs_descriptions.cleaned_job_title.isin(jobs_to_remove)] \n",
    "\n",
    "# Filter to only jobs specified by the jobs_to_model list\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title\\\n",
    "                                      .isin(jobs_to_model.cleaned_job_title)]\n",
    "    \n",
    "# Remove all jobs without `min_job_summaries` or more resume entries\n",
    "cnt_resumes_available = jobs_descriptions.groupby('cleaned_job_title')\\\n",
    "                                .count().reset_index()\n",
    "cnt_resumes_available = list(cnt_resumes_available[\n",
    "            cnt_resumes_available.summary_text>parameters['min_job_summaries']].cleaned_job_title)\n",
    "jobs_descriptions = jobs_descriptions[jobs_descriptions.cleaned_job_title\\\n",
    "                       .isin(cnt_resumes_available)]\n",
    "\n",
    "# Remove duplicate data\n",
    "jobs_descriptions = jobs_descriptions.groupby(['cleaned_job_title','summary_text','from_year'])\\\n",
    "        .resume_id.first().reset_index()\n",
    "\n",
    "print(\"Number of jobs with \"+str(parameters['min_job_summaries'])+\"+ resume entries:\", len(cnt_resumes_available))\n",
    "print(\"Number of resume entries available:\", jobs_descriptions.cleaned_job_title.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleaned_job_title    234714\n",
       "summary_text         234714\n",
       "from_year            234714\n",
       "resume_id            234714\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code samples the number of records to remove excessive numbers\n",
    "new_job_descriptions = pd.DataFrame()\n",
    "for name, group in jobs_descriptions.groupby('cleaned_job_title'):\n",
    "    if group[group.from_year == 2016].cleaned_job_title.count() >= parameters['max_number_records']:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group[group.from_year < 2017]\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "    elif group[(group.from_year == 2016) | (group.from_year == 2017)].cleaned_job_title.count() >= parameters['max_number_records']:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group[group.from_year < 2018]\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "    else:\n",
    "        new_job_descriptions = pd.concat([new_job_descriptions,group\\\n",
    "            .sort_values(by='from_year', ascending=False).head(parameters['max_number_records'])])\n",
    "\n",
    "new_job_descriptions.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data for Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save off list of resume ids\n",
    "if parameters['doc_type'] == 'indeed_resume':\n",
    "    # Save the list of resume ids for resumes being used\n",
    "    pd.DataFrame(new_job_descriptions.resume_id.unique())\\\n",
    "                .to_csv(directory+'03_relevant_resume_ids.csv',index=False)\n",
    "\n",
    "# Save off list of relevant job titles\n",
    "relevant_job_titles = pd.DataFrame(new_job_descriptions.cleaned_job_title.unique())\n",
    "relevant_job_titles.columns = ['cleaned_job_title']\n",
    "relevant_job_titles.to_csv(directory+'03_relevant_job_titles.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves the cleaned salary information back to the main data folder\n",
    "combined_salaries.to_csv(directory+'03_cleaned_salaries_for_app.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = new_job_descriptions.summary_text\n",
    "y_labels = new_job_descriptions.cleaned_job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, \n",
    "                                                    y_labels,\n",
    "                                                    test_size=parameters['train_test_split'],\n",
    "                                                    random_state=parameters['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 222978\n",
      "y_train:  222978\n",
      "X_test:  11736\n",
      "y_test:  11736\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\",len(X_train))\n",
    "print(\"y_train: \",len(y_train))\n",
    "print(\"X_test: \",len(X_test))\n",
    "print(\"y_test: \",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_job_descriptions.cleaned_job_title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in new_job_descriptions.cleaned_job_title.unique():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# x_data = new_job_descriptions.summary_text\n",
    "# y_labels = new_job_descriptions.cleaned_job_title\n",
    "\n",
    "# x_data = preprocess_list(new_job_descriptions.summary_text)\n",
    "# print(\"Done with preprocess\")\n",
    "\n",
    "# # create a count vectorizer object \n",
    "# count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "# count_vectorized_X_train = count_vect.fit_transform(X_train)\n",
    "\n",
    "# sm = SMOTE(kind='regular')\n",
    "# count_vect_X_res, count_vect_y_res = sm.fit_sample(count_vectorized_X_train, y_train)\n",
    "\n",
    "# # transform the training and validation data using count vectorizer object\n",
    "# # xtrain_count =  count_vect.transform(train_x)\n",
    "# count_vectorized_X_test =  count_vect.transform(X_test)\n",
    "\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# x_data = new_job_descriptions.summary_text\n",
    "# y_labels = new_job_descriptions.cleaned_job_title\n",
    "\n",
    "# x_data = preprocess_list(new_job_descriptions.summary_text)\n",
    "# print(\"Done with preprocess\")\n",
    "\n",
    "# # Split the data into test and train datasets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x_data, \n",
    "#                                                     y_labels,\n",
    "#                                                     test_size=parameters['train_test_split'],\n",
    "#                                                     random_state=parameters['random_state'])\n",
    "\n",
    "# # Train TF-IDF vectorizer model\n",
    "# vect = TfidfVectorizer(min_df=parameters['min_df'], \n",
    "#                        ngram_range=(parameters['min_ngram'], parameters['max_ngram'])\n",
    "#                       ).fit(X_train)\n",
    "# X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "# print(\"Done with TD-IDF\")\n",
    "\n",
    "# print('Vocabulary len:', len(vect.get_feature_names()))\n",
    "\n",
    "# sm = SMOTE(kind='regular')\n",
    "# X_res, y_res = sm.fit_sample(X_train_vectorized, y_train)\n",
    "\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickling_on = open(directory+\"models/dev_X_test.pkl\",\"wb\")\n",
    "# # pickle.dump(X_test, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/dev_y_test.pkl\",\"wb\")\n",
    "# # pickle.dump(y_test, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/dev_x_SMOTE_data.pkl\",\"wb\")\n",
    "# # pickle.dump(X_res, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/dev_y_SMOTE_data.pkl\",\"wb\")\n",
    "# # pickle.dump(y_res, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "# # pickling_on = open(directory+\"models/vect.pkl\",\"wb\")\n",
    "# # pickle.dump(vect, pickling_on)\n",
    "# # pickling_on.close()\n",
    "\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_X_test.pkl\",\"rb\")\n",
    "# X_test = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_y_test.pkl\",\"rb\")\n",
    "# y_test = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_x_SMOTE_data.pkl\",\"rb\")\n",
    "# X_res = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/dev_y_SMOTE_data.pkl\",\"rb\")\n",
    "# y_res = pickle.load(pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# pickling_on = open(directory+\"models/vect.pkl\",\"rb\")\n",
    "# vect = pickle.load(pickling_on)\n",
    "# pickling_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_model = MultinomialNB(alpha=0.02)\n",
    "# nb_model.fit(X_res, y_res)\n",
    "\n",
    "# y_pred = nb_model.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# # Accuracy: 35.83% .012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# svm_model = SGDClassifier(loss='hinge', penalty='l2', alpha=.0008, n_iter=3, random_state=42)\n",
    "\n",
    "# svm_model.fit(X_res, y_res)\n",
    "\n",
    "# y_pred = svm_model.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# print(\"End:\", datetime.datetime.now())\n",
    "# # Accuracy: 47.21% alpha=.0008, n_iter=3\n",
    "# # Count Vectorizer Accuracy: 40.81% .0008 n_iter=3\n",
    "# # Accuracy: 41.42% .001 5\n",
    "# # Accuracy: 41.41% .009 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# eclf1 = VotingClassifier(estimators=[\n",
    "#             ('nb', nb_model), ('svm', svm_model)], voting='hard')\n",
    "# eclf2 = VotingClassifier(estimators=[\n",
    "#             ('nb', nb_model), ('svm', svm_model)], voting='soft')\n",
    "# # eclf3 = VotingClassifier(estimators=[\n",
    "# #             ('nb', nb_model), ('svm', svm_model)], voting='soft', weights=[1,1,2], flatten_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "# eclf1.fit(X_res, y_res)\n",
    "# y_pred = eclf1.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start:\", datetime.datetime.now())\n",
    "# eclf2.fit(X_res, y_res)\n",
    "# y_pred = eclf2.predict(vect.transform(X_test))\n",
    "# print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "# print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# # from sklearn.decomposition import PCA\n",
    "# # from sklearn.pipeline import Pipeline\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# # pca = PCA(n_components=152).fit(X_res)\n",
    "# # data2D = pca.transform(X_res)\n",
    "# # plt.scatter(data2D[:,0], data2D[:,1], c=data.target)\n",
    "# # plt.show()              #not required if using ipython notebook\n",
    "\n",
    "\n",
    "# # Load libraries\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# from scipy.sparse import csr_matrix\n",
    "# from sklearn import datasets\n",
    "# import numpy as np\n",
    "\n",
    "# tsvd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# X_sparse_tsvd = tsvd.fit_transform(X_res)\n",
    "\n",
    "# # # Show results\n",
    "# print('Original number of features:', X_res.shape[1])\n",
    "# print('Reduced number of features:', X_sparse_tsvd.shape[1])\n",
    "# # Original number of features: 64\n",
    "# # Reduced number of features: 10\n",
    "# # View Percent Of Variance Explained By New Features\n",
    "# # # Sum of first three components' explained variance ratios\n",
    "# # tsvd.explained_variance_ratio_[0:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_matrix = X_res.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_remove_index = []\n",
    "# # filevector = open('docvectors.txt', 'w')\n",
    "# vector_list = []\n",
    "# meta_list = []\n",
    "# meta_list = list(y_res)\n",
    "# # filemeta = open('docmeta.txt', 'w')\n",
    "# # edu_filemeta.write(\"%s\\n\" % 'title')\n",
    "\n",
    "# for index in range(X_res.shape[0]):\n",
    "#     cleaned_vectors = '\\t'.join(str(vector) for vector in X_sparse_tsvd[index])\n",
    "#     if not cleaned_vectors or cleaned_vectors == '':\n",
    "#         print(index)\n",
    "#         list_of_remove_index.append(index)\n",
    "#         continue\n",
    "#     vector_list.append(cleaned_vectors)\n",
    "# #     filevector.write(\"%s\\n\" % cleaned_vectors)\n",
    "# #     cleaned_meta = (str(index) + ' ' + ' '.join(traindocs[index].words))\n",
    "# #     if index >= 94999:\n",
    "# #         print(index)\n",
    "# #     if not cleaned_meta:\n",
    "# #         print(\"issue with meta\")\n",
    "# #         print(index)\n",
    "# #     filemeta.write(\"%s\\n\" %cleaned_meta )\n",
    "# #     meta_list.append(cleaned_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(X_sparse_tsvd).to_csv('teest.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(vector_list))\n",
    "# print(X_sparse_tsvd.shape)\n",
    "# print(len(meta_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len(vector_list)\n",
    "# # len(meta_list)\n",
    "# filevector = open('docvectors.txt', 'w')\n",
    "# filemeta = open('docmeta.txt', 'w')\n",
    "# for row in vector_list:\n",
    "#     filevector.write(\"%s\\n\" % row)\n",
    "# for row in meta_list:\n",
    "#     filemeta.write(\"%s\\n\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# conf_mat = confusion_matrix(y_test, y_pred)\n",
    "# fig, ax = plt.subplots(figsize=(50,50))\n",
    "# sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Greys',\n",
    "#             xticklabels=nb_model.classes_, yticklabels=nb_model.classes_)\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = FunctionTransformer(preprocess_list)\n",
    "smt = SMOTE()\n",
    "tfidf = TfidfVectorizer(min_df=parameters['min_df'], ngram_range=(parameters['min_ngram'], parameters['max_ngram']))\n",
    "nb = MultinomialNB(alpha=parameters['alpha'])\n",
    "preprocess = FunctionTransformer(preprocess_list, validate=False)\n",
    "\n",
    "pipeline = Pipeline([('preprocess', preprocess), ('tfidf', tfidf), ('smt', smt), ('nb', nb)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 222978\n",
      "y_train: 222978\n",
      "Start: 2018-08-05 07:25:31.706267\n",
      "End: 2018-08-05 07:41:05.537445\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', len(X_train))\n",
    "print('y_train:', len(y_train))\n",
    "\n",
    "print(\"Start:\", datetime.datetime.now())\n",
    "pipeline.fit(X_train,y_train)\n",
    "print(\"End:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.81%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "# Accuracy: 44.81% for doc similarity\n",
    "# Accuracy: 35.53% for skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.461527810083\n",
      "precision_score:  0.477049649202\n",
      "recall_score:  0.475251537231\n"
     ]
    }
   ],
   "source": [
    "print('f1_score: ', f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print('precision_score: ', precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print('recall_score: ', recall_score(y_test, y_pred, average=\"macro\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>android engineer</td>\n",
       "      <td>90.16%</td>\n",
       "      <td>90.16%</td>\n",
       "      <td>90.16%</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>technical recruiter</td>\n",
       "      <td>77.05%</td>\n",
       "      <td>94.95%</td>\n",
       "      <td>85.07%</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ios engineer</td>\n",
       "      <td>87.50%</td>\n",
       "      <td>80.77%</td>\n",
       "      <td>84.00%</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>caregiver</td>\n",
       "      <td>88.14%</td>\n",
       "      <td>78.79%</td>\n",
       "      <td>83.20%</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>salesforce engineer</td>\n",
       "      <td>80.33%</td>\n",
       "      <td>85.96%</td>\n",
       "      <td>83.05%</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class precision  recall  fscore  support\n",
       "7       android engineer    90.16%  90.16%  90.16%       61\n",
       "108  technical recruiter    77.05%  94.95%  85.07%       99\n",
       "51          ios engineer    87.50%  80.77%  84.00%       52\n",
       "24             caregiver    88.14%  78.79%  83.20%       66\n",
       "94   salesforce engineer    80.33%  85.96%  83.05%      114"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(y_test, y_pred)\n",
    "'{:.1%}'.format(1/3.0)\n",
    "\n",
    "metrics = pd.DataFrame(list(zip(pipeline.classes_, precision, recall, fscore, support)))\n",
    "metrics.columns = ['class','precision', 'recall', 'fscore', 'support']\n",
    "metrics_samples = metrics.sort_values(by='fscore',ascending=False).head(5)\n",
    "metrics_samples.precision = metrics_samples.precision.map(lambda x: '{:.2%}'.format(x))\n",
    "metrics_samples.recall = metrics_samples.recall.map(lambda x: '{:.2%}'.format(x))\n",
    "metrics_samples.fscore = metrics_samples.fscore.map(lambda x: '{:.2%}'.format(x))\n",
    "metrics_samples.sort_values(by='fscore',ascending=True).to_csv('temp.csv')\n",
    "metrics_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# counted = collections.Counter(y_test)\n",
    "\n",
    "# from operator import itemgetter\n",
    "# import heapq\n",
    "# import collections\n",
    "# def least_common_values(array, to_find=None):\n",
    "#     counter = collections.Counter(array)\n",
    "#     if to_find is None:\n",
    "#         return sorted(counter.items(), key=itemgetter(1), reverse=False)\n",
    "#     return heapq.nsmallest(to_find, counter.items(), key=itemgetter(1))\n",
    "\n",
    "# # counted.most_common()\n",
    "# least_common_values(counted, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>accountant</td>\n",
       "      <td>staff accountant</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>java software engineer</td>\n",
       "      <td>j2ee engineer</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>marketing director</td>\n",
       "      <td>marketing manager</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>associate</td>\n",
       "      <td>cashier</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>network administrator</td>\n",
       "      <td>network engineer</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>manager</td>\n",
       "      <td>general manager</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>assistant</td>\n",
       "      <td>administrative assistant</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>process engineer</td>\n",
       "      <td>manufacturing engineer</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>project manager</td>\n",
       "      <td>it project manager</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>marketing specialist</td>\n",
       "      <td>marketing manager</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      actual                prediction  count\n",
       "73                accountant          staff accountant     39\n",
       "1152  java software engineer             j2ee engineer     33\n",
       "1226      marketing director         marketing manager     32\n",
       "328                associate                   cashier     30\n",
       "1296   network administrator          network engineer     30\n",
       "1189                 manager           general manager     28\n",
       "249                assistant  administrative assistant     27\n",
       "1366        process engineer    manufacturing engineer     26\n",
       "1602         project manager        it project manager     26\n",
       "1252    marketing specialist         marketing manager     25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the test population, get the most confused labels\n",
    "\n",
    "# pd.options.display.max_rows = 10000\n",
    "predictions = pd.DataFrame(list(zip(y_test, y_pred)))\n",
    "predictions.columns=['actual','prediction']\n",
    "predictions['count']=1\n",
    "pred_group = predictions.groupby(['actual','prediction']).count().reset_index()\n",
    "pred_group[(pred_group.actual != pred_group.prediction) \n",
    "           & (pred_group.prediction!='account executive')\n",
    "          ].sort_values(by='count',ascending=False).head(10)\n",
    "# .to_csv('most_confusion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Most Relevant Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instructor\n",
      "-------\n",
      "0 lesson plan\n",
      "1 school student\n"
     ]
    }
   ],
   "source": [
    "# This code finds the top parameters['num_skills'] of features to show the user. It filters out any \n",
    "# ngram where the same n-1 version of the ngram is shown. This cuts down on repetition.\n",
    "\n",
    "label_id = 50\n",
    "\n",
    "print(pipeline.classes_[label_id])\n",
    "print('-------')\n",
    "\n",
    "features_list = []\n",
    "topn_class1 = sorted(zip(pipeline.named_steps['nb'].coef_[label_id], \n",
    "                         pipeline.named_steps['tfidf'].get_feature_names()))[-parameters['num_skills']:]\n",
    "for coef, feat in topn_class1:\n",
    "    features_list.append(feat)\n",
    "\n",
    "accepted_skill_list = [pipeline.classes_[label_id]]\n",
    "for potential_skill in sorted(features_list, key=lambda x: -len(x.split())):\n",
    "    highest_match = len(potential_skill.split())\n",
    "    for accepted_skill in accepted_skill_list:\n",
    "        leftovers = list(set(potential_skill.split()) - set(accepted_skill.split()))\n",
    "        if len(leftovers) < highest_match:\n",
    "            highest_match = len(leftovers)\n",
    "    if highest_match > 1:\n",
    "        accepted_skill_list.append(potential_skill)\n",
    "accepted_skill_list = accepted_skill_list[1:]\n",
    "shuffle(accepted_skill_list)\n",
    "\n",
    "for index, skill in enumerate(accepted_skill_list):\n",
    "    print(index, skill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL LABEL\n",
      "301362    programmer analyst\n",
      "Name: cleaned_job_title, dtype: object\n",
      "\n",
      "---------------------\n",
      "\n",
      "INPUT\n",
      "301362    .Senior Oracle Developer .Project for DTE working on changes on the CSB application. .Project: CSB - Costumer service and Billing application .Responsibilities: .• Creating DML Scripts to insert new records into parameters and system variables tables. .• Creating packages, procedures, functions using Oracle SQL and PL/SQL .• Written and modifying Unix shell scripts to execute batch processes. .• Written and modifying SQL Scripts. .• Responsible for coding and unit testing. .• Using ClearCase...\n",
      "Name: summary_text, dtype: object\n",
      "\n",
      "---------------------\n",
      "\n",
      "OUTPUT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.99787409738054389, 'data engineer'),\n",
       " (0.0013924117506951411, 'programmer analyst'),\n",
       " (0.00036467955799108131, 'database administrator'),\n",
       " (0.00017590604614715479, 'java software engineer'),\n",
       " (8.1387049838448254e-05, 'j2ee engineer'),\n",
       " (3.6071628842895359e-05, 'net engineer'),\n",
       " (2.1635604507330222e-05, 'business intelligence engineer'),\n",
       " (1.9910934671133829e-05, 'applications engineer'),\n",
       " (1.2800137532779193e-05, 'data architect'),\n",
       " (9.9195518875086707e-06, 'systems analyst'),\n",
       " (2.2168369270583512e-06, 'quality assurance tester'),\n",
       " (1.6730880192783693e-06, 'data analyst'),\n",
       " (1.6289411790883927e-06, 'technical consultant'),\n",
       " (9.5395385627289708e-07, 'engineer'),\n",
       " (9.0191742941619685e-07, 'software engineer'),\n",
       " (8.0696212213939197e-07, 'software architect'),\n",
       " (7.7460908451068473e-07, 'quality assurance analyst'),\n",
       " (5.4587298879768956e-07, 'software quality engineer'),\n",
       " (4.7543133833621856e-07, 'quality assurance'),\n",
       " (3.2911582907578079e-07, 'business intelligence analyst')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code returns the prediction probabilities for an example input\n",
    "\n",
    "print(\"ACTUAL LABEL\")\n",
    "example_index = 41\n",
    "print(y_test[example_index:example_index+1])\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "print()\n",
    "print(\"INPUT\")\n",
    "example = X_test[example_index:example_index+1]\n",
    "print(example)\n",
    "\n",
    "print()\n",
    "print(\"---------------------\")\n",
    "print()\n",
    "print(\"OUTPUT\")\n",
    "\n",
    "job_rankings = list(zip(pipeline.predict_proba(example)[0],pipeline.classes_))\n",
    "sorted(job_rankings,reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e2a10bf0fedb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Save NB model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpickling_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"models/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msave_time\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_pipeline_model.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickling_on\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mpickling_on\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "# # This code saves the model to the models folder\n",
    "# # directory = '/mnt/disks/mnt_dir/'\n",
    "\n",
    "# save_time = re.sub('[^A-Za-z0-9]+', '', str(datetime.datetime.now()))\n",
    "# print(save_time)\n",
    "\n",
    "# write_param = open(directory+\"models/\" + save_time + '_parameters.txt','w')\n",
    "# for key in parameters:\n",
    "#     write_param.write(key + \"=\" + str(parameters[key]) + '\\n')\n",
    "# write_param.close()\n",
    "\n",
    "# # Save preprocessed x data\n",
    "# pickling_on = open(directory+\"models/\"+save_time+\"_x_data.pkl\",\"wb\")\n",
    "# pickle.dump(x_data, pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# # Save preprocessed y labels\n",
    "# pickling_on = open(directory+\"models/\"+save_time+\"_y_labels.pkl\",\"wb\")\n",
    "# pickle.dump(y_labels, pickling_on)\n",
    "# pickling_on.close()\n",
    "\n",
    "# Save NB model\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_pipeline_model.pkl\",\"wb\")\n",
    "pickle.dump(pipeline, pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator FunctionTransformer from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator NearestNeighbors from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# This code loads an old model\n",
    "# directory = '/mnt/disks/mnt_dir/'\n",
    "\n",
    "save_time = '20180724220628349336' # Currently best model for doc similarity\n",
    "# save_time = '20180725002822539809' # Currently best model for skills\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_x_data.pkl\",\"rb\")\n",
    "x_data = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_y_labels.pkl\",\"rb\")\n",
    "y_labels = pickle.load(pickling_on)\n",
    "pickling_on.close()\n",
    "\n",
    "pickling_on = open(directory+\"models/\"+save_time+\"_pipeline_model.pkl\",\"rb\")\n",
    "pipeline = pickle.load(pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
