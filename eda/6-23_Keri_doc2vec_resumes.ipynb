{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import os, sys, email\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from string import punctuation\n",
    "import timeit\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "start = timeit.default_timer()\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "from smart_open import smart_open\n",
    "from random import shuffle\n",
    "\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('processed_resumes_work_ADDED_JOB_TITLES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed jobs without description\n",
    "data = data[~data.descript.isnull()]\n",
    "\n",
    "# Convert null job title into blank\n",
    "data.loc[data.role.isnull()] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for training doc2vec\n",
    "data['train_val'] = data.role + \" \" + data.descript.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_val'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214940"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_val'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "\n",
    "    cleaned_list = []\n",
    "    \n",
    "    for row in data:\n",
    "        row = re.sub(r'[^a-zA-Z ]+', ' ', row.lower())\n",
    "        row = ' '.join([lmtzr.lemmatize(word) for word in row.split() if word not in stop_words])\n",
    "        cleaned_list.append(row)    \n",
    "    \n",
    "    return cleaned_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application architect .TOKYO, JAPAN\\xa0.ING L fe I su ce Comp y (Jp)Lm ted p ov des fe su ce p oducts d se v ces\\xa0.fo E ow e s. ING L Po t (INGLP)sfudmet system povdgv ous\\xa0.se v ces of the ING fe su ce to Age t, R, Custome d ING emp oyees. Th s INGLP s\\xa0.etypot the web whe e ING c p omote ew p oducts d se v ces, teg te\\xa0.d ffe e t web ppctosfop ocess gdhdg custome tsctos, docume t\\xa0.p oduct gudeesdp ov de st uct o s d educ to cotetfoRsd ge ts..'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data[328412]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328412"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.index(\"application architect tokyo japan ing l fe su ce comp jp lm ted p ov de fe su ce p oducts se v ce fo e ow e ing l po inglp sfudmet system povdgv ous se v ce ing fe su ce age r custome ing emp oyees th inglp etypot web whe e ing c p omote ew p oducts se v ce teg te ffe e web ppctosfop ocess gdhdg custome tsctos docume p oduct gudeesdp ov de st uct educ cotetforsd ge t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['application architect tokyo japan ing l fe su ce comp jp lm ted p ov de fe su ce p oducts se v ce fo e ow e ing l po inglp sfudmet system povdgv ous se v ce ing fe su ce age r custome ing emp oyees th inglp etypot web whe e ing c p omote ew p oducts se v ce teg te ffe e web ppctosfop ocess gdhdg custome tsctos docume p oduct gudeesdp ov de st uct educ cotetforsd ge t']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in cleaned_data if \"application architect tokyo japan\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = data.train_val.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_data = clean_data(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open('cleaned_data', 'wb') as fp:\n",
    "#     pickle.dump(cleaned_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pickle.load(open('cleaned_data', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traindocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200000 train, 14940 test\n"
     ]
    }
   ],
   "source": [
    "# Currently testing model process on 100,000 records\n",
    "# 95k for training set, 5k for test set\n",
    "traindocs = []\n",
    "testdocs = []\n",
    "for index, line in enumerate(cleaned_data):\n",
    "    words = gensim.utils.to_unicode(line).split()\n",
    "    split = ['train', 'test'][index//1200000]\n",
    "    \n",
    "    if split == 'train':\n",
    "        traindocs.append(TaggedDocument(words, [index]))\n",
    "    else:\n",
    "        testdocs.append(TaggedDocument(words, [index]))\n",
    "\n",
    "print('%d train, %d test' % (len(traindocs), len(testdocs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('traindocs', 'wb') as fp:\n",
    "    pickle.dump(traindocs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testdocs', 'wb') as fp:\n",
    "    pickle.dump(testdocs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/gensim/models/doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Doc2Vec(traindocs, dm = 1, dbow_words = 1, \n",
    "                              negative = 5, alpha=0.025, size= 200, \n",
    "                              min_alpha=0.025, min_count=0\n",
    "                             )\n",
    " \n",
    "model.train(traindocs, total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('actuals', 0.487826406955719),\n",
       " ('versus', 0.4535791575908661),\n",
       " ('forecasted', 0.40754592418670654),\n",
       " ('expected', 0.3885841965675354),\n",
       " ('overrun', 0.386729896068573),\n",
       " ('compared', 0.37691235542297363),\n",
       " ('reasonableness', 0.3718114197254181),\n",
       " ('unexpected', 0.3611285090446472),\n",
       " ('baseline', 0.3575695753097534),\n",
       " ('projected', 0.35488003492355347)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['actual'])\n",
    "# model['ceo']\n",
    "# model.docvecs.most_similar(2)\n",
    "# traindocs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['designer', 'bim', 'cad', 'manager', 'design', 'permitting', 'construction', 'oversight', 'single', 'multi', 'family', 'residential', 'commercial', 'retail', 'mixed', 'use', 'educational', 'facility', 'design', 'conducted', 'urban', 'design', 'planning', 'ordinance', 'design', 'well', 'web', 'graphic', 'design', 'coordinated', 'team', 'engineer', 'architect', 'construction', 'manager', 'design', 'project', 'w', 'construction', 'cost', 'ranging', 'k', 'activity', 'included', 'contract', 'negotiation', 'zoning', 'ordinance', 'review', 'building', 'code', 'research', 'review', 'construction', 'document', 'design', 'permit', 'expediting', 'interfaced', 'managed', 'coordination', 'client', 'consultant', 'vendor', 'throughout', 'phase', 'design', 'implemented', 'maintained', 'computer', 'system', 'server', 'software', 'set', 'managed', 'emerging', 'standard', 'bim', 'cad', 'software', 'revit', 'acad', 'designed', 'maintained', 'urban', 'studio', 'inc', 'company', 'website', 'http', 'www', 'urbanstudio', 'u'], tags=[85917])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(traindocs)\n",
    "# model.docvecs[85916]\n",
    "traindocs[85917]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.docvecs[94999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filevector = open('docvectors.txt', 'w')\n",
    "filemeta = open('docmeta.txt', 'w')\n",
    "# filemeta.write(\"%s\\n\" % 'title')\n",
    "\n",
    "for index in range(95000):\n",
    "#     cleaned_vectors = '\\t'.join(str(vector) for vector in model.docvecs[index])\n",
    "#     filevector.write(\"%s\\n\" % cleaned_vectors)\n",
    "    filemeta.write(\"%s\\n\" % (str(index) + ' ' + ' '.join(traindocs[index].words[0:5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['national', 'account', 'manager', 'accountable', 'managing', 'client', 'portfolio', 'client', 'totaling', 'individual', 'location', 'hospitality', 'retail', 'travel', 'vertical', 'total', 'annual', 'recurring', 'revenue', 'million', 'responsible', 'achieving', 'non', 'recurring', 'revenue', 'profit', 'margin', 'monthly', 'support', 'revenue', 'quota', 'constantly', 'exceeded', 'goal', 'consulted', 'sold', 'maintained', 'guest', 'back', 'house', 'wireless', 'infrastructure', 'named', 'national', 'account', 'resulting', 'trusted', 'advisor', 'role', 'formulated', 'strategic', 'sale', 'plan', 'stimulated', 'account', 'growth', 'retention', 'executed', 'creation', 'presentation', 'proposal', 'contract', 'monthly', 'reporting', 'portal', 'rebranding', 'marketing', 'material', 'utilized', 'salesforce', 'tm', 'sale', 'activity', 'hardware', 'distribution', 'customized', 'reporting', 'used', 'strong', 'project', 'management', 'skill', 'organize', 'secure', 'manage', 'company', 'resource', 'meet', 'customer', 'timeline', 'divested', 'vmware'], tags=[3847])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindocs[3847]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95000"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the data more. Are the majority of these jobs entry level or higher level?\n",
    "# We will base it on their graduation date.\n",
    "\n",
    "# Load dataset\n",
    "edu_data = pd.read_csv('processed_resumes_education.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>resume_id</th>\n",
       "      <th>container</th>\n",
       "      <th>degree</th>\n",
       "      <th>school</th>\n",
       "      <th>location</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0004d469fc497102</td>\n",
       "      <td>education-items</td>\n",
       "      <td>Bachelor of Science in Computer Science</td>\n",
       "      <td>Wichita State University</td>\n",
       "      <td>Wichita, KS</td>\n",
       "      <td>1990 to 1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0006216bf673dc16</td>\n",
       "      <td>education-items</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Youth Academy Soccer Coach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0006216bf673dc16</td>\n",
       "      <td>education-items</td>\n",
       "      <td>Bachelor of Arts in History</td>\n",
       "      <td>Georgia State University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>August 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0006216bf673dc16</td>\n",
       "      <td>education-items</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wake Forest University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995 to 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>000cb5da9472be95</td>\n",
       "      <td>education-items</td>\n",
       "      <td>Bachelor of Science in Human Resources Management</td>\n",
       "      <td>Louisiana State University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city         resume_id        container                                             degree                      school     location         dates\n",
       "0  atlanta  0004d469fc497102  education-items            Bachelor of Science in Computer Science    Wichita State University  Wichita, KS  1990 to 1994\n",
       "1  atlanta  0006216bf673dc16  education-items                                                NaN  Youth Academy Soccer Coach          NaN          2018\n",
       "2  atlanta  0006216bf673dc16  education-items                        Bachelor of Arts in History    Georgia State University  Atlanta, GA   August 2004\n",
       "3  atlanta  0006216bf673dc16  education-items                                                NaN      Wake Forest University          NaN  1995 to 1997\n",
       "4  atlanta  000cb5da9472be95  education-items  Bachelor of Science in Human Resources Management  Louisiana State University          NaN           NaN"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_data.columns = ['city','resume_id','container','degree','school','location','dates']\n",
    "edu_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>resume_id</th>\n",
       "      <th>container</th>\n",
       "      <th>degree</th>\n",
       "      <th>school</th>\n",
       "      <th>location</th>\n",
       "      <th>dates</th>\n",
       "      <th>degree_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [city, resume_id, container, degree, school, location, dates, degree_changed]\n",
       "Index: []"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_data[edu_data.degree == 'n economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_data['degree_changed'] = edu_data.degree.str.strip()\n",
    "edu_data = edu_data[~edu_data.degree_changed.isnull()]\n",
    "edu_data = edu_data[edu_data.degree_changed != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>resume_id</th>\n",
       "      <th>container</th>\n",
       "      <th>degree</th>\n",
       "      <th>school</th>\n",
       "      <th>location</th>\n",
       "      <th>dates</th>\n",
       "      <th>degree_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [city, resume_id, container, degree, school, location, dates, degree_changed]\n",
       "Index: []"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_data[edu_data.degree_changed == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = edu_data.degree_changed.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'交換留学 in 応用数学と統計学'"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data[145508]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_cleaned_data = clean_data(sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_cleaned_data = [i for i in edu_cleaned_data if i != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145451"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edu_cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently testing model process on 100,000 records\n",
    "# 95k for training set, 5k for test set\n",
    "edu_traindocs = []\n",
    "edu_testdocs = []\n",
    "for index, line in enumerate(edu_cleaned_data):\n",
    "    words = gensim.utils.to_unicode(line).split()\n",
    "    edu_traindocs.append(TaggedDocument(words, [index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/gensim/models/doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Doc2Vec(edu_traindocs, dm = 0, dbow_words = 1, \n",
    "                              negative = 5, alpha=0.025, size= 100, \n",
    "                              min_alpha=0.025, min_count=50\n",
    "                             )\n",
    " \n",
    "model.train(edu_traindocs, total_examples=1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145451"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edu_filevector = open('edu_docvectors.txt', 'w')\n",
    "edu_meta_list = []\n",
    "edu_filemeta = open('edu_docmeta.txt', 'w')\n",
    "# edu_filemeta.write(\"%s\\n\" % 'title')\n",
    "\n",
    "for index in range(len(edu_traindocs)):\n",
    "    cleaned_vectors = '\\t'.join(str(vector) for vector in model.docvecs[index])\n",
    "    if not cleaned_vectors or cleaned_vectors == '':\n",
    "        print(\"issue with vector\")\n",
    "        print(index)\n",
    "    edu_filevector.write(\"%s\\n\" % cleaned_vectors)\n",
    "    cleaned_meta = (str(index) + ' ' + ' '.join(edu_traindocs[index].words))\n",
    "#     if index >= 94999:\n",
    "#         print(index)\n",
    "    if not cleaned_meta:\n",
    "        print(\"issue with meta\")\n",
    "        print(index)\n",
    "    edu_filemeta.write(\"%s\\n\" %cleaned_meta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(551, 0.8868790864944458),\n",
       " (70196, 0.878495454788208),\n",
       " (2000, 0.8709387183189392),\n",
       " (80538, 0.8597651124000549),\n",
       " (70195, 0.851523756980896),\n",
       " (107155, 0.8514955639839172),\n",
       " (59046, 0.8435146808624268),\n",
       " (77950, 0.8270519971847534),\n",
       " (63751, 0.8169573545455933),\n",
       " (113529, 0.8154358863830566)]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.most_similar(['actual'])\n",
    "# model['ceo']\n",
    "model.docvecs.most_similar(5367)\n",
    "# edu_traindocs[5367]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(551, 0.9420228004455566),\n",
       " (107155, 0.9348306059837341),\n",
       " (59046, 0.9313094019889832),\n",
       " (113529, 0.9298691153526306),\n",
       " (2000, 0.9274170398712158),\n",
       " (70195, 0.9271657466888428),\n",
       " (70196, 0.9147785902023315),\n",
       " (38485, 0.9115675091743469),\n",
       " (63751, 0.9100584387779236),\n",
       " (80538, 0.9061126112937927)]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar(5367)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['business', 'administrator'], tags=[551])"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_traindocs[551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['business', 'administrator', 'business'], tags=[70196])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_traindocs[70196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['master', 'business', 'administrator'], tags=[113529])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_traindocs[113529]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we get the clustering of documents, we can try to derive the topic\n",
    "# https://stackoverflow.com/questions/46047506/how-to-find-most-similar-terms-words-of-a-document-in-doc2vec?rq=1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
