{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import os, sys, email\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from string import punctuation\n",
    "import timeit\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "start = timeit.default_timer()\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "from smart_open import smart_open\n",
    "from random import shuffle\n",
    "\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('processed_resumes_work_ADDED_JOB_TITLES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed jobs without description\n",
    "data = data[~data.descript.isnull()]\n",
    "\n",
    "# Convert null job title into blank\n",
    "data.loc[data.role.isnull()] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for training doc2vec\n",
    "data['train_val'] = data.role + \" \" + data.descript.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229127"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_val'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214940"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_val'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "\n",
    "    cleaned_list = []\n",
    "    \n",
    "    for row in data:\n",
    "        row = re.sub(r'[^a-zA-Z ]+', ' ', row.lower())\n",
    "        row = ' '.join([lmtzr.lemmatize(word) for word in row.split() if word not in stop_words])\n",
    "        cleaned_list.append(row)    \n",
    "    \n",
    "    return cleaned_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application architect .TOKYO, JAPAN\\xa0.ING L fe I su ce Comp y (Jp)Lm ted p ov des fe su ce p oducts d se v ces\\xa0.fo E ow e s. ING L Po t (INGLP)sfudmet system povdgv ous\\xa0.se v ces of the ING fe su ce to Age t, R, Custome d ING emp oyees. Th s INGLP s\\xa0.etypot the web whe e ING c p omote ew p oducts d se v ces, teg te\\xa0.d ffe e t web ppctosfop ocess gdhdg custome tsctos, docume t\\xa0.p oduct gudeesdp ov de st uct o s d educ to cotetfoRsd ge ts..'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data[328412]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328412"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.index(\"application architect tokyo japan ing l fe su ce comp jp lm ted p ov de fe su ce p oducts se v ce fo e ow e ing l po inglp sfudmet system povdgv ous se v ce ing fe su ce age r custome ing emp oyees th inglp etypot web whe e ing c p omote ew p oducts se v ce teg te ffe e web ppctosfop ocess gdhdg custome tsctos docume p oduct gudeesdp ov de st uct educ cotetforsd ge t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['application architect tokyo japan ing l fe su ce comp jp lm ted p ov de fe su ce p oducts se v ce fo e ow e ing l po inglp sfudmet system povdgv ous se v ce ing fe su ce age r custome ing emp oyees th inglp etypot web whe e ing c p omote ew p oducts se v ce teg te ffe e web ppctosfop ocess gdhdg custome tsctos docume p oduct gudeesdp ov de st uct educ cotetforsd ge t']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in cleaned_data if \"application architect tokyo japan\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = data.train_val.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_data = clean_data(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('cleaned_data', 'wb') as fp:\n",
    "#     pickle.dump(cleaned_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pickle.load(open('cleaned_data', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_engineer_dat = [s for s in cleaned_data if \"engineer\" in s or \"sales\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traindocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191467 train, 0 test\n"
     ]
    }
   ],
   "source": [
    "# Currently testing model process on 100,000 records\n",
    "# 95k for training set, 5k for test set\n",
    "traindocs = []\n",
    "testdocs = []\n",
    "for index, line in enumerate(cleaned_engineer_dat):\n",
    "    words = gensim.utils.to_unicode(line).split()\n",
    "    split = ['train', 'test'][index//1200000]\n",
    "    \n",
    "    if split == 'train':\n",
    "        traindocs.append(TaggedDocument(words, [index]))\n",
    "    else:\n",
    "        testdocs.append(TaggedDocument(words, [index]))\n",
    "\n",
    "print('%d train, %d test' % (len(traindocs), len(testdocs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('traindocs', 'wb') as fp:\n",
    "    pickle.dump(traindocs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testdocs', 'wb') as fp:\n",
    "    pickle.dump(testdocs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/gensim/models/doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Doc2Vec(traindocs, dm = 1, dbow_words = 1, \n",
    "                              negative = 5, alpha=0.025, size= 200, \n",
    "                              min_alpha=0.001, min_count=0, epochs=10\n",
    "                             )\n",
    " \n",
    "# model.train(traindocs, total_examples=175605, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwheatley/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('workflow', 0.6198469400405884),\n",
       " ('system', 0.5893020629882812),\n",
       " ('methodology', 0.5851994752883911),\n",
       " ('procedure', 0.5841983556747437),\n",
       " ('program', 0.5720818042755127),\n",
       " ('method', 0.5653647184371948),\n",
       " ('operation', 0.5644145607948303),\n",
       " ('project', 0.5632549524307251),\n",
       " ('activity', 0.5632162094116211),\n",
       " ('application', 0.5554951429367065)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(doc_id):\n",
    "    if isinstance(doc_id, int):\n",
    "        print(doc_id, 'seed_doc', ' '.join(traindocs[doc_id].words))\n",
    "    else:\n",
    "        print(doc_id)\n",
    "    print()\n",
    "        \n",
    "    examples = model.docvecs.most_similar(doc_id)\n",
    "    for example in examples:\n",
    "        index = example[0]\n",
    "        percent = example[1]\n",
    "        text = ' '.join(traindocs[index].words)\n",
    "        print(index, percent, text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85916 seed_doc sr business analyst sale engineer responsible product demonstration installation design sintecmedia software respond rfi rfp prospective current customer cable amp amp broadcast network mso mvpd write functional design sintecmedia software covering adsales right management program scheduling promotion finance provide product demonstration training site remotely area sintecmedia broadcast management software act project manager gap analysis phase implementation participate analysis provide marketing material powerpoint presentation one sheet etc provide input product roadmaps r amp amp\n",
      "\n",
      "40151 0.6598896384239197 composer recording mixing engineer guitarist vocalist manager write arrange music organize lead rehearsal responsible recording production mixing recent project\n",
      "\n",
      "12636 0.6573036909103394 electrical engineer provide electrical design custom control panel drawing electrical schematic field wiring panel wiring\n",
      "\n",
      "9826 0.6550716161727905 system engineer provide ad exchange office pc citrix vdi smart phone support client throughout u via phone email\n",
      "\n",
      "12768 0.654778242111206 staffing specialist information technology healthcare finance electrical amp amp mechanical engineering support full cycle talent acquisition team recruiter client manager amp amp executive staff coordinate job fair hiring event seek new talent network build rapport potential candidate prepares post job appropriate job board social medium etc screen candidate resume ensure qualification meet open position initiate direct contact job candidate via telephone e mail social medium prepares present qualified candidate talent acquisition team us internal database online job board social medium source identify potential candidate open position\n",
      "\n",
      "29359 0.652536928653717 software engineer qfund provides web based point sale solution capable handling various short term finance transaction payday loan check cashing installment loan title loan etc check n go leader consumer financial industry providing instant cash advance web application support payday loan cash advance check cashing involved design development mvc based web application using strut designed developed ui using jsp servlets html javascript\n",
      "\n",
      "97790 0.6522753834724426 senior software engineer built managed solaris hp ux red hat linux server provide o platform production application database configure manage veritas volume manager veritas cluster server product solaris server manage window server server host web application using ii m sql server database manage ii web server window server nt server manage support version control software software release management product rational clearcase clearquest responsible veritas netbackup dr solution\n",
      "\n",
      "1616 0.6516718864440918 project manager sale engineer trainer software metratech metranet metracare amp amp metraar\n",
      "\n",
      "1565 0.6510374546051025 network integration engineer provide system integration engineering support amp amp video headend build out shos vhos along side rd party vendor team amp amp iptv u verse solution provide training amp amp support amp amp ops team network management maintain customer relationship amp amp responsible install integration testing amp amp customer sign offs\n",
      "\n",
      "38160 0.646227240562439 chief engineer responsible maintenance support\n",
      "\n",
      "51012 0.6457781791687012 senior quality assurance engineer provide manual testing web based product window nt unix mac linux platform create manual test plan new feature update existing test plan provide detail testing participate functional requirement spec document review assist trouble shooting customer issue\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_most_similar(85916)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filevector = open('docvectors.txt', 'w')\n",
    "vector_list = []\n",
    "meta_list = []\n",
    "# filemeta = open('docmeta.txt', 'w')\n",
    "# edu_filemeta.write(\"%s\\n\" % 'title')\n",
    "\n",
    "for index in range(len(traindocs)):\n",
    "    cleaned_vectors = '\\t'.join(str(vector) for vector in model.docvecs[index])\n",
    "    if not cleaned_vectors or cleaned_vectors == '':\n",
    "        print(\"issue with vector\")\n",
    "        print(index)\n",
    "    vector_list.append(cleaned_vectors)\n",
    "#     filevector.write(\"%s\\n\" % cleaned_vectors)\n",
    "    cleaned_meta = (str(index) + ' ' + ' '.join(traindocs[index].words))\n",
    "#     if index >= 94999:\n",
    "#         print(index)\n",
    "    if not cleaned_meta:\n",
    "        print(\"issue with meta\")\n",
    "        print(index)\n",
    "#     filemeta.write(\"%s\\n\" %cleaned_meta )\n",
    "    meta_list.append(cleaned_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vector_list)\n",
    "# len(meta_list)\n",
    "filevector = open('docvectors.txt', 'w')\n",
    "filemeta = open('docmeta.txt', 'w')\n",
    "for row in vector_list:\n",
    "    filevector.write(\"%s\\n\" % row)\n",
    "for row in meta_list:\n",
    "    filemeta.write(\"%s\\n\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the data more. Are the majority of these jobs entry level or higher level?\n",
    "# We will base it on their graduation date.\n",
    "\n",
    "# Load dataset\n",
    "edu_data = pd.read_csv('processed_resumes_education.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>resume_id</th>\n",
       "      <th>container</th>\n",
       "      <th>degree</th>\n",
       "      <th>school</th>\n",
       "      <th>location</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0004d469fc497102</td>\n",
       "      <td>education-items</td>\n",
       "      <td>Bachelor of Science in Computer Science</td>\n",
       "      <td>Wichita State University</td>\n",
       "      <td>Wichita, KS</td>\n",
       "      <td>1990 to 1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0006216bf673dc16</td>\n",
       "      <td>education-items</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Youth Academy Soccer Coach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0006216bf673dc16</td>\n",
       "      <td>education-items</td>\n",
       "      <td>Bachelor of Arts in History</td>\n",
       "      <td>Georgia State University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>August 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>0006216bf673dc16</td>\n",
       "      <td>education-items</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wake Forest University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995 to 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>000cb5da9472be95</td>\n",
       "      <td>education-items</td>\n",
       "      <td>Bachelor of Science in Human Resources Management</td>\n",
       "      <td>Louisiana State University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city         resume_id        container                                             degree                      school     location         dates\n",
       "0  atlanta  0004d469fc497102  education-items            Bachelor of Science in Computer Science    Wichita State University  Wichita, KS  1990 to 1994\n",
       "1  atlanta  0006216bf673dc16  education-items                                                NaN  Youth Academy Soccer Coach          NaN          2018\n",
       "2  atlanta  0006216bf673dc16  education-items                        Bachelor of Arts in History    Georgia State University  Atlanta, GA   August 2004\n",
       "3  atlanta  0006216bf673dc16  education-items                                                NaN      Wake Forest University          NaN  1995 to 1997\n",
       "4  atlanta  000cb5da9472be95  education-items  Bachelor of Science in Human Resources Management  Louisiana State University          NaN           NaN"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_data.columns = ['city','resume_id','container','degree','school','location','dates']\n",
    "edu_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>resume_id</th>\n",
       "      <th>container</th>\n",
       "      <th>degree</th>\n",
       "      <th>school</th>\n",
       "      <th>location</th>\n",
       "      <th>dates</th>\n",
       "      <th>degree_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [city, resume_id, container, degree, school, location, dates, degree_changed]\n",
       "Index: []"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_data[edu_data.degree == 'n economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_data['degree_changed'] = edu_data.degree.str.strip()\n",
    "edu_data = edu_data[~edu_data.degree_changed.isnull()]\n",
    "edu_data = edu_data[edu_data.degree_changed != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently testing model process on 100,000 records\n",
    "# 95k for training set, 5k for test set\n",
    "edu_traindocs = []\n",
    "edu_testdocs = []\n",
    "for index, line in enumerate(edu_cleaned_data):\n",
    "    words = gensim.utils.to_unicode(line).split()\n",
    "    edu_traindocs.append(TaggedDocument(words, [index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we get the clustering of documents, we can try to derive the topic\n",
    "# https://stackoverflow.com/questions/46047506/how-to-find-most-similar-terms-words-of-a-document-in-doc2vec?rq=1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
